{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              DOI  \\\n",
      "0       10.47363/jaicc/2024(3)347   \n",
      "1  10.70715/jitcai.2024.v1.i1.004   \n",
      "2            10.2139/ssrn.4782875   \n",
      "3      10.9781/ijimai.2024.02.006   \n",
      "4            10.2139/ssrn.4614223   \n",
      "\n",
      "                                               Title  \\\n",
      "0  Impact of AI and GenAI on Healthcare: Security...   \n",
      "1  The Impact of GenAI on Student Engagement and ...   \n",
      "2  Knowledge Management Perspective of GenAI (GenAI)   \n",
      "3  GenAI in Product Design Education: Navigating ...   \n",
      "4  GenAI Against Humanity: Nefarious Applications...   \n",
      "\n",
      "                                            Abstract  \n",
      "0  <jats:p>This paper aims to understand the impa...  \n",
      "1  <jats:p>The rapid adoption of AI (AI) in highe...  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n",
      "Index(['DOI', 'Title', 'Abstract'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('6n.csv')\n",
    "\n",
    "# Inspect the first few rows and columns\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'Abstract' column has the value 'N/A'\n",
    "df = df[~df['Abstract'].isin(['N/A']) & df['Abstract'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 434\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(df)\n",
    "print(f\"Number of rows in the DataFrame: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cleaning function\n",
    "def clean_html_xml(text):\n",
    "    # Create a BeautifulSoup object to parse the HTML/XML\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    # Extract and return text without HTML/XML tags\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['Abstract'].apply(clean_html_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.47363/jaicc/2024(3)347</td>\n",
       "      <td>Impact of AI and GenAI on Healthcare: Security...</td>\n",
       "      <td>&lt;jats:p&gt;This paper aims to understand the impa...</td>\n",
       "      <td>This paper aims to understand the impact of AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.70715/jitcai.2024.v1.i1.004</td>\n",
       "      <td>The Impact of GenAI on Student Engagement and ...</td>\n",
       "      <td>&lt;jats:p&gt;The rapid adoption of AI (AI) in highe...</td>\n",
       "      <td>The rapid adoption of AI (AI) in higher educat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.7256/2454-0625.2024.6.70926</td>\n",
       "      <td>Socio-cultural risks of multimodal large gener...</td>\n",
       "      <td>&lt;jats:p&gt;\\n The article is devoted to the study...</td>\n",
       "      <td>\\n The article is devoted to the study of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.51191/issn.2637-1898.2024.7.12.12</td>\n",
       "      <td>AI: Duality in Applications of GenAI and Assis...</td>\n",
       "      <td>&lt;jats:p&gt;This paper explores the multifaceted r...</td>\n",
       "      <td>This paper explores the multifaceted role of A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.1007/s43681-022-00176-2</td>\n",
       "      <td>Review of the state of the art in autonomous AI</td>\n",
       "      <td>&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;jats:p&gt;This ...</td>\n",
       "      <td>AbstractThis article presents a new design for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    DOI  \\\n",
       "0             10.47363/jaicc/2024(3)347   \n",
       "1        10.70715/jitcai.2024.v1.i1.004   \n",
       "6        10.7256/2454-0625.2024.6.70926   \n",
       "7  10.51191/issn.2637-1898.2024.7.12.12   \n",
       "9            10.1007/s43681-022-00176-2   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Impact of AI and GenAI on Healthcare: Security...   \n",
       "1  The Impact of GenAI on Student Engagement and ...   \n",
       "6  Socio-cultural risks of multimodal large gener...   \n",
       "7  AI: Duality in Applications of GenAI and Assis...   \n",
       "9    Review of the state of the art in autonomous AI   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  <jats:p>This paper aims to understand the impa...   \n",
       "1  <jats:p>The rapid adoption of AI (AI) in highe...   \n",
       "6  <jats:p>\\n The article is devoted to the study...   \n",
       "7  <jats:p>This paper explores the multifaceted r...   \n",
       "9  <jats:title>Abstract</jats:title><jats:p>This ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  This paper aims to understand the impact of AI...  \n",
       "1  The rapid adoption of AI (AI) in higher educat...  \n",
       "6  \\n The article is devoted to the study of the ...  \n",
       "7  This paper explores the multifaceted role of A...  \n",
       "9  AbstractThis article presents a new design for...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['cleaned_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 16:07:13,798 - top2vec - INFO - Pre-processing documents for training\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2024-11-12 16:07:13,958 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
      "2024-11-12 16:08:06,547 - top2vec - INFO - Creating joint document/word embedding\n",
      "INFO:top2vec:Creating joint document/word embedding\n",
      "2024-11-12 16:08:07,011 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "INFO:top2vec:Creating lower dimension embedding of documents\n",
      "2024-11-12 16:08:10,148 - top2vec - INFO - Finding dense areas of documents\n",
      "INFO:top2vec:Finding dense areas of documents\n",
      "2024-11-12 16:08:10,174 - top2vec - INFO - Finding topics\n",
      "INFO:top2vec:Finding topics\n"
     ]
    }
   ],
   "source": [
    "model = Top2Vec(documents, embedding_model='universal-sentence-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This paper aims to understand the impact of AI and GenAI on the healthcare sector. As AI grows, it becomes an integral part of the healthcare system's components, such as the diagnosis process, the development of personalized treatments, and improvement in overall patient care. However, such enhancements raise severe concerns regarding data security and the privacy of patients.\"\n",
      " 'The rapid adoption of AI (AI) in higher education is reshaping students’ learning experiences, with tools such as GenAI, Grammarly, and Microsoft Copilot becoming integral to academic work. This study, informed by data from the Digital Education Council Global AI Student Survey 2024, examines the impact of AI on students, focusing on usage patterns, trust in AI-generated content, ethical awareness, and expectations for institutional support. Findings indicate that 86% of students use AI for various academic tasks, with a majority expressing concerns about trust, fairness, and over-reliance on AI. While students value AI’s benefits, only 5% are fully aware of institutional guidelines on AI use, and 72% desire more AI literacy courses, reflecting a significant need for comprehensive support in navigating AI responsibly. The study underscores the importance of clear ethical guidelines, faculty training, and student involvement in AI policy formation to foster responsible AI use and preserve academic integrity. These insights offer valuable guidance for educators and policymakers seeking to integrate AI ethically and effectively into higher education.'\n",
      " '\\n The article is devoted to the study of the conditions for ensuring the information security of Russian citizens when using generative \"AI\" technologies in the socio-cultural sphere. The relevance of the topic is due to the modern high rates of development of computer neural networks that generate multimedia content: texts, images, sounds and videos. The developers classify generative technologies as \"AI\", position them as a \"new nuclear project\" capable of radically increasing the productivity of socio-cultural creativity, and receive significant government, corporate and investment financing. The object of the study is modern multimedia generative models, the subject of the study is the possibility of their use in the socio-cultural sphere of creativity and the associated risks of information security. The purpose of the study is to determine the conditions for ensuring the information security of Russian citizens when using multimodal generative technologies in the socio-cultural sphere. \\xa0The research materials are scientific publications of recent years (2021–2024) in Russian journals of the HAC list (categories K1, K2) and international Scopus publications (quartiles Q1, Q2) devoted to research and critical analysis of the possibilities of multimodal generative models, associated risks and security tools. The philosophical methodology is applied: theoretical and cultural analysis, synthesis.  The scientific novelty of the article is due to the application of a philosophical theoretical and cultural methodology for a critical comparison of the declarations of developers and the actual potential of applications of multimodal generative technologies. The result of the study is an assessment of how greatly exaggerated the risks predicted based on the positioning of the technologies in question as \"AI\". The real risks are proposed to include: the incompatibility of development costs with the usefulness of the results; lowering the cultural level of professional and amateur creativity and worsening the tastes of the mass audience; use in \"social engineering\", fraud, mass disinformation, fake news, manipulation of public consciousness, \"cancellation culture\", destruction of traditional values and substitution of socio-cultural identity. The means of ensuring the safety of Russian citizens in the development and use of multimedia generative technologies in the socio-cultural sphere are recommended.\\n\\t'\n",
      " 'This paper explores the multifaceted role of AI in the field of music, more specifically, examining the positives and negatives of generative and assistive capacities. AI (AI) in music involves the application of computational techniques to various aspects of music creation, production and consumption. In the domain of assistive AI, the concentration is on how machine learning could potentially help musicians in the area of composition and performance to enhance their musical creativity. The paper will discuss an interesting collaborative effort between pure human creativity and computational assistance covering an explanation for a vast number of tools using generative as well as assistive AI models.\\n\\nIn addition, the paper will address the concerns facing the music industry while this technology keeps on improving, the potential drawbacks and ethical considerations. It opens the question of authenticity and emotional depth, and when or if this new technology could be able to replicate it. Further explanation in the paper will consider music examples with a focus on music styles assisted and generated by the use of AI, from pop to classical music.\\n\\nWith a thorough analysis of the aforementioned subject, the paper aims to provide a detailed perspective on the constant evolution of AI tools used in music with highlights on the need for a balanced approach. In providing a detailed perspective on the evolving landscape of AI tools in music, this study adopts a methodological approach that involves comprehensive analysis of both the benefits and challenges associated with these innovative gadgets. The paper contributes to the ongoing discussion on the intersection of technology and artistic expression. By examining the potential benefits and challenges with these innovative models, the paper signifies ongoing discourse on the impact of technology on artistic expression.'\n",
      " 'AbstractThis article presents a new design for autonomous AI (AI), based on the state-of-the-art algorithms, and describes a new autonomous AI system called ‘AutoAI’. The methodology is used to assemble the design founded on self-improved algorithms that use new and emerging sources of data (NEFD). The objective of the article is to conceptualise the design of a novel AutoAI algorithm. The conceptual approach is used to advance into building new and improved algorithms. The article integrates and consolidates the findings from existing literature and advances the AutoAI design into (1) using new and emerging sources of data for teaching and training AI algorithms and (2) enabling AI algorithms to use automated tools for training new and improved algorithms. This approach is going beyond the state-of-the-art in AI algorithms and suggests a design that enables autonomous algorithms to self-optimise and self-adapt, and on a higher level, be capable to self-procreate.'\n",
      " \"AbstractEthical and social concerns are a key obstacle to the adoption of AI (AI) in the life sciences and beyond. The discussion of these issues has intensified in recent years and led to a number of approaches, tools and initiatives. Key amongst them is the idea of ex-ante impact assessments that aim to identify issues at the early stages of development. One prominent example of such ex-ante impact assessment is the European Union's (EU) Assessment list for Trustworthy AI (ALTAI). This article uses the findings of a large-scale application of the ALTAI to a large neuro-informatics project as an exemplar to demonstrate the effectiveness and limitations of the ALTAI in practice. The article shows that ex-ante impact assessment has the potential to help identify and address ethical and social issues. However, they need to be understood as part of a broader socio-technical ecosystem of AI. For ALTAI and related approaches to be useful in bio-medical research, they should be interpreted from a systems theory perspective which allows for their integration into the rich set of tools, legislation and approaches. The paper argues that ex-ante impact assessments have the best chance of being successful if seen applied in conjunction with other approaches in the context of the overall AI ecosystem.\"\n",
      " 'With the development of AI technology, ethical, legal, and social problems are emerging. In particular, examples of abuse of GenAI include fake news, deepfakes, automatic spam and phishing, and copyright in-fringement, and ethical regulations are needed. Globally, these problems are responded to through AI ethics guidelines and AI Ethics Committee, among which the European Union is implementing safety and accountabil-ity and ethical evaluation through AI Act. In addition, AI ethics standardiza-tion is necessary to strengthen global competitiveness, secure social trust, and minimize negative effects. To this end, the domestic AI Ethics Forum promotes the ethical use of AI technology through discussion of ethical is-sues, guideline development, education, and international cooperation ac-tivities. In this paper, we examine the overall status of AI ethics regulation trends and standardization, which can be expected to have effects such as reliability, safety assurance, innovation promotion, and increased social acceptance through standardization activities.'\n",
      " \"Objective:This study investigates the transformative potential of GenAI(GenAI) within the business domain and the entrepreneurial activity.Methodology:A comprehensive research design is adopted, integrating text-mining techniques to analysedata obtained from publicly available innovation repositories. A systematic literaturereview (SLR) is developed based on the literature obtained from all databases indexedin Web of Science (WoS), incorporating preprints from arXiv, alongside industry-relatedinnovation data in the form of patents from Google Patents. This method enables the derivationof valuable insights regarding the impact and prospective developments of GenAIacross diverse business sectors and industries by leveraging Natural Language Processing(NLP) and network analysis.Results:The research outcomes highlight the significant potential of GenAI in enabling informeddecision-making, enhancing productivity, and revealing new growth opportunities inthe business landscape. The continuously evolving business environment is examined,emphasising GenAI's role as a catalyst for data-driven innovation. However, there are stillrelevant limitations to overcome.Limitations:The selection of data sources and the study period may have excluded relevant or recentlypublished articles and patents within the scope of the present research. The language ofthe databases analysed is only English.Practical Implications:The practical implications of this study carry significant weight, serving as a valuableresource for decision-makers, researchers, and practitioners navigating the constantlyshifting terrain of business innovation through the lens of GenAI. Understanding thepotential advantages and challenges associated with GenAI adoption equips stakeholdersto make informed decisions and develop future business strategies.\"\n",
      " 'AbstractThere is a broad consensus that AI should contribute to the common good, but it is not clear what is meant by that. This paper discusses this issue and uses it as a lens for analysing what it calls the “democracy deficit” in current AI governance, which includes a tendency to deny the inherently political character of the issue and to take a technocratic shortcut. It indicates what we may agree on and what is and should be up to (further) deliberation when it comes to AI ethics and AI governance. Inspired by the republican tradition in political theory, it also argues for a more active role of citizens and (end-)users: not only as participants in deliberation but also in ensuring, creatively and communicatively, that AI contributes to the common good.'\n",
      " 'GenAI (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to GenAI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.'\n",
      " 'Presently, GenAI has taken center stage in the news media, educational institutions, and the world at large. Machine learning has been a decades-old phenomenon, with little exposure to the average person until very recently. In the natural world, the oldest and best example of a “generative” model is the human being - one can close one’s eyes and imagine several plausible different endings to one’s favorite TV show. This paper focuses on the impact of generative and machine learning AI on the financial industry. Although GenAI is an amazing tool for a discriminant user, it also challenges us to think critically about the ethical implications and societal impact of these powerful technologies on the financial industry. It requires ethical considerations to guide decision-making, mitigate risks, and ensure that GenAI is developed and used to align with ethical principles, social values, and in the best interests of communities.'\n",
      " 'In this study, we attempted to analyze the AI literacy content elements found in AI textbooks, focusing on educational books for lower grades, and seek a direction for developing AI educational books for lower grades through critical consideration. As a result of this study, it was found that there was some bias in the proportion of common areas of elementary school AI education subjects shown in AI literacy education books for lower grades. Elementary schools are places where basic AI literacy education must be provided to school-age students entering the era of AI. Students in lower grades must also receive appropriate AI literacy education tailored to their grade level of development. Therefore, even if it is a somewhat difficult and unfamiliar concept or theory without bias in each area, teaching and learning materials that take into account the developmental characteristics of lower grades should be developed and actively reflected in the elementary school AI education content system. '\n",
      " 'The prevalence of scams proliferating via online platforms has been identified as an emerging societal problem resulting in large-scale financial losses for victims. Online scams typically rely for their success on the generation of fake but convincing user profiles to conceal the identities of the scammers from the people being tricked into parting with their money. The increasing sophistication of GenAI (GenAI), which can produce outputs indistinguishable from real content, thus carries the risk of being adopted by fraudsters to assist in the enactment of online scams. This article considers the risks of the potential uptake and use of GenAI applications by online scammers operating in the sharing economy, with a focus on homestay-marketplace platforms and, in particular, the largest such platform, Airbnb.'\n",
      " 'AbstractThis research addressed the management awareness about the ethical and moral aspects of AI (AI). It is a general trend to speak about AI, and many start-ups and established companies are communicating about the development and implementation of AI solutions. Therefore, it is important to consider different perspectives besides the technology and data as the key elements for AI systems. The way in which societies are interacting and organising themselves will change. Such transformations require diverse perspectives from the society and particularly from AI system developers for shaping the humanity of the future. This research aimed to overcome this barrier with the answers for the question: What kind of awareness does the management of AI companies have about the social impact of its AI product or service? The central research question was divided into five sub-questions that were answered by a fundamental literature review and an empirical research study. This covered the management understanding of the terms moral, ethics, and AI; the internal company prioritization of moral and ethics; and the involved stakeholders in the AI product or service development. It analysed the known and used ethical AI guidelines and principles. In the end, the social responsibility of the management regarding AI systems was analysed and compared.'\n",
      " 'AbstractIn this paper, we present an approach for the systematic and comprehensive inclusion of ethical considerations in the design and development process of AI systems, called Ethics by Design for AI (EbD-AI). The approach is the result of a three-year long research effort, and has recently be adopted by the European Commission as part of its ethics review procedure for AI projects. We describe and explain the approach and its different components and its application to the development of AI software and systems. We also compare it to other approaches in AI ethics, and we consider limitations of the approach as well as potential criticisms.'\n",
      " 'AbstractHuman rights concerns in relation to the impacts brought forth by AI (‘AI’) have revolved around examining how it affects specific rights, such as the right to privacy, non-discrimination and freedom of expression. However, this article argues that the effects go deeper, potentially challenging the foundational assumptions of key concepts and normative justifications of the human rights framework. To unpack this, the article applies the lens of ‘slow violence’, a term borrowed from environmental justice literature, to frame the grinding, gradual, attritional harms of AI towards the human rights framework.The article examines the slow violence of AI towards human rights at three different levels. First, the individual as the subject of interest and protection within the human rights framework, is increasingly unable to understand nor seek accountability for harms arising from the deployment of AI systems. This undermines the key premise of the framework which was meant to empower the individual in addressing large power disparities and calling for accountability towards such abuse of power. Secondly, the ‘slow violence’ of AI is also seen through the unravelling of the normative justifications of discrete rights such as the right to privacy, freedom of expression and freedom of thought, upending the reasons and assumptions in which those rights were formulated and formalised in the first place. Finally, the article examines how even the wide interpretations towards the normative foundation of human rights, namely human dignity, is unable to address putative new challenges AI poses towards the concept. It then considers and offers the outline to critical perspectives that can inform a new model of human rights accountability in the age of AI.'\n",
      " 'AbstractAs AI (AI) rapidly advances and integrates into various domains, cybersecurity emerges as a critical field grappling with both the benefits and pitfalls of AI technologies. This paper explores the multifaceted dimensions of AI-driven cyberattacks, offering insights into their implications, mitigation strategies, underlying motivations, and profound societal impacts. The research centres on developing and presenting the AI Cybersecurity Dimensions (AICD) Framework, a comprehensive, multidimensional schema designed to guide academics, policymakers, and industry professionals in understanding and combating the evolving challenges posed by AI-driven cyber threats. The research unveils the complex dynamics of offensive AI, stressing the need for adaptive defences and ethical considerations. Concurrently, the study highlights adversarial AI threats, calling for proactive measures to address their potential ramifications. Through rigorous textual analyses and extensive literature reviews, the paper underscores the urgency for interdisciplinary approaches to bridge the technology-humanity chasm traditionally observed in cybersecurity discussions. By synthesising these diverse elements, the AICD Framework emerges as an instrumental tool for holistic understanding and practical interventions in the AI-infused cybersecurity landscape. The paper concludes with an urgent call for collaborative efforts in research and practice to navigate the intricate challenges and capitalise on the opportunities borne from the convergence of AI and cybersecurity.'\n",
      " 'AbstractThe emergence of GenAI, such as large language models and text-to-image models, has had a profound impact on society. The ability of these systems to simulate human capabilities such as text writing and image creation is radically redefining a wide range of practices, from artistic production to education. While there is no doubt that these innovations are beneficial to our lives, the pervasiveness of these technologies should not be underestimated, and raising increasingly pressing ethical questions that require a radical resemantization of certain notions traditionally ascribed to humans alone. Among these notions, that of technological intentionality plays a central role. With regard to this notion, this paper first aims to highlight what we propose to define in terms of the intentionality gap, whereby, insofar as, currently, (1) it is increasingly difficult to assign responsibility for the actions performed by AI systems to humans, as these systems are increasingly autonomous, and (2) it is increasingly complex to reconstruct the reasoning behind the results they produce as we move away from good old fashioned AI; it is now even more difficult to trace the intentionality of AI systems back to the intentions of the developers and end users. This gap between human and technological intentionality requires a revision of the concept of intentionality; to this end, we propose here to assign preter-intentional behavior to GenAI. We use this term to highlight how AI intentionality both incorporates and transcends human intentionality; i.e., it goes beyond (preter) human intentionality while being linked to it. To show the merits of this notion, we first rule out the possibility that such preter-intentionality is merely an unintended consequence and then explore its nature by comparing it with some paradigmatic notions of technological intentionality present in the wider debate on the moral (and technological) status of AI.'\n",
      " 'The use of GenAI (AI) in higher education design programmes is expanding, yet there is little formalized approach to its integration. Professionally, GenAI is starting to become an indispensable tool for ideation and prototyping, two fundamental skills taught in design’s studio pedagogy. Yet this digital leap into the future risks leaving design educators behind unless they take a proactive approach to its implementation and present its strengths and weaknesses. This study surveyed 74 design students from an Australian university, exploring their current utilization of GenAI and their projections for its future application in design practice. Findings confirm that GenAI is being used in an ad hoc way by students to speed up the ideation process tempered by a sceptical view of its creative output. A list of GenAI training for integration into the design curricula based on current research and survey results is proposed.'\n",
      " 'AbstractThroughout our history, we, Homo sapiens, have used technologies to better satisfy ourneeds. The relation betweenneedsandtechnologyis so fundamental that the US National Research Council defines the distinguishing characteristic of technology as its goal “to make modifications in the world [in order] to meet human needs” [1]. AI (AI) is one of the most promising emerging technologies of our time. Similar to other technologies, AI is expected by many “to meet [human] needs”. In this article, we reflect on the relationship betweenneedsand AI, and call for the realization ofneeds-awareAI systems. We argue that re-thinkingneedsfor,through,by, andwithAI can be a very useful means towards the development of realistic approaches for sustainableHuman-aware,Accountable,Lawful, andEthical (HALE) AI systems. We discuss some of the most critical gaps, barriers, enablers, and drivers of co-creating future AI-based sociotechnical systems in which [human]needsare well considered and met. Finally, we provide an overview of potential challenges and considerations that should be carefully taken into account; and call for joint, immediate, and interdisciplinary efforts and collaborations to start on the path toneeds-awareAI.'\n",
      " 'AbstractData and autonomous systems are taking over our lives, from healthcare to smart homes very few aspects of our day to day are not permeated by them. The technological advances enabled by these technologies are limitless. However, with advantages so too come challenges. As these technologies encompass more and more aspects of our lives, we are forgetting the ethical, legal, safety and moral concerns that arise as an outcome of integrating our lives with technology. In this work, we study the lifecycle of AI from data gathering to deployment, providing a structured analytical assessment of the potential ethical, safety and legal concerns. The paper then presents the foundations for the first ethical AI sustainability statement to guide future development of AI in a safe and sustainable manner.'\n",
      " 'AbstractGenAI (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we’ll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social media platforms to the unnerving potential of AI to generate fabricated identities, or alibis made of synthetic realities, the stakes have never been higher. The lines between the virtual and the real worlds are blurring, and the consequences of potential GenAI’s nefarious applications impact us all. This article serves both as a synthesis of rigorous research presented on the risks of GenAI and misuse of LLMs and as a thought-provoking vision of the different types of harmful GenAI applications we might encounter in the near future, and some ways we can prepare for them.'\n",
      " 'AbstractAI (AI) is playing an increasingly important role in society, and applications like GenAI and Dall-E, which can produce texts and pictures on their own, are becoming very popular. This development raises questions regarding ethics, values, and responsibility, as AI-generated documents may promote misinformation and erode democracy, while human actors can scarcely be held accountable. AI technology may also support an efficient, rationalized society, which has its advantages and disadvantages. Two main spheres, which influence society’s perspective on the connection between AI, ethics and responsibility, are public media debates and the legal system. Popular newspapers reach broad audiences, so insight is provided into what perspectives on these issues are helping everyday citizens form their opinions. Legal frameworks potentially regulate citizens’ and companies’ dealing with AI technology—and may get included in media discussions on AI. Acknowledging that, this article presents a two-folded analysis. First, the article presents the results of a discourse analysis of 113 articles from German newspapers, ranging from the center-left to the conservative spectrum. The analysis examined how these media frame the connection of AI, ethics, values, and responsibility. The article discusses the discourse analysis together with theoretical assumptions around the question, which actors in society could be counted as accountable in AI regards. Second, a discussion of the European AI legal system is added, to evaluate its connection with the media discourses. The article presents the results of both parts of the analysis together and finally discusses further research perspectives.'\n",
      " 'AI (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?'\n",
      " 'GenAI, powered by Large Language Models (LLMs), has the potential to revolutionize human life by automating tasks, fostering creativity, and improving efficiency. In this work, we highlight recent advancements and related studies in GenAI, focusing on its profound impact across diverse domains such as business customization, healthcare, and software development. Key trends are discussed, including the integration of multimodal AI, which combines text, speech, and images to create seamless interactions and enhance user experiences. The growing adoption of GenAI in enterprises, driven by efficiency gains and innovation, underscores its transformative potential in business operations. Furthermore, the evolving regulatory landscape seeks to address ethical and legal challenges posed by AI, particularly in regulating high-risk systems and ensuring transparency and accountability. This study explores three AI-driven systems we developed, using case studies to demonstrate how GenAI transforms routine tasks, making them more efficient and innovative. Usability testing was conducted to assess the performance of these systems, and experimental results validate their effectiveness in automating tasks, personalizing user experiences, and improving operational efficiency. These findings emphasize the growing importance of customized AI solutions in enhancing operational efficiency and meeting specific organizational needs, ultimately leading to significant improvements in both personal and professional settings.'\n",
      " 'AbstractThe popularisation of AI (AI) technologies has sparked discussion about their ethical implications. This development has forced governmental organisations, NGOs, and private companies to react and draft ethics guidelines for future development of ethical AI systems. Whereas many ethics guidelines address values familiar to ethicists, they seem to lack in ethical justifications. Furthermore, most tend to neglect the impact of AI on democracy, governance, and public deliberation. Existing research suggest, however, that AI can threaten key elements of western democracies that are ethically relevant. In this paper, Rawls’s theory of justice is applied to draft a set of guidelines for organisations and policy-makers to guide AI development towards a more ethical direction. The goal is to contribute to the broadening of the discussion on AI ethics by exploring the possibility of constructing AI ethics guidelines that are philosophically justified and take a broader perspective of societal justice. The paper discusses how Rawls’s theory of justice as fairness and its key concepts relate to the ongoing developments in AI ethics and gives a proposition of how principles that offer a foundation for operationalising AI ethics in practice could look like if aligned with Rawls’s theory of justice as fairness.'\n",
      " 'AbstractAI (AI) offers much promise for improving healthcare. However, it runs the looming risk of causing individual and societal harms; for instance, exacerbating inequalities amongst minority groups, or enabling compromises in the confidentiality of patients’ sensitive data. As such, there is an expanding, unmet need for ensuring AI for healthcare is developed in concordance with human values and ethics. Augmenting “principle-based” guidance that highlight adherence to ethical ideals (without necessarily offering translation into actionable practices), we offer a solution-based framework for operationalising ethics in AI for healthcare. Our framework is built from a scoping review of existing solutions of ethical AI guidelines, frameworks and technical solutions to address human values such as self-direction in healthcare. Our view spans the entire length of the AI lifecycle: data management, model development, deployment and monitoring. Our focus in this paper is to collate actionable solutions (whether technical or non-technical in nature), which can be steps that enable and empower developers in their daily practice to ensuring ethical practices in the broader picture. Our framework is intended to be adopted by AI developers, with recommendations that are accessible and driven by the existing literature. We endorse the recognised need for ‘ethical AI checklists’ co-designed with health AI practitioners, which could further operationalise the technical solutions we have collated. Since the risks to health and wellbeing are so large, we believe a proactive approach is necessary for ensuring human values and ethics are appropriately respected in AI for healthcare.'\n",
      " 'AbstractThere is a growing feeling that AI (AI) is getting out of control. Many AI experts worldwide stress that great care must be taken on the so-called alignment problem, broadly understood as the challenge of developing AIs whose actions are in line with human values and goals. The story goes that ever more powerful AI systems are escaping human control and might soon operate in a manner that is no longer guided by human purposes. This is what we call the AI-out-of-control discourse which, in this paper, we critically examine and debunk. Drawing on complementary insights from political theory, socio-technical studies and Marxian political economy, we critique the supposed animistic and autonomous nature of AI, and the myth of the uncontrollability of AI. The problem is not that humanity has lost control over AI, but that only a minority of powerful stakeholders are controlling its creation and diffusion, through politically undemocratic processes of decision-making. In these terms, we reframe the alignment problem thesis with an emphasis on citizen engagement and public political participation. We shed light on the existing politics of AI and contemplate alternative political expressions whereby citizens steer AI development or stop it in the first place.'\n",
      " 'The controversy surrounding GenAI has reopened the debate about the impact of new technologies in many fields of activities, including communication and PR. This study mapped Romanian PR practitioners’ use of GenAI and their perception of it, placing a special focus on the ethical concerns involved and the implications for the profession itself. We took a quantitative-qualitative approach by using both a survey and semi-structured interviews. Our goal was to determine the impact of GenAI (AI) in the Romanian PR industry and to understand the reasons and challenges behind integrating GenAI in PR practice. The survey findings revealed a substantial adoption (73.5%) of AI within the Romanian PR community, with an overwhelming 91.6% of them using GenAI. The satisfaction level was remarkably high, with 92% expressing satisfaction with GenAI application efficacy. Benefits included timesaving, work simplification, and the reduction of repetitive tasks. Surprisingly, not only did 67.3% of respondents not perceive AI as an immediate threat to PR jobs, but 80.5% believed AI represents an opportunity for the industry. Indeed, almost all our interviewees admitted relief and satisfaction when using GenAI tools to complete their tasks. However, some concerns were expressed regarding the quality of the GenAI content and, in particular, the need to always check this kind of content by a human editor before using it. Moreover, PR professionals’ main ethical concerns are related to the issue of transparency towards their clients when using AI tools to produce different types of content.'\n",
      " 'AbstractAI is currently supplanting the work of humans in many societal contexts. The purpose of this article is to consider the question of when algorithmic tools should be regarded as performing sufficiently well to replace human judgements and decision-making at sentencing. More precisely, the question as to which are the ethically plausible criteria for the comparative performance assessments of algorithms and humans is considered with regard to both risk assessment algorithms that are designed to provide predictions of recidivism and sentencing algorithms designed to determine sentences in individual criminal cases. It is argued, first, that the prima facie most obvious assessment criteria do not stand up to ethical scrutiny. Second, that ethically plausible criteria presuppose ethical theory on penal distribution which currently has not been sufficiently developed. And third, that the current lack of assessment criteria has comprehensive implications regarding when algorithmic tools should be implemented in criminal justice practice.'\n",
      " 'AbstractDemocratic theories assume that citizens have some form of political knowledge in order to vote for representatives or to directly engage in democratic deliberation and participation. However, apart from widespread attention to the phenomenon of fake news and misinformation, less attention has been paid to how they are supposed to acquire that knowledge in contexts shaped by AI and related digital technologies. While this topic can also be approached from an empirical angle, this paper contributes to supporting concerns about AI and democracy by looking at the issue through the lens of political epistemology, in particular using the concept of epistemic agency. It argues that AI (AI) endangers democracy since it risks to diminish the epistemic agency of citizens and thereby undermine the relevant kind of political agency in democracy. It shows that next to fake news and manipulation by means of AI analysis of big data, epistemic bubbles and the defaulting of statistical knowledge endanger the epistemic agency of citizens when they form and wish to revise their political beliefs. AI risks to undermine trust in one’s own epistemic capacities and hinder the exercise of those capacities. If we want to protect the knowledge basis of our democracies, we must address these problems in education and technology policy.'\n",
      " 'This study investigates the use of GenAI (GenAI), in university assessments in Malaysia to understand its impact on evaluations. It explores the implications, challenges and academic viewpoints related to this advancement. The research methodology involves a combination of methods, including gathering feedback from education experts at three universities using a 5-point Likert scale. The main results show that educators generally see AI as beneficial for improving assessment accuracy but highlight some considerations that need attention. Additionally, the findings suggest that while AI can enhance assessments by providing optimized learning experiences ethical issues such as data privacy and excessive automation need to be addressed. Educators also acknowledge the importance of training programs to help them develop the skills needed to integrate AI into their practices effectively. The study concludes that although AI shows potential for transforming education, maintaining a balance between technology and human-centered learning is crucial for implementation.'\n",
      " 'AbstractThe integration of AI (AI) into human society mandates that their decision-making process is explicable to users, as exemplified in Asimov’s Three Laws of Robotics. Such human interpretability calls for explainable AI (XAI), of which this paper cites various models. However, the transaction between computable accuracy and human interpretability can be a trade-off, requiring answers to questions about the negotiable conditions and the degrees of AI prediction accuracy that may be sacrificed to enable user-interpretability. The extant research has focussed on technical issues, but it is also desirable to apply a branch of ethics to deal with the trade-off problem. This scholarly domain is labelledcoarse ethicsin this study, which discusses two issues vis-à-vis AI prediction as a type of evaluation. First, which formal conditions would allow trade-offs? The study posits two minimal requisites: adequately high coverage and order-preservation. The second issue concerns conditions that could justify the trade-off between computable accuracy and human interpretability, to which the study suggests two justification methods: impracticability and adjustment of perspective from machine-computable to human-interpretable. This study contributes by connecting ethics to autonomous systems for future regulation by formally assessing the adequacy of AI rationales.'\n",
      " 'Since its maiden release into the public domain on November 30, 2022, GenAI garnered more than one million subscribers within a week. The GenAI tool ⎼GenAI took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of GenAI to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of GenAI in promoting teaching and learning. Benefits of GenAI include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the GenAI such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how GenAI could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving GenAI tools could be used safely and constructively to improve education and support students’ learning.'\n",
      " 'The development of AI today is increasingly rapid. AI is able to process and collect data to carry out a task efficiently and accurately, as well as being creative and flexible, so that AI can produce work independently. However, the use of AI cannot be separated from providing data in the form of works protected by copyright. This article discusses the concept of AI in Law Number 28 of 2014 concerning Copyright and the problems that exist, namely the use of works protected by copyright as data for AI creations. This research is normative juridical research with a conceptual approach and a statutory approach carried out by examining existing doctrines and applicable regulations. According to the provisions of Copyright Law in Indonesia, AI cannot yet be categorized as the creator of a creation because it is not a legal subject, and the use of a creation to utilize AI in the creative field must still respect and respect the creative work by obtaining permission from the creator of the creation.'\n",
      " 'Conversations about AI (AI) are impossible to escape since the inception of GenAI in November 2022—whether it is about the end of our jobs or the end of the world! This Editorial talks about AI and its subsets and how this may relate to health care.'\n",
      " 'AbstractWhat criteria must an AI (AI) satisfy to qualify for moral standing? My starting point is that sentient AIs should qualify for moral standing. But future AIs may have unusual combinations of cognitive capacities, such as a high level of cognitive sophistication without sentience. This raises the question of whether sentience is a necessary criterion for moral standing, or merely sufficient. After reviewing nine criteria that have been proposed in the literature, I suggest that there is a strong case for thinking that some non-sentient AIs, such as those that are conscious and have non-valenced preferences and goals, and those that are non-conscious and have sufficiently cognitively complex preferences and goals, should qualify for moral standing. After responding to some challenges, I tentatively argue that taking into account uncertainty about which criteria an entity must satisfy to qualify for moral standing, and strategic considerations such as how such decisions will affect humans and other sentient entities, further supports granting moral standing to some non-sentient AIs. I highlight three implications: that the issue of AI moral standing may be more important, in terms of scale and urgency, than if either sentience or consciousness is necessary; that researchers working on policies designed to be inclusive of sentient AIs should broaden their scope to include all AIs with morally relevant interests; and even those who think AIs cannot be sentient or conscious should take the issue seriously. However, much uncertainty about these considerations remains, making this an important topic for future research.'\n",
      " 'Qualitative researchers can benefit from using GenAI (GenAI), such as different versions of GenAI—GPT-3.5 or GPT-4, Google Bard—now renamed as a Gemini, and Bing Chat—now renamed as a Copilot, in their studies. The scientific community has used AI (AI) tools in various ways. However, using GenAI has generated concerns regarding potential research unreliability, bias, and unethical outcomes in GenAI-generated research results. Considering these concerns, the purpose of this commentary is to review the current use of GenAI in qualitative research, including its strengths, limitations, and ethical dilemmas from the perspective of critical appraisal from South Asia, Nepal. I explore the controversy surrounding the proper acknowledgment of GenAI or AI use in qualitative studies and how GenAI can support or challenge qualitative studies. First, I discuss what qualitative researchers need to know about GenAI in their research. Second, I examine how GenAI can be a valuable tool in qualitative research as a co-author, a conversational platform, and a research assistant for enhancing and hindering qualitative studies. Third, I address the ethical issues of using GenAI in qualitative studies. Fourth, I share my perspectives on the future of GenAI in qualitative research. I would like to recognize and record the utilization of GenAI and/or AI alongside my cognitive and evaluative abilities in constructing this critical appraisal. I offer ethical guidance on when and how to appropriately recognize the use of GenAI in qualitative studies. Finally, I offer some remarks on the implications of using GenAI in qualitative studies'\n",
      " 'The advent of GenAI (AI), including advanced machine learning and natural language processing technologies, has ushered in a transformative era for sales training. This paper explores the profound impacts of these technologies on enhancing the effectiveness and adaptability of sales teams. Focusing on the automation of administrative tasks, the personalization of training experiences through adaptive learning systems, real-time performance analytics, and the creation of immersive simulations, we demonstrate how GenAI significantly enhances productivity, efficiency, and sales strategy innovation.'\n",
      " 'AbstractThis scoping review examines the research landscape about publics’ views on the ethical challenges of AI. To elucidate how the concerns voiced by the publics are translated within the research domain, this study scrutinizes 64 publications sourced from PubMed® and Web of Science™. The central inquiry revolves around discerning the motivations, stakeholders, and ethical quandaries that emerge in research on this topic. The analysis reveals that innovation and legitimation stand out as the primary impetuses for engaging the public in deliberations concerning the ethical dilemmas associated with AI technologies. Supplementary motives are rooted in educational endeavors, democratization initiatives, and inspirational pursuits, whereas politicization emerges as a comparatively infrequent incentive. The study participants predominantly comprise the general public and professional groups, followed by AI system developers, industry and business managers, students, scholars, consumers, and policymakers. The ethical dimensions most commonly explored in the literature encompass human agency and oversight, followed by issues centered on privacy and data governance. Conversely, topics related to diversity, nondiscrimination, fairness, societal and environmental well-being, technical robustness, safety, transparency, and accountability receive comparatively less attention. This paper delineates the concrete operationalization of calls for public involvement in AI governance within the research sphere. It underscores the intricate interplay between ethical concerns, public involvement, and societal structures, including political and economic agendas, which serve to bolster technical proficiency and affirm the legitimacy of AI development in accordance with the institutional norms that underlie responsible research practices.'\n",
      " 'With the rapid development of AI technology, GenAI, an AI chat robot released by OpenAI on November 30, 2022, exploded on the Internet. After GenAI exploded on the Internet, AI painting gradually came into peoples sight. At the same time, the debate about AI painting has also become a hot topic of daily discussion. By researching and summarizing the literature on the Internet and analyzing the concepts related to AI painting, this paper will focus on the drawing principle of AI painting and the pros and cons of AI painting as the main research questions, and then the impact on the emergence and development of AI painting have a discussion. While allowing more readers to understand the duality of the impact of AI painting, it also emphasizes that AI lacks the emotional depth of art created by humans. This paper proposes that AI can enhance the potential of human creativity, but the quality and creative context of the main works come from the infinite possibilities of human artists. The future prospects of AI-generated art are expected to be complex and evolving, but subject to constant examination.'\n",
      " 'AbstractWhile there has been much discussion of the ethical assessment of AI (AI) in medicine, such work has rarely been combined with the parallel body of scholarship analyzing epistemic implications of AI. This paper proposes a method for joint evaluation of AI’s ethical and epistemic implications in medicine that draws on the principle-oriented tradition in bioethics and the consequent ‘ethical matrix’ approach to assessing novel technologies. It first introduces principle-based approaches as specific tools for ethical assessment of AI in medicine and other domains that are contrasted with the lack of comparable epistemic principles that would govern AI evaluation in medicine. In the next section, the ethical matrix is explained as a well-established principle-based tool in applied ethics that has had some limited applications to near-term implications of AI in medicine and elsewhere that can be strengthened, I suggest, using epistemic principles. To this end, the following section looks to the philosophy of science for relevant epistemic principles, identifying ‘accuracy’, ‘consistency’, ‘relevance’, and ‘instrumental efficacy’ as a provisional set for technology evaluation. The next section articulates the relevance of these epistemic principles to AI in medicine by highlighting conventional standards that have already been applied in AI, epistemology, and the medical sciences. Before concluding, the paper then defines and defends the possibility of an ‘ethical-epistemic matrix’ for the application of these epistemic principles alongside established ethical principles to a selection of stakeholder groups: patients, clinicians, developers, and the public.'\n",
      " 'AbstractUsing AI (AI) in research offers many important benefits for science and society but also creates novel and complex ethical issues. While these ethical issues do not necessitate changing established ethical norms of science, they require the scientific community to develop new guidance for the appropriate use of AI. In this article, we briefly introduce AI and explain how it can be used in research, examine some of the ethical issues raised when using it, and offer nine recommendations for responsible use, including: (1) Researchers are responsible for identifying, describing, reducing, and controlling AI-related biases and random errors; (2) Researchers should disclose, describe, and explain their use of AI in research, including its limitations, in language that can be understood by non-experts; (3) Researchers should engage with impacted communities, populations, and other stakeholders concerning the use of AI in research to obtain their advice and assistance and address their interests and concerns, such as issues related to bias; (4) Researchers who use synthetic data should (a) indicate which parts of the data are synthetic; (b) clearly label the synthetic data; (c) describe how the data were generated; and (d) explain how and why the data were used; (5) AI systems should not be named as authors, inventors, or copyright holders but their contributions to research should be disclosed and described; (6) Education and mentoring in responsible conduct of research should include discussion of ethical use of AI.'\n",
      " \"The new generation of AI products, represented by GenAI and Wenyan Yixin, is rapidly and extensively integrating into human production and life at an unprecedented pace, breadth, and depth. GenAI possesses distinct characteristics and functionalities compared to rule-based AI, exerting a more prominent dual impact on the high-quality development of China's economy. On the one hand, it can promote high-quality economic development through empowering effects such as innovation-driven effects, enhanced production efficiency, and industrial transformation and upgrading effects. On the other hand, it may give rise to deep-seated risks, including labor market disruptions, market monopolization issues, national security risks, and misinformation phenomena, which could hinder high-quality economic development. It is crucial to have a correct understanding and a scientific approach, leveraging its positive effects while proactively addressing negative impacts, guiding it to better serve the needs of China's high-quality economic development.\"\n",
      " 'AbstractWho is responsible for the events and consequences caused by using artificially intelligent tools, and is there a gap between what human agents can be responsible for and what is being done using AI? Both questions presuppose that the term ‘responsibility’ is a good tool for analysing the moral issues surrounding AI. This article will draw this presupposition into doubt and show how reference to responsibility obscures the complexity of moral situations and moral agency, which can be analysed with a more differentiated toolset of moral terminology. It suggests that the impression of responsibility gaps only occurs if we gloss over the complexity of the moral situation in which artificial intelligent tools are employed and if—counterfactually—we ascribe them some kind of pseudo-agential status.'\n",
      " 'The advent of AI (AI) has revolutionized the way multimedia content is created, processed, and consumed. The Digital Generative Multimedia Tool Theory (DGMTT) aims to provide a theoretical framework for understanding the implications, mechanics, and potential of AI-driven tools in the realm of multimedia. The theory addresses the convergence of AI with digital media creation, exploring how generative models influence artistic expression, content generation, and the broader cultural landscape. The use of generative technologies to produce digital multimedia material is one of the newer developments in this field. DGMTT is therefore presented as a theoretical foothold to address new innovation in the 21st century dominated AI. In this logic framework, it is argued that AI tools provide users with interactive capabilities to generate and modify multimedia content, offering new dimensions of creative freedom and flexibility. Interactive AI tools deepen user engagement by allowing personalized content creation and real-time feedback during the creative process. Thus, DGMTT offers an all-encompassing structure for comprehending and evaluating the fundamentals and consequences of generative tools in the production of multimedia content. It provides information about the creation and use of these instruments, thereby promoting developments in the digital media industry. These tools create dynamic and interactive multimedia content by utilizing machine learning, AI, and algorithms. This theory emphasizes how crucial it is to comprehend the fundamental ideas and principles of generative tools in order to use them efficiently when creating digital media content.'\n",
      " \"The   rapid   advancement   of   artificial   intelligence   (AI)   has revolutionized  the  accounting  profession,  automating  tasks,  identifying patterns,  and  improving  accuracy.  However,  the  increasing  reliance  on  AI raises  ethical  concerns  regarding  privacy,  bias,  transparency,  and accountability. This research paper delves into the ethical considerations of AI implementation in accounting practices.Thepaper begins by examining the  potential  benefits  of  AI  in  accounting,  highlighting  its  ability  to streamline  operations,  enhance  efficiency,  and  reduce  errors.  However,  it also  acknowledges  the  ethical  risks  associated  with  AI,  including  data privacy  breaches,  biased  decision-making,  lack  of  transparency,  and accountability  issues.The  paper  proposes  a  framework  for  responsible  AI implementation  in  accounting  to  address  these  ethical  concerns.  The framework  emphasizes  establishing  clear  ethical  guidelines,ensuring  data privacy  and  security,  mitigating  AI  algorithms'  bias,  promoting  AI decisionmaking  transparency,  and  establishing  accountability  mechanisms.The paper further explores the role of accountants in addressing AI ethics. Accountants  are  responsible  for  upholding  ethical  standards  and  ensuring that AI systems are used responsibly and ethically. They must be aware of the ethical implications of AI and have the knowledge and skills to mitigate ethical risks.In conclusion, the paper emphasizes the need for a proactive approach to AI ethics in accounting. By establishing clear ethical guidelines, promoting responsible AI implementation, and empowering accountants with ethical  knowledge  and  skills,  the  accounting  profession  can  harness  the potential  of AI  while  upholding  ethical  principles  and  safeguarding  public trust.\"\n",
      " 'AbstractA burgeoning of AI (AI) technologies in recent years has led to increased discussion about its potential to address many issues considered otherwise intractable, including those highlighted by the United Nations 2030 Agenda for Sustainable Development and associated Sustainable Development Goals. In tandem with this growth in AI is an expanding body of documentation regarding how such advanced technologies should be governed and managed. Issued by a variety of sources and comprising frameworks, policies and guidelines, this body of work encompasses the legal, social, ethical and policy issues around AI. With at least 470 such documents identified, as of May 2021, in the Council of Europe’s tracker of AI initiatives, questions are emerging around the diversity of views expressed, especially regarding the influence of the Global North or Euro-American perspectives. Our previous analysis of a corpus of largely grey literature discovered blind spots regarding both gender representation and perspectives from the Global South. Expanding on that work, this paper examines a significantly extended corpus, with a focus on the role of underrepresented groups in the wider AI discourse. We find that voices from the Global South and consideration of alternative ethical approaches are largely absent from the conversation. In light of the prominence of social, cultural and ethical perspectives from the Global North, this paper explores implications for the development of standards for ethical AI. Concluding by offering approaches to incorporate more diverse ethical viewpoints and beliefs, we call for increased consideration of power structures when developing AI ethics policies and standards within these alternative socio-cultural and socio-economic contexts.'\n",
      " 'Since the launch of GenAI in November 2022, there has been a dawning understanding in the higher education sector of ways GenAI (GenAI) tools can challenge the traditional roles of academic teaching staff (e.g., Chan & Tsi, 2023) and support learning by students. For example, Mike Sharples in Sabzalieva and Valentini (2023) identifies ten roles that GenAI can play which would all support student learners. Media and sector concern has focused on whether GenAI use by students would disrupt the integrity of degrees and awards and there is a good deal of debate on how to adapt assessment, learning outcomes and curricula to reflect and reward unique human competences associated with a discipline or subject and embrace students’ use of GenAI.\\nEducational development colleagues have been at the vanguard of leading higher education provider reactions and responses to the widespread availability and capabilities of GenAI. This case study reflects on a year of action to lead teaching staff and students as well as institutional policy and practice through a series of steps to enable rapid, proportionate and robust change. We apply Kotter’s (1996) eight stage change model to reflect on the activities, achievements and challenges to date. We do not purport to have finished but rather can see, one year in, that increasingly activity is more embedded into structures, routines, the practice of others, and our work as educational developers. We reflect forward too on the ways we will act next to ‘make change stick’ and on our own personal, professional journeys as educational change leaders, all of whom were new appointments in the educational development centre. We chart how we have been able to innovate and to lead complex educational change at pace.'\n",
      " 'AbstractAI (AI) has found a myriad of applications in many domains of technology, and more importantly, in improving people’s lives. Sadly, AI solutions have already been utilized for various violations and theft, even receiving the name AI or Crime (AIC). This poses a challenge: are cybersecurity experts thus justified to attack malicious AI algorithms, methods and systems as well, to stop them? Would that be fair and ethical? Furthermore, AI and machine learning algorithms are prone to be fooled or misled by the so-called adversarial attacks. However, adversarial attacks could be used by cybersecurity experts to stop the criminals using AI, and tamper with their systems. The paper argues that this kind of attacks could be named Ethical Adversarial Attacks (EAA), and if used fairly, within the regulations and legal frameworks, they would prove to be a valuable aid in the fight against cybercrime.'\n",
      " 'AbstractGenAI (GnAI) has garnered significant attention worldwide across diverse industries, including in book publishing. To date, more attention has been paid to its potential in creative collaboration and less to the editorial possibilities of its application. Interest has accelerated since the breakthrough of a new Large Language Model in late 2022. This paper engages with the ethical and industrial implications of using GnAI in a creative context, namely literary publishing. It raises crucial questions about intellectual property, trust, the author–editor relationship and publishing professionals’ evolving roles in shaping quality literature. Using a published story as a test case, we compare edits using GnAI with those by professional editors over multiple drafts and at different stages of editorial development. We consider the potential ethical implications of the use of GnAI in literary fiction editing, highlighting the principles and practices that underpin professional editing to consider how these may or may not translate in the use of GnAI. This is followed by a discussion of the risks and opportunities in using GnAI in editing literary texts in the trade publishing context.'\n",
      " \"In an era marked by remarkable technological advancements, AI (AI) has emerged as a powerful force in the realm of International Relations. AI's adaptability, which includes automating the processes of foreign policy-making and improving predictive analytics, is swiftly reshaping the ways in which countries participate in international affairs. The impact of AI is notably observed in activities like data analysis, policy assessment, conflict resolution, cybersecurity, language translation, and disaster response, all of which streamline diplomatic activities and enhance communication. This article discusses how AI technology will shape the field of International Relations.\"\n",
      " 'AbstractGovernance efforts for AI (AI) are taking on increasingly more concrete forms, drawing on a variety of approaches and instruments from hard regulation to standardisation efforts, aimed at mitigating challenges from high-risk AI systems. To implement these and other efforts, new institutions will need to be established on a national and international level. This paper sketches a blueprint of such institutions, and conducts in-depth investigations of three key components of any future AI governance institutions, exploring benefits and associated drawbacks: (1) “purpose”, relating to the institution’s overall goals and scope of work or mandate; (2) “geography”, relating to questions of participation and the reach of jurisdiction; and (3) “capacity”, the infrastructural and human make-up of the institution. Subsequently, the paper highlights noteworthy aspects of various institutional roles specifically around questions of institutional purpose, and frames what these could look like in practice, by placing these debates in a European context and proposing different iterations of a European AI Agency. Finally, conclusions and future research directions are proposed.'\n",
      " 'AbstractThe control problem related to robots and AI usually discussed is that we might lose control over advanced technologies. When authors like Nick Bostrom and Stuart Russell discuss this control problem, they write in a way that suggests that having as much control as possible is good while losing control is bad. In life in general, however, not all forms of control are unambiguously positive and unproblematic. Some forms—e.g. control over other persons—are ethically problematic. Other forms of control are positive, and perhaps even intrinsically good. For example, one form of control\\xa0that many philosophers have argued is intrinsically good and a virtue is self-control. In this paper, I relate these questions about control and its value to different forms of robots and AI more generally. I argue that the more robots are made to resemble human beings, the more problematic it becomes—at least symbolically speaking—to want to exercise full control over these robots. After all, it is unethical for one human being to want to fully control another human being. Accordingly, it might be seen as problematic—viz. as representing something intrinsically bad—to want to create humanoid robots that we exercise complete control over. In contrast, if there are forms of AI such that control over them can be seen as a form of self-control, then this might be seen as a virtuous form of control. The “new control problem”, as I call it, is the question of under what circumstances retaining and exercising complete control over robots and AI is unambiguously ethically good.'\n",
      " 'AbstractMedical imaging (MI) has assumed a central role in medicine. AI (AI) has revolutionized computer vision and it is also approaching to impact deeply MI. Fundamental ethical matters have raised and teams of experts around the world are involved in defining ethical borders for AI in MI. However, reading the extremely detailed proposals, it is clear that the treated ethical arguments have been completely redefined and specifically structured for AI in MI. Instead, many of them should be inherited from other technologies already in use in MI. The complete re-definition of ethical principles could produce contradictions and delays for AI adoption in MI, thus arising important ethical concerns. In this paper, potential ethical issues related to AI delay are presented: the objective is to contribute to reuse some concepts from other technologies to streamline the arguments and avoid these concerns.'\n",
      " 'In this systematic review, we synthesize ten empirical peer-reviewed articles published between 2019 and 2023 that used GenAI (GenAI) for automated feedback in higher education. There are significant opportunities and challenges to integrate these tools effectively into learning environments as the demand for timely and personalized feedback grows. We examine the articles based on instructional contexts and system characteristics, identifying critical implementation possibilities for GenAI in automated feedback. Our findings reveal that GenAI provides diverse feedback across various contexts with multiple instructional purposes. GenAI systems can reduce instructor workload by automating routine grading and feedback tasks, allowing educators to focus on more complex teaching responsibilities with augmented capabilities. Additionally, these systems enhance communication, offer cognitive and emotional support, and improve accessibility by creating supportive, stress-free learning environments. Overall, implementing GenAI automated feedback systems improves educational outcomes and creates a more efficient and supportive learning environment for students and instructors. We conclude with future research directions to better integrate GenAI with human instruction by reconsidering instructors’ roles, especially in providing feedback to create more effective educational experiences.'\n",
      " 'AbstractIn this editorial essay, we argue that GenAI programs (GenAI) draw on what we term a “hypercommons”, involving collectively produced inputs and labour that are largely invisible or untraceable. We argue that automatizing the exploitation of common inputs, in ways that remix and reconfigure them, can lead to a crisis of academic authorship in which the moral agency involved in scholarly production is increasingly eroded. We discuss the relationship between the hypercommons and authorship in terms of moral agency and the ethics of academic production, speculating on different responses to the crisis of authorship as posed by GenAI.'\n",
      " 'AbstractGenAI (GenAI) represents a shift from AI’s ability to “recognize” to its ability to “generate” solutions for a wide range of tasks. As generated solutions and applications grow more complex and multi-faceted, new needs, objectives, and possibilities for explainability (XAI) have emerged. This work elaborates on why XAI has gained importance with the rise of GenAI and the challenges it poses for explainability research. We also highlight new and emerging criteria that explanations should meet, such as verifiability, interactivity, security, and cost considerations. To achieve this, we focus on surveying existing literature. Additionally, we provide a taxonomy of relevant dimensions to better characterize existing XAI mechanisms and methods for GenAI. We explore various approaches to ensure XAI, ranging from training data to prompting. Our paper provides a concise technical background of GenAI for non-technical readers, focusing on text and images to help them understand new or adapted XAI techniques for GenAI. However, due to the extensive body of work on GenAI, we chose not to delve into detailed aspects of XAI related to the evaluation and usage of explanations. Consequently, the manuscript appeals to both technical experts and professionals from other fields, such as social scientists and information systems researchers. Our research roadmap outlines over ten directions for future investigation.'\n",
      " 'AbstractWidespread use of AI (AI) and machine learning (ML) in the US banking industry raises red flags with regulators and social groups due to potential risk of data-driven algorithmic bias in credit lending decisions. The absence of a valid and reliable measure of responsible AI (RAI) has stunted the growth of organizational research on RAI (i.e., the organizational balancing act to optimize efficiency and equity). To address this void, we develop a novel measurement instrument to assess RAI maturity in firms. A review of the nascent literature reveals that there is a wide distribution of RAI capabilities. The RAI instrument that we advance is based on the exhaustive review of this dispersed literature. Analyses of data from large US banks show strong evidence of validity and reliability of the RAI maturity instrument.'\n",
      " 'AbstractThe potential for AI algorithms and game theory concepts\\xa0to offer prescriptive and decision-making capability for humankind is increasingly recognized. This derives from the increasing availability of granular, multivariable, well-curated data offering analytical insights for necessarily complex human behaviors and activities. Of the multitude of situations that this decision-making aptitude presents, the application to governmental policy offers a commanding case. This would allow decisions to be made for the benefit of societies and citizens based on rigorous objective information devoid of the traditional approach of choosing policies and societal values based on the opinion of a handful of selected representatives who may be exposed to a lack of comprehensive data analysis capacity and subject to personal biases. There would need to be a critical requirement of wider socially responsible data practices here, beyond those of technical considerations and the incorporation of wider societal fairness approaches. Amongst the schools of political thought particularly acquiescent to the application by this approach would be the egalitarian approach of John Rawls. Here an Original Position’s pre-determination tool of Veil of Ignorance and ensuing Difference Principal presents a method of distributive justice that can be clearly mathematically defined in economics theory through Wald’s Maximin principle. This offers an opportunity to apply algorithmic game theory and AI computational approaches to implement Rawlsian distributive justice that are presented and discussed. The outputs from the algorithmic acquaintance of Rawlsian egalitarianism with applicable state data, protected with appropriate privacy, security, legal, ethical and social governance could in turn lead to automated direct governmental choices and an objective Social Contract for citizens of digitally literate nations.'\n",
      " 'AbstractThe potential benefits and risks of AI technologies have sparked a wide-ranging debate in both academic and public circles. On one hand, there is an urgent call to address the immediate and avoidable challenges associated with these tools, such as accountability, privacy, bias, understandability, and transparency; on the other hand, prominent figures like Geoffrey Hinton and Elon Musk have voiced concerns over the potential rise of Super AI, whose singularity could pose an existential threat to humanity. Coordinating the efforts of thousands of decentralized entities to prevent such a hypothetical event may seem insurmountable in our intricate and multipolar world. Thus, drawing from both perspectives, this work suggests employing the tools and framework of Stoic philosophy, particularly the concept of the dichotomy of control—focusing on what is within our power. This Stoic principle offers a practical and epistemological approach to managing the complexities of AI, and it encourages individuals to organize their efforts around what they can influence while adapting to the constraints of external factors. Within this framework, the essay found that Stoic wisdom is essential for assessing risks, courage is necessary to face contemporary challenges, and temperance and tranquility are indispensable; and these lessons can inform ongoing public and academic discourse, aiding in the development of more effective policy proposals for aligning Narrow AI and General AI with human values.'\n",
      " 'AbstractGenAI (AI), as a transformative technology, holds significant promise for applications in healthcare. At the same time, the datafication, AI integration, and commodification of health have opened the floodgates for ethical issues, including those related to fairness, access, beneficence, democracy, solidarity, inclusion, and societal harms. As further the digitalization, innovation, and disruption of healthcare is inevitable, the paper maps out how power, equity, access, identity, participation, and knowledge contribute to creating social injustice issues. It also discusses that current justice approaches—distributive justice, representational justice, restorative justice, and capabilities-centered justice—do not have enough impact to prevent or remedy the many harms and injustices that AI has already created in healthcare or will continue to do so. The paper proposes that a transformative justice approach is needed for GenAI as a transformative technology, focused on (1) peace, emancipation, and eliminating the root causes of injustice, (2) holistic conflict resolution, (3) human rights-based approaches, and (4) the empowerment of agency and actors.'\n",
      " 'AbstractAI (AI) technologies are increasingly creeping into the work sphere, thereby gradually questioning and/or disturbing the long-established moral concepts and norms communities have been using to define what makes work good. Each community, and Muslims make no exception in this regard, has to revisit their moral world to provide well-thought frameworks that can engage with the challenging ethical questions raised by the new phenomenon of AI-mediated work. For a systematic analysis of the broad topic of AI-mediated work ethics from an Islamic perspective, this article focuses on presenting an accessible overview of the “moral world” of work in the Islamic tradition. Three main components of this moral world were selected due to their relevance to the AI context, namely (1) Work is inherently good for humans, (2) Practising a religiously permitted profession and (c) Maintaining good relations with involved stakeholders. Each of these three components is addressed in a distinct section, followed by a sub-section highlighting the relevance of the respective component to the particular context of AI-mediated work. The article argues that there are no unsurmountable barriers in the Islamic tradition against the adoption of AI technologies in work sphere. However, important precautions should be considered to ensure that embracing AI will not be at the cost of work-related moral values. The article also highlights how important lessons can be learnt from the positive historical experience of automata that thrived in the Islamic civilization.'\n",
      " 'AbstractThis survey paper explores the transformative role of AI (AI) in information security. Traditional methods, especially rule-based approaches, faced significant challenges in protecting sensitive data from ever-changing cyber threats, particularly with the rapid increase in data volume. This study thoroughly evaluates AI’s application in information security, discussing its strengths and weaknesses. It provides a detailed review of AI’s impact on information security, examining various AI algorithms used in this field, such as supervised, unsupervised, and reinforcement learning, and highlighting their respective strengths and limitations. The study identifies key areas for future AI research in information security, focusing on improving algorithms, strengthening information security, addressing ethical issues, and exploring safety and security-related concerns. It emphasizes significant security risks, including vulnerability to adversarial attacks, and aims to enhance the robustness and reliability of AI systems in protecting sensitive information by proposing solutions for potential threats. The findings aim to benefit cybersecurity professionals and researchers by offering insights into the intricate relationship between AI, information security, and emerging technologies.'\n",
      " \"<p>Deep learning and AI (AI) have enabled deepfakes, prompting concerns about their social impact. deepfakes have detrimental effects in several businesses, despite their apparent benefits. We explore deepfake detection research and its social implications in this study. We examine capsule networks' ability to detect video deepfakes and their design implications. This strategy reduces parameters and provides excellent accuracy, making it a promising deepfake defense. The social significance of deepfakes is also highlighted, underlining the necessity to understand them. Despite extensive use of face swap services, nothing is known about deepfakes' social impact. The misuse of deepfakes in image-based sexual assault and public figure distortion, especially in politics, highlight the necessity for further research on their social impact. Using state-of-the-art deepfake detection methods like fake face and deepfake detectors and a broad forgery analysis tool reduces the damage deepfakes do. We inquire about to review deepfake detection research and its social impacts in this work. In this paper we analysed various deepfake methods, social impact with misutilization of deepfake technology, and finally giving clear analysis of existing machine learning models. We want to illuminate the potential effects of deepfakes on society and suggest solutions by combining study data.</p>\"\n",
      " 'AbstractThe cosmetic skincare industry is a growing market that extends to different regions and customer groups. In addition to scientific advances and technological developments, state-of-the-art digital approaches, including machine learning and other AI (AI)-based techniques, are being applied at different stages of the value chain. The objectives of these efforts include optimizing the supply chain, developing high-quality, effective and safe products and personalization at every step of the customer journey. However, the use of digital technologies comes with risks and undesirable effects. These include a lack of transparency and accountability, compromised fairness and a general deficiency in data governance, all of which are critical at every customer touchpoint. This dark side of digital transformation is recognized by both businesses and governments. In this paper, we explain the concept of bias leading to unfairness for beauty technology applications. Based on published data we identified potential sources of AI bias in the cosmetic skincare industry and/or beauty tech. They were classified by the stage of the AI lifecycle: biases related to target setting, to acquisition and annotation, to modeling, to validation and evaluation, and to deployment and monitoring. We aim to create awareness of such phenomena among readers, whether executives, managers, developers or potential end-users.'\n",
      " 'AbstractThe arrival of AI (AI) in our society has sparked many hopes and fears, with people having diverging views on the need to strictly regulate AI. The current study investigates how demographic and personality traits are associated with a desire to strictly regulate AI using a representative sample of adults from New Zealand (N = 47,951 participants). Data revealed that support for strict regulation of AI is positively related with agreeableness, neuroticism, and honesty–humility. However, it is negatively related to openness to experiences. A wide range of demographic factors including gender, age, ethnicity, religiosity, neighbourhood level economic deprivation, living rural, relationship status, and parental status were additionally related to support for regulation of AI. However, all these effects were fairly small suggesting that both personality and socio-demographic factors contribute to support for regulating AI, but other factors beyond these characteristics should also be considered for understanding people’s support for regulating AI.'\n",
      " 'AbstractThis paper provides the first comprehensive analysis of ethical issues raised by AI (AI) in veterinary medicine for companion animals. Veterinary medicine is a socially valued service, which, like human medicine, will likely be significantly affected by AI. Veterinary AI raises some unique ethical issues because of the nature of the client–patient–practitioner relationship, society’s relatively minimal valuation and protection of nonhuman animals and differences in opinion about responsibilities to animal patients and human clients. The paper examines how these distinctive features influence the ethics of AI systems that might benefit clients, veterinarians and animal patients—but also harm them. It offers practical ethical guidance that should interest ethicists, veterinarians, clinic owners, veterinary bodies and regulators, clients, technology developers and AI researchers.'\n",
      " 'Abstract\\nRecent AI (AI) tools have demonstrated the ability to produce outputs traditionally considered creative. One such system is text-to-image GenAI (e.g. Midjourney, Stable Diffusion, DALL-E), which automates humans’ artistic execution to generate digital artworks. Utilizing a dataset of over 4 million artworks from more than 50,000 unique users, our research shows that over time, text-to-image AI significantly enhances human creative productivity by 25% and increases the value as measured by the likelihood of receiving a favorite per view by 50%. While peak artwork Content Novelty, defined as focal subject matter and relations, increases over time, average Content Novelty declines, suggesting an expanding but inefficient idea space. Additionally, there is a consistent reduction in both peak and average Visual Novelty, captured by pixel-level stylistic elements. Importantly, AI-assisted artists who can successfully explore more novel ideas, regardless of their prior originality, may produce artworks that their peers evaluate more favorably. Lastly, AI adoption decreased value capture (favorites earned) concentration among adopters. The results suggest that ideation and filtering are likely necessary skills in the text-to-image process, thus giving rise to “generative synesthesia”—the harmonious blending of human exploration and AI exploitation to discover new creative workflows.'\n",
      " 'AbstractOne of the main difficulties in assessing AI (AI) is the tendency for people to anthropomorphise it. This becomes particularly problematic when we attach human moral activities to AI. For example, the European Commission’s High-level Expert Group on AI (HLEG) have adopted the position that we should establish a relationship of trust with AI and should cultivate trustworthy AI (HLEG AI Ethics guidelines for trustworthy AI, 2019, p. 35). Trust is one of the most important and defining activities in human relationships, so proposing that AI should be trusted, is a very serious claim. This paper will show that AI cannot be something that has the capacity to be trusted according to the most prevalent definitions of trust because it does not possess emotive states or can be held responsible for their actions—requirements of the affective and normative accounts of trust. While AI meets all of the requirements of the rational account of trust, it will be shown that this is not actually a type of trust at all, but is instead, a form of reliance. Ultimately, even complex machines such as AI should not be viewed as trustworthy as this undermines the value of interpersonal trust, anthropomorphises AI, and diverts responsibility from those developing and using them. '\n",
      " 'The academic landscape is experiencing a seismic shift as Generative Artificial Intelli-gence (GenAI) rapidly transforms research methodologies. This paper delves into the potential im-pact of GenAI on the future of writing research papers. We explore how GenAI can revolutionize research by: • Augmenting Research Efficiency: Streamlining literature reviews, automating data analy-sis, and generating draft content. • Empowering Knowledge Discovery: Identifying research gaps, suggesting novel hypothe-ses, and summarizing complex information. • Elevating Research Communication: Crafting clear, concise, and grammatically correct language tailored for diverse audiences. However, ethical considerations and potential challenges like plagiarism and bias in AI-generated content must be addressed. We propose strategies for responsible development and integration of GenAI tools in research writing. Finally, we discuss the evolving role of researchers in this AI-powered future, emphasizing critical thinking, human judgment, and effective communication of research findings.'\n",
      " 'AbstractA transition to a world with artificial general intelligence (AGI) may occur within the next few decades. This transition may give rise to catastrophic risks from misaligned AGI, which have received a significant amount of attention, deservedly. Here I argue that AGI systems that are intent-aligned—they always try to do what their operators want them to do—would also create catastrophic risks, mainly due to the power that they concentrate on their operators. With time, that power would almost certainly be catastrophically exploited, potentially resulting in human extinction or permanent dystopia. I suggest that liberal democracies, if they decide to allow the development of AGI, may react to this threat by letting AGI take shape as an intergenerational social project, resulting in an arrangement where AGI is not intent-aligned but symbiotic with humans. I provide some tentative ideas on what the resulting arrangement may look like and consider what speaks for and what against aiming for intent-aligned AGI as an intermediate step.'\n",
      " 'AbstractIn the past few decades, technology has completely transformed the world around us. Indeed, experts believe that the next big digital transformation in how we live, communicate, work, trade and learn will be driven by AI (AI) [83]. This paper presents a high-level industrial and academic overview of AI in Education (AIEd). It presents the focus of latest research in AIEd on reducing teachers’ workload, contextualized learning for students, revolutionizing assessments and developments in intelligent tutoring systems. It also discusses the ethical dimension of AIEd and the potential impact of the Covid-19 pandemic on the future of AIEd’s research and practice. The intended readership of this article is policy makers and institutional leaders who are looking for an introductory state of play in AIEd.'\n",
      " 'Medical image recognition has enormous potential to benefit from the recent developments in federated learning (FL) and interpretable AI (AI). The function of FL and explainable AI (XAI) in the diagnosis of brain cancers is discussed in this paper. XAI and FL techniques are vital for ensuring data ethics during medical image processing. This paper highlights the benefits of FL, such as cooperative model training and data privacy preservation, and the significance of XAI approaches in providing logical justifications for model predictions. A number of case studies on the segmentation of medical images employing FL were reviewed to compares and contrasts various methods for assessing the efficacy of FL and XAI based diagnostic models for brain tumors. The relevance of FL and XAI to improve the accuracy and interpretability during medical image diagnosis have been presented. Future research directions are also described indicating as to integrate data from various modes, create standardised evaluation processes, and manage ethical issues. This paper is intended to provide a deeper insight on relevance of FL and XAI in medical image diagnosis.'\n",
      " 'The recent surge of GenAI (AI) in higher education presents a fascinating landscape of opportunities and challenges. AI has the potential to personalize education and create more engaging learning experiences. However, the effectiveness of AI interventions relies on well-considered implementation strategies. The impact of AI platforms in education is largely determined by the particular learning environment and the distinct needs of each student. Consequently, investigating the attitudes of future educators towards this technology is becoming a critical area of research. This study explores the impact of GenAI platforms on students’ learning performance, experience, and satisfaction within higher education. It specifically focuses on students’ experiences with varying levels of technological proficiency. A comparative study was conducted with two groups from different academic contexts undergoing the same experimental condition to design, develop, and implement instructional design projects using various AI platforms to produce multimedia content tailored to their respective subjects. Undergraduates from two disciplines—Early Childhood Education (n = 32) and Computer Science (n = 34)—participated in this study, which examined the integration of GenAI platforms into educational content implementation. Results indicate that both groups demonstrated similar learning performance in designing, developing, and implementing instructional design projects. Regarding user experience, the general outcomes were similar across both groups; however, Early Childhood Education students rated the usefulness of AI multimedia platforms significantly higher. Conversely, Computer Science students reported a slightly higher comfort level with these tools. In terms of overall satisfaction, Early Childhood Education students expressed greater satisfaction with AI software than their counterparts, acknowledging its importance for their future careers. This study contributes to the understanding of how AI platforms affect students from diverse backgrounds, bridging a gap in the knowledge of user experience and learning outcomes. Furthermore, by exploring best practices for integrating AI into educational contexts, it provides valuable insights for educators and scholars seeking to optimize the potential of AI to enhance educational outcomes.'\n",
      " 'AbstractFollowing the success of deep learning (DL) in research, we are now witnessing the fast and widespread adoption of AI (AI) in daily life, influencing the way we act, think, and organize our lives. However, much still remains a mystery when it comes to how these systems achieve such high performance and why they reach the outputs they do. This presents us with an unusual combination: of technical mastery on the one hand, and a striking degree of mystery on the other. This conjunction is not only fascinating, but it also poses considerable risks, which urgently require our attention. Awareness of the need to analyze ethical implications, such as fairness, equality, and sustainability, is growing. However, other dimensions of inquiry receive less attention, including the subtle but pervasive ways in which our dealings with AI shape our way of living and thinking, transforming our culture and human self-understanding. If we want to deploy AI positively in the long term, a broader and more holistic assessment of the technology is vital, involving not only scientific and technical perspectives, but also those from the humanities. To this end, we present outlines of awork programfor the humanities that aim to contribute to assessing and guiding the potential, opportunities, and risks of further developing and deploying DL systems. This paper contains a thematic introduction (Sect.\\xa01), an introduction to the workings of DL for non-technical readers (Sect.\\xa02), and a main part, containing the outlines of a work program for the humanities (Sect.\\xa03). Readers familiar with DL might want to ignore 2 and instead directly read 3 after 1.'\n",
      " '<p><span lang=\"EN-US\">The advancement of AI (AI) has led to its widespread use in sectors such as finance, healthcare, military, and employment in developed countries. However, this reliance has raised concerns about AI governance, particularly regarding algorithmic biases based on skin color, gender, race, and age. Consequently, many countries have introduced regulations and ethical frameworks to address these issues. The Ministry of Digital Economy and Entrepreneurship in Jordan has included AI in its 2022 plan, signaling significant progress. The integration of AI in education programs underscores this commitment. However, addressing AI\\'s potential negative impacts is essential. We propose ethical considerations and regulations for AI to complement Jordan\\'s initiatives. Our research aims to promote responsible AI usage by developing ethical guidelines in Jordan. It presents techniques to identify and mitigate biases related to skin color, gender, and age in AI outputs and datasets. The research includes extensive testing on datasets, analyzing approximately 100 images, and revealing notable error rates, including a 16% error rate in detecting skin color, a 4% error rate in seeing white faces, and a 6% error rate in identifying females over men. Therefore, ethical considerations and regulations for AI applications in Jordan must be implemented.</span></p>'\n",
      " 'AbstractResearch and activism have increasingly denounced the problematic environmental record of the infrastructure and value chain underpinning AI (AI). Water-intensive data centres, polluting mineral extraction and e-waste dumping are incontrovertibly part of AI’s footprint. In this article, I turn to areas affected by AI-fuelled environmental harm and identify an ethics of resistance emerging from local activists, which I term ‘elemental ethics’. Elemental ethics interrogates the AI value chain’s problematic relationship with the elements that make up the world, critiques the undermining of local and ancestral approaches to nature and reveals the vital and quotidian harms engendered by so-called intelligent systems. While this ethics is emerging from grassroots and Indigenous groups, it echoes recent calls from environmental philosophy to reconnect with the environment via the elements. In empirical terms, this article looks at groups in Chile resisting a Google data centre project in Santiago and lithium extraction (used for rechargeable batteries) in Lickan Antay Indigenous territory, Atacama Desert. As I show, elemental ethics can complement top-down, utilitarian and quantitative approaches to AI ethics and sustainable AI as well as interrogate whose lived experience and well-being counts in debates on AI extinction.'\n",
      " ' Dual Use Research of Concern (DURC) has been well analyzed regarding the life sciences. This article explores the topic of younger fields of medical research and their potential for misuse, especially in the military context. The areas of research considered are AI, neurotechnology, and neuroenhancement. Each of these areas have brought forward highly promising new research. However, in light of the current armed conflicts in Europe and in the Middle East, there is a need to consider what the potential harmful consequences of medical research are. Using the example of war, this article demonstrates various instances of how current medical research could be—or is being—misused and discusses various possible solutions to the dual use dilemma. The main finding is that there needs to be a more concise and international effort to prevent the misuse of research. The raising of awareness in the general medical research community for the topic of DURC is one of the simplest steps that should be undertaken in order to ensure the non-maleficence of global research. Additionally, considering the potentially far-reaching consequences of DURC, it is time to consider the introduction of a new intergovernmental agency to monitor research and establish safeguards in order to cover all fields of research. '\n",
      " \"This research investigates the transformative potential of Mixture of Experts (MoE) and multimodal learning within GenAI, exploring their roles in advancing towards Artificial General Intelligence (AGI). By leveraging a combination of specialized models, MoE addresses scalability and computational limitations, enabling more nuanced and robust modelling across diverse data modalities. The research exploration draws inspiration from pioneering projects like Google's Gemini and OpenAI's anticipated Q* to push the boundaries of AI capabilities. The objectives include exploring the impact of MoE on GenAI, investigating multimodal learning's role in achieving AGI, conducting experiments to demonstrate MoE's effectiveness across various domains, and assessing the influence of AI-generated preprints on the peer-review process. Ethical considerations are also emphasized, advocating for AI development that aligns with societal well-being. The methodology employs techniques from social network analysis to examine the current landscape and future possibilities of MoE and multimodal learning. Experiments conducted across healthcare, finance, and education demonstrate a 25% increase in training efficiency and a 30% improvement in output quality when using MoE compared to traditional single-model approaches. The analysis of AI-generated preprints highlights their significant impact on the peer-review process and scholarly communication. The findings underscore the potential of MoE and multimodal learning to propel GenAI towards AGI. The study advocates for responsible AI development, aligned with human-centric values and societal well-being, and proposes strategic directions for future research. This research promotes the balanced and ethical integration of MoE, multimodality, and AGI in GenAI, fostering equitable distribution and ethical usage of AI technologies.\"\n",
      " '\\n\\n\\n'\n",
      " \"The twenty-first century has witnessed significant advancements in informatics, reshaping our understanding of data processing and accessibility. AI (AI), encompassing techniques such as machine learning (ML), deep learning (DP), and neural networks (NN), is poised to revolutionize medicine. AI holds the capability of analyzing vast amounts of data, extracting meaningful insights, and making accurate predictions, thereby empowering industries to make informed decisions, drive innovation, and enhance efficiency. The landscape of medical AI has evolved significantly, demonstrating expert-level disease detection from medical images and promising breakthroughs across various industries. AI revolutionizes medical practice by leveraging advanced algorithms and machine learning capabilities to improve diagnostics, treatment planning, and overall patient care. However, the deployment of medical AI systems in regular clinical practice still needs to be tapped, presenting complex ethical, technical, and human-centered challenges that must be addressed for successful implementation. While AI algorithms have shown efficacy in retrospective medical investigations, their translation into practical medical settings has been limited, raising concerns about their usability and interaction with healthcare professionals. Moreover, the representativeness of retrospective datasets in real-world medical practice is subject to filtering and cleaning biases. Integrating AI into clinical medicine holds great promise for transforming healthcare delivery, improving patient care, and revolutionizing aspects such as diagnosis, treatment planning, drug discovery, personalized treatment, and medical imaging. With advanced algorithms and machine learning capabilities, AI and robotics in Healthcare can analyze large volumes of medical data, extract meaningful insights, and provide accurate predictions, empowering healthcare professionals to make informed decisions and optimize resource allocation. The availability of extensive clinical, genomics, and digital imaging data, coupled with investments from healthcare institutions and technology giants, underscores the potential of AI in healthcare. This review article explores AI's powerful potential to revolutionize healthcare delivery across multiple domains, emphasizing the need to overcome challenges and harness its transformative capabilities in clinical practice.\"\n",
      " \"While discussing whether digital art shaped by technology is art or not, in recent years, artists have created new, experimental and original works by using AI in their works. For example, while AI was a painter's brush, it became the pen of a writer or poet, became the notes of a composer, and offered an architect the opportunity to create simulation spaces. While transforming technology into art, people who think, question and strive to produce the best have had the opportunity and experience to perceive life and art in a new way. In the digital world we live in, Refik Anadol is an artist who has been thinking about AI technology and has been producing experimental works since 2018. The artist combines the data paintings and installations he creates with architectural structures by transforming each piece of data he handles into color pigments. In this study, it is introduced and discussed how AI, which is the product of digital technology, science and engineering, is handled in an artistic context in Refik Anadol's works.\"\n",
      " 'AbstractHow would it be assessed from an ethical point of view if human wage work were replaced by artificially intelligent systems (AI) in the course of an automation process? An answer to this question has been discussed above all under the aspects of individual well-being and social justice. Although these perspectives are important, in this article, we approach the question from a different perspective: that of leading a meaningful life, as understood in analytical ethics on the basis of the so-called meaning-in-life debate. Our thesis here is that a life without wage work loses specific sources of meaning, but can still be sufficiently meaningful in certain other ways. Our starting point is John Danaher’s claim that ubiquitous automation inevitably leads to an achievement gap. Although we share this diagnosis, we reject his provocative solution according to which game-like virtual realities could be an adequate substitute source of meaning. Subsequently, we outline our own systematic alternative which we regard as a decidedly humanistic perspective. It focuses both on different kinds of social work and on rather passive forms of being related to meaningful contents. Finally, we go into the limits and unresolved points of our argumentation as part of an outlook, but we also try to defend its fundamental persuasiveness against a potential objection.'\n",
      " 'Abstract\\nThe clamor for AI-based applications involving generative models for text and images has fueled wild speculation about the risks and opportunities for society and humanity at large. The potential “existential” threat as a precursor to artificial general intelligence has provoked wide-ranging debates in the public, politics, and the corporate world involving technologists and ethicists from a range of academic disciplines. This thinkpiece proposes a metaperspective to reflect critically and constructively upon the current state of the field of AI ethics, arguing that scholars working in the domain of ethics should focalize conceptual, substantive, and procedural issues as integral elements of an ethical assessment of given technologies and their applications. It suggests that the ethics of GenAI is conceptually still underexplored and overly propagating technological fixes to problems of all kinds (technosolutionism). Procedurally, it needs to be clarified who can, who ought to, and who ultimately will be considered and heard as an expert on AI ethics, a question of relevance for the trust in, and reliance on, AI.'\n",
      " 'AbstractAI (AI) continues to pervade several aspects of healthcare with pace and scale. The need for an ethical framework in AI to address this has long been recognized, but to date most efforts have delivered only high-level principles and value statements. Herein, we explain the need for an ethical framework in healthcare AI, the different moral theories that may serve as its basis, the rationale for why we believe this should be built around virtue ethics, and explore this in the context of five key ethical concerns for the introduction of AI in healthcare. Some existing work has suggested that AI may replace clinicians. We argue to the contrary, that the clinician will not be replaced, nor their role attenuated. Rather, they will be integral to the responsible design, deployment, and regulation of AI in healthcare, acting as the moral exemplar for the virtuous machine. We collate relevant points from the literature and formulate our own to present a coherent argument for the central role of clinicians in ethical AI and propose ideas to help advance efforts to employ ML-based solutions within healthcare. Finally, we highlight the responsibility of not only clinicians, but also data scientists, tech companies, ethicists, and regulators to act virtuously in realising the vision of ethical and accountable AI in healthcare.'\n",
      " 'AbstractDetermining the agency-status of machines and AI has never been more pressing. As we progress into a future where humans and machines more closely co-exist, understanding hallmark features of agency affords us the ability to develop policy and narratives which cater to both humans and machines. This paper maintains that decision-making processes largely underpin agential action, and that in most instances, these processes yield good results in terms of making good choices. However, in some instances, when faced with two (or more) choices, an agent may find themselves with equal reasons to choose either - thus being presented with a tie. This paper argues that in the event of a tie, the ability to create a voluntarist reason is a hallmark feature of agency, and second, that AI, through current tie-breaking mechanisms does not have this ability, and thus fails at this particular feature of agency.'\n",
      " 'This work addresses the problem of recovering lost or damaged satellite image pixels (gaps) caused by sensor processing errors or by natural phenomena like cloud presence. Such errors decrease our ability to monitor regions of interest and significantly increase the average revisit time for all satellites. This paper presents a novel neural system based on conditional deep generative adversarial networks (cGAN) optimized to fill satellite imagery gaps using surrounding pixel values and static high-resolution visual priors. Experimental results show that the proposed system outperforms traditional and neural network baselines. It achieves a normalized least absolute deviations error of ( \\xa0&amp; \\xa0decrease in error compared with the two baselines) and a mean squared error loss of \\xa0( \\xa0&amp; \\xa0decrease in error) over the test set. The model can be deployed within a remote sensing data pipeline to reconstruct missing pixel measurements for near-real-time monitoring and inference purposes, thus empowering policymakers and users to make environmentally informed decisions.'\n",
      " 'In this writing, we will delve into every aspect of the utilization, challenges, as well as ethical considerations in harnessing AI (AI) Technology, with a focus on GenAI, an exceptional language model. AI technology has become an inseparable element in modern life, manifesting across various sectors such as business, healthcare, governance, and several others. The capabilities of AI are capable of driving data-driven decision-making, reducing the potential for human errors, and enhancing process efficiency. However, its impact is also not devoid of potential risks, including data security and the replacement of human roles. To ensure intelligent AI usage, it is imperative to uphold AI ethics, protect user information and privacy, strive to prevent discriminatory practices, and ensure system safety stability. The questions raised in this study revolve around the benefits and challenges of implementing GenAI, optimizing its use, and its role in the realm of education. The mission of this study is to unravel the benefits, challenges, as well as ethical considerations in the utilization of GenAI in the AI era, while ensuring responsible steps in its application.'\n",
      " 'The advent of AI (AI) has significantly transformed various aspects of human life, particularly in information retrieval and assistance. This research presents a comprehensive evaluation of Gemini, previously known as Google Bard, a state-of-the-art AI chatbot developed by Google. Through a meticulous methodology encompassing both qualitative and quantitative approaches, this research aims to assess Gemini’s performance, usability, integration capabilities, ethical implications. Primary data collection methods, including user surveys and interviews, were utilized to gather towards the qualitative feedback on user experiences with Gemini, supplemented by secondary data analysis using tools such as Google Analytics to capture quantitative metrics. Performance evaluation involved benchmarking against other AI chatbots and technical analysis of Gemini’s architecture and training methods. User experience testing examined usability, engagement, and integration with Google Workspace and third-party services. Ethical considerations regarding data privacy, security, and biases in AI-generated content were also addressed, ensuring compliance with major regulations and promoting ethical AI practices. Acknowledging limitations and challenges inherent in the investigative exploration, data analysis was conducted using thematic and statistical methods to derive insights. The results and findings of this research offer valuable insights into the capabilities and limitations of Gemini, providing implications for future AI development, user interaction design, and ethical AI governance. By contributing to the ongoing discourse on AI advancements and their societal impact, this exploration facilitates informed decision-making and lays the groundwork for future research endeavors in the field of AI-driven conversational agents.'\n",
      " 'Everyday, AI (AI) is being increasingly integrated into the teaching and learning process at Russian universities. The high level of quality of feedback from AI tools leads to the spread of AI plagiarism – unauthorized borrowing of GenAI materials – among students. The purpose of this study is to: a) highlight aspects that determine students’ understanding of the issues of compliance with author’s ethics and the problem of plagiarism when interacting with GenAI; b) develop a questionnaire to determine students’ understanding of the issues of compliance with author’s ethics and the problem of AI plagiarism; c) conduct an online survey of university students, analyze and discuss the results obtained. The paper highlights five aspects that determine students’ understanding of the issues of compliance with author’s ethics and the problem of AI plagiarism when completing educational assignments and preparing research texts: a) students’ general understanding of the issues of compliance with author’s ethics and the problem of plagiarism in an academic environment; b) students’ experience of AI tools for educational purposes; c) students’ understanding of the problem of AI plagiarism and attitude towards borrowing materials from GenAI; d) teachers’ actions to prevent AI plagiarism among students; e) the policy of educational organizations regarding student compliance with ethics and AI plagiarism. An online questionnaire was developed to determine the degree to which students understand the issues of compliance with copyright ethics and the problem of AI plagiarism. 1,599 students from 29 universities of the Russian Federation took part in the survey. The results showed that in general, in the Russian student community, plagiarism is a widespread social phenomenon, many types of which are perceived by young people as a norm of academic behavior. Despite the relatively high awareness of students in the field of AI technologies, the extremely rare use by teachers of specialized subject disciplines of AI tools in the educational process I’d the reason for the current low level of spread of AI plagiarism in the academic environment. At the same time, it is necessary to state that students lack a systematic understanding of exactly how they can “legally” use GenAI materials and what exactly will be considered AI plagiarism. According to students, the importance of understanding the issues of compliance with author ethics and the problem of AI plagiarism will depend, on the one hand, on the actions of teachers to explain to students the rules for using GenAI materials, and on the other hand, the presence in universities of a regulatory framework regulating the field and the extent to which students use AI in the educational process.'\n",
      " '<span lang=\"EN-IN\">There is a growing need for an image encryption scheme, for huge amount of social media data or even the medical data to secure the privacy of the patients or the user. This study introduces a ground-breaking deep learning architecture named crypto generative adversarial networks (CryptoGAN), a novel architecture for generating cipher images. This architecture has the ability to generate both encrypted and decrypted images. The CryptoGAN system consists of an initial encryption network, a generative network that verifies the output against the desired domain, and a subsequent decryption phase. The generative adversarial networks (GAN) are utilised as the learning network to generate cipher images. This is achieved by training the neural network using images encrypted from a conventional image encryption scheme such as advanced encryption standards (AES), and learning from the resulting losses. This enhances security measures when dealing with a large dataset of photos. The assessment of the performance metrics of the encrypted image, including entropy, histogram, correlation plot, and vulnerability to assaults, demonstrates that the suggested generative network may get a higher level of security.</span>'\n",
      " 'As GenAI (AI) continues to transform the landscape of education, college faculty must be equipped with the necessary skills to navigate this digital frontier effectively. This position paper argues that instructional development programs for college faculty related to GenAI should focus on three key aspects: enhancing fundamental teaching skills, making AI more familiar to educators, and preventing burnout. These three areas are interconnected and can collectively contribute to the success of AI integration in higher education. In this paper, I present and critique the GenAI output. I found the output to be cogent and potentially useful, but limited by inconsistencies, lack of details, and hallucinations. Although AI output may be useful for guiding practice at a surface level, it could not capture the human voice and attention to detail necessary for scholarship.'\n",
      " 'International students face unique challenges in pursuing higher education in a foreign country. To address these challenges and enhance their academic experience, higher education institutions are increasingly exploring the use of AI (AI) applications. This research essay aims to investigate the impact of AI on the education of international students. Instead of a traditional literature review, it employs a research approach to examine the potential applications of AI and discuss associated concerns. The research paper explores various AI applications, such as personalized learning experiences, adaptive testing, predictive analytics, and chatbots for learning and research. By analyzing the role of AI in education for international students, this research paper sheds light on how AI can improve learning efficiency and provide customized educational support. Additionally, it identifies significant risks and limitations, including privacy concerns, cultural differences, language proficiency, and ethical implications, which must be effectively addressed. The findings contribute to a better understanding of the potential impact of AI on international students’ educational experiences and offer insights into the integration of AI into educational administration and learning processes.'\n",
      " \"AbstractThe introduction of GenAI in November 2022 by OpenAI has stimulated substantial discourse on the implementation of AI (AI) in various domains such as academia, business, and society at large. Although AI has been utilized in numerous areas for several years, the emergence of GenAI (GAI) applications such as GenAI, Jasper, or DALL-E are considered a breakthrough for the acceleration of AI technology due to their ease of use, intuitive interface, and performance. With GAI, it is possible to create a variety of content such as texts, images, audio, code, and even videos. This creates a variety of implications for businesses requiring a deeper examination, including an influence on business model innovation (BMI). Therefore, this study provides a BMI perspective on GAI with two primary contributions: (1) The development of six comprehensive propositions outlining the impact of GAI on businesses, and (2) the discussion of three industry examples, specifically software engineering, healthcare, and financial services. This study employs a qualitative content analysis using a scoping review methodology, drawing from a wide-ranging sample of 513 data points. These include academic publications, company reports, and public information such as press releases, news articles, interviews, and podcasts. The study thus contributes to the growing academic discourse in management research concerning AI's potential impact and offers practical insights into how to utilize this technology to develop new or improve existing business models.\"\n",
      " 'AbstractAs AI (AI) thrives and propagates through modern life, a key question to ask is how to include humans in future AI? Despite human involvement at every stage of the production process from conception and design through to implementation, modern AI is still often criticized for its “black box” characteristics. Sometimes, we do not know what really goes on inside or how and why certain conclusions are met. Future AI will face many dilemmas and ethical issues unforeseen by their creators beyond those commonly discussed (e.g., trolley problems and variants of it) and to which solutions cannot be hard-coded and are often still up for debate. Given the sensitivity of such social and ethical dilemmas and the implications of these for human society at large, when and if our AI make the “wrong” choice we need to understand how they got there in order to make corrections and prevent recurrences. This is particularly true in situations where human livelihoods are at stake (e.g., health, well-being, finance, law) or when major individual or household decisions are taken. Doing so requires opening up the “black box” of AI; especially as they act, interact, and adapt in a human world and how they interact with other AI in this world. In this article, we argue for the application of cognitive architectures for ethical AI. In particular, for their potential contributions to AI transparency, explainability, and accountability. We need to understand how our AI get to the solutions they do, and we should seek to do this on a deeper level in terms of the machine-equivalents of motivations, attitudes, values, and so on. The path to future AI is long and winding but it could arrive faster than we think. In order to harness the positive potential outcomes of AI for humans and society (and avoid the negatives), we need to understand AI more fully in the first place and we expect this will simultaneously contribute towards greater understanding of their human counterparts also.'\n",
      " 'AbstractThis paper explores AI (AI) ethics from an Islamic perspective at a critical time for AI ethical norm-setting. It advocates for a pluralist approach to ethical AI benchmarking. As rapid advancements in AI technologies pose challenges surrounding autonomy, privacy, fairness, and transparency, the prevailing ethical discourse has been predominantly Western or Eurocentric. To address this imbalance, this paper delves into the Islamic ethical traditions to develop a framework that contributes to the global debate on optimal norm setting for designing and using AI technologies.The paper outlines Islamic parameters for ethical values and moral actions in the context of AI\\'s ethical uncertainties. It emphasizes the significance of both textual and non-textual Islamic sources in addressing these uncertainties while placing a strong emphasis on the notion of \"good\" or \"maṣlaḥa\" as a normative guide for AI\\'s ethical evaluation. Defining maṣlaḥa as an ethical state of affairs in harmony with divine will, the paper highlights the coexistence of two interpretations of maṣlaḥa: welfarist/utility-based and duty-based. Islamic jurisprudence allows for arguments supporting ethical choices that prioritize building the technical infrastructure for AI to maximize utility. Conversely, it also supports choices that reject consequential utility calculations as the sole measure of value in determining ethical responses to AI advancements.'\n",
      " 'AbstractSustainability constitutes a focal challenge and objective of our time and requires collaborative efforts. As AI brings forth substantial opportunities for innovations across industry and social contexts, so it provides innovation potential for pursuing sustainability. We argue that (chemical) research and development driven by AI can substantially contribute to sustainability if it is leveraged in an ethical way. Therefore, we propose that the ethical principle explicability combined with (open) research data management systems should accompany AI in research and development to foster sustainability in an equitable and collaborative way.'\n",
      " '<div class=\"page\" title=\"Page 1\"><div class=\"layoutArea\"><div class=\"column\"><p><span lang=\"EN-US\">A countless number of AI applications exist in a wide range of fields. The AI (AI) technology is becoming mature, free powerful libraries enable programmers to generate new apps using a few lines of code. The study identifies the applications that are the most interesting for a developer as far as profit is concerned. Some AI applications related to trading, industry, sales, logistics, games, and personal services have been considered. To select the most promising AI applications, multi criteria methods have been adopted. This brainstorm may be useful to inspire new born start-ups, willing to create viral apps/products. The paper wishes to be informative and light, for further information, a rich selection of publications and books is provided.</span></p></div></div></div>'\n",
      " 'The introduction and rapid evolution of GenAI (genAI) models necessitates a refined understanding for the concept of “intelligence”. The genAI tools are known for its capability to produce complex, creative, and contextually relevant output. Nevertheless, the deployment of genAI models in healthcare should be accompanied appropriate and rigorous performance evaluation tools. In this rapid communication, we emphasizes the urgent need to develop a “GenAIQ Test” as a novel tailored tool for comprehensive benchmarking of genAI models against multiple human-like intelligence attributes. A preliminary framework is proposed in this communication. This framework incorporates miscellaneous performance metrics including accuracy, diversity, novelty, and consistency. These metrics were considered critical in the evaluation of genAI models that might be utilized to generate diagnostic recommendations, treatment plans, and patient interaction suggestions. This communication also highlights the importance of orchestrated collaboration to construct robust and well-annotated benchmarking datasets to capture the complexity of diverse medical scenarios and patient demographics. This communication suggests an approach aiming to ensure that genAI models are effective, equitable, and transparent. To maximize the potential of genAI models in healthcare, it is important to establish rigorous, dynamic standards for its benchmarking. Consequently, this approach can help to improve clinical decision-making with enhancement in patient care, which will enhance the reliability of genAI applications in healthcare.'\n",
      " \"Integrating GenAI into education has sparked a debate regarding its ethical and practical implications. This paper explores the transformative potential of GenAI in various educational contexts, highlighting its ability to generate new data and aid personalized learning. It also addresses concerns about academic integrity and learning quality. This paper advocates for a balanced approach to AI in education by examining different perspectives, including educators and technologists. It suggests that AI can be a valuable educational tool by enhancing student learning and teacher productivity. The discussion extends to AI implementation's potential economic and social challenges and proposes solutions to ensure equal access. Ultimately, the paper concludes that with responsible use, AI can significantly improve educational outcomes and efficiency and offer innovative support for students and educators.\"\n",
      " 'AbstractThe recent wave of GenAI (GenAI) systems like Stable Diffusion or GenAI that can produce images, text and code from human prompts raises controversial issues about creatorship, originality, creativity and copyright. This paper focuses on creatorship: who creates and should be credited with the outputs made with the help of GenAI? There is currently significant moral, legal and regulatory uncertainty around these questions. We develop a novel framework, called CCC (collective-centered creation), that helps resolve this uncertainty. According to CCC, GenAI outputs are created by collectives in the first instance. Claims to creatorship come in degrees and depend on the nature and significance of individual contributions made by the various agents and entities involved, including users, GenAI systems, developers, producers of training data and others. We demonstrate how CCC can help navigate a range of ongoing controversies around the responsible development and deployment of GenAI technologies and help more accurately attribute credit where it is due.'\n",
      " 'BackgroundInstitutional review boards (IRBs) have been criticised for delays in approvals for research proposals due to inadequate or inexperienced IRB staff. AI (AI), particularly large language models (LLMs), has significant potential to assist IRB members in a prompt and efficient reviewing process.MethodsFour LLMs were evaluated on whether they could identify potential ethical issues in seven validated case studies. The LLMs were prompted with queries related to the proposed eligibility criteria of the study participants, vulnerability issues, information to be disclosed in the informed consent document (ICD), risk–benefit assessment and justification of the use of a placebo. Another query was issued to the LLMs to generate ICDs for these case scenarios.ResultsAll four LLMs were able to provide answers to the queries related to all seven cases. In general, the responses were homogeneous with respect to most elements. LLMs performed suboptimally in identifying the suitability of the placebo arm, risk mitigation strategies and potential risks to study participants in certain case studies with a single prompt. However, multiple prompts led to better outputs in all of these domains. Each of the LLMs included all of the fundamental elements of the ICD for all case scenarios. Use of jargon, understatement of benefits and failure to state potential risks were the key observations in the AI-generated ICD.ConclusionIt is likely that LLMs can enhance the identification of potential ethical issues in clinical research, and they can be used as an adjunct tool to prescreen research proposals and enhance the efficiency of an IRB.'\n",
      " \"The article\\xa0Mapping GenAI (GAI's Exciting Future: From Gemini to Q* and Beyond\\xa0has been retracted at the request of EAI's Research Integrity Committee. The paper is being removed on the grounds of misrepresentation of institutional affiliation and plagiarism.\\xa0\"\n",
      " 'AI (AI), particularly machine learning, has made significant strides in the past decade. Due to the widely applicable nature of this technology, the emergence of increasingly intelligent machines is poised to transform today’s society. Recently, the rate of AI development has aroused significant concerns due to the lack of guiding policy and regulation. Thus, it is integral for the public to recognize the technology and make informed choices regarding the future of AI. This paper serves to acquaint the layperson and other stakeholders involved in AI development with the current progress of AI and the ethical concerns that must be addressed before significant advancements. The subject of discussion is narrowed down to three fields of AI’s most prominent use: (1) the internet; (2) the automotive industry; and (3) the healthcare industry. For each sector, the foundation of the domain-specific AI technique is introduced, the benefits and ethical ramifications are discussed, and a final cost-benefit analysis is provided.'\n",
      " 'The 1st AAAI/ACM Conference on AI, Ethics, and Society (AIES-18) was held February 13, 2018 at the Hilton New Orleans Riverside, in New Orleans, Louisiana. The event was held just before AAAI in order to highlight the overlap of the two conference and logistical support for the conference was provided by AAAI. By attendance measures the conference was a resounding success with a sold out registration of over 300 people. The conference brought together program chairs from the four major focal areas: AI and jobs: Jason Furman (Harvard University); AI and law: Gary Marchant (Arizona State University); AI and philosophy: Huw Price (Cambridge University); and AI: Francesca Rossi (IBM and University of Padova). All the paper from the conference are available for download at the conference website: http://www.aies-conference.com/'\n",
      " \" I argue here that Christian ethical responses to AI (AI) ought to take on, largely, two different approaches. The first considers proximate ethical concerns related to AI. This ethical approach most often considers more immediate personal and socio-political repercussions and the kind of impact that is occurring now or in the very near future. Proximate ethics of this type includes discussion about fairness, accountability, sustainability and transparency. The second concerns ultimate ethics which focuses on the longer-term impact and implications of AI. Examples of this type might include issues of uniqueness, deep societal transformation and inequality, changes to personal character and even the role AI might have in God's ultimate economy of creation and grace. My contention is that the Christian church needs to attend to both approaches to AI and that when it focuses too myopically on one at the expense of the other it often eclipses the entire witness of the church in our technological society. \"\n",
      " \"AI encompasses a wide range of approaches, methodologies, and techniques aimed at mimicking human intelligence in machines. In recent times, the concepts of GenAI (AI), Super AI, and Narrow AI have attracted considerable attention. Undoubtedly, the success of GenAI in capturing all attention has played a significant role in this. AI technology has a profound impact on all sectors, and sector representatives are striving to adapt to this technology more quickly. It is projected that AI could generate an economic size of 13 trillion American dollars by 2030. Developments in AI technologies undoubtedly lead to significant improvements in the functioning of public institutions and access for citizens. AI has the potential to be used in many public services, including security and defense, healthcare services, education, transportation and infrastructure, environmental and natural resource management, law and justice systems, among others. Therefore, evaluating the types of AI, Narrow AI applications, and chatbots for public use is seen as highly beneficial from the perspective of public administration and the public sector. In our study, the topics of super AI, GenAI, narrow AI, and chatbots have been extensively evaluated within the context of the public sector and public administration. Utilizing findings from both Turkish and English literature reviews, the importance and potential impacts of AI within the public sector, along with current trends, have been comprehensively assessed. This research delves into the concepts of AI and its subsets—super AI, GenAI, narrow AI, and chatbots—within the general framework of the public sector. China and the United States are pioneering and leading countries in terms of investment. Although the U.S. stands out in many areas regarding investment, China's integration of AI with national strategies and its policies indicate that it may play a more dominant role in the future. There are four main implementation areas of AI in the public sector: efficiency and automation, service delivery, data-driven governance, and ethical and regulatory challenges. A review of the literature reveals that the ethical, legal, and social implications of implementing AI in the public sector require more careful consideration. The study makes a significant contribution to the field of AI discussions in public administration and the public sector, providing a comprehensive assessment of current discussions on AI in the literature.\"\n",
      " \"In the dynamic field of renewable and sustainable energy, AI (AI) integration has emerged as a crucial catalyst for enhancing efficiency, cost reduction, and addressing multifaceted challenges. This work delves into the performance and contributions of GenAI, a prominent representative of large AI language models, within the context of renewable and sustainable energy. The research endeavors to explore GenAI's efficacy and role across a diverse spectrum of renewable energy aspects, spanning solar energy, wind energy, biomass energy, hydropower, geothermal energy, energy storage, grid integration, energy efficiency, materials science, policy, economics, environmental impact, energy accessibility, and advanced biofuels. The investigation commences with solar energy, where GenAI showcases impressive capabilities in data analysis, modeling, and forecasting. It facilitates solar panel placement optimization, energy production prediction, and overall efficiency enhancement. Likewise, in the realm of wind energy, GenAI proves invaluable for tasks such as wind turbine control, maintenance scheduling, and wind speed prediction. In biomass energy, GenAI aids in feedstock selection, process optimization, and emissions reduction. In the hydropower sector, it supports reservoir management and river flow prediction, thereby optimizing energy output. Geothermal energy benefits from GenAI's geological analysis, reservoir modeling, and exploration strategies. Energy storage solutions are indispensable for grid stability, and GenAI contributes to the advancement of cutting-edge battery technologies, augmenting energy storage capacity and lifespan. Furthermore, GenAI's insights foster the evolution of smart grids, ensuring efficient energy distribution and effective demand management. Additionally, GenAI provides invaluable insights into policy and economics, offering recommendations for incentivizing the adoption of renewable energy sources while considering environmental impact and sustainability. It also contributes to the advancement of tidal and wave energy technologies, as well as the development of advanced biofuels. The outcomes of this research paper underscore the potential of AI and GenAI in shaping the future of renewable energy, expediting progress toward a sustainable energy ecosystem.\"\n",
      " 'AbstractWhile the demand for ethical AI (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.'\n",
      " 'The arrival of GenAI (AI) is fundamentally different from prior technologies used in educational settings. Educators and researchers of online, blended, and in-person learning are still coming to grips with possible applications of AI in the learning experience with existing technologies; let alone understanding the potential consequences that future developments in AI will produce. Despite potential risks, AI may revolutionize previous models of teaching and learning and perhaps create opportunities to realize progressive educational goals. Given the longstanding tradition of philosophy to examine questions surrounding ethics, ontology, technology, and education, the purpose of this critical reflection paper is to draw from prominent philosophers across these disciplines to address the question: how can AI be employed in future educational contexts in a humanizing and ethical manner? Drawing from the work of Gunther Anders, Michel Foucault, Paolo Freire, Benjamin Bloom, and Hannah Arendt, we propose a framework for assessing the use and ethics of AI in modern education contexts regarding human versus AI generated textual and multimodal content, and the broader political, social, and cultural implications. We conclude with applied examples of the framework and implications for future research and practice.'\n",
      " 'As AI (AI) and content production become increasingly intertwined, GenAI models are continually evolving, yielding increasingly significant technological dividends. GenAI has been widely applied in the realm of content creation, but its \\npractical application is hampered by a number of challenges, including data scarcity, model instability, and inconsistent content styles. To address these issues, improvements can be made by accumulating data, optimizing models, and refining creative styles. With the advancement of \\ntechnology and the improvement of related industry policies, GenAI will play an increasingly important role in the content production \\nfield in the future, achieving deeper fusion.'\n",
      " \"This paper explores the transformative potential of AI (AI) and GenAI in reshaping the title industry, particularly in mortgage origination. By analyzing historical challenges, including the subprime mortgage crisis and the inefficiencies of traditional title systems, juxtaposed with modern AI-driven solutions, we highlight the paradigm shift towards technology-centric operations. We examine AI's role in addressing issues such as lost chains of title, complex legal frameworks, and outdated land title recording practices. The research emphasizes AI's capacity for streamlining processes, enhancing accuracy in title searches, and mitigating fraud risks. This study not only delves into AI's operational impact but also considers legal, ethical, and data security implications, underscoring the need for balanced and informed integration of AI technologies in the title industry. The findings suggest a future where AI and GenAI fundamentally alter traditional practices, offering increased efficiency, reliability, and transparency in mortgage origination processes.\"\n",
      " 'Abstract\\nBackground\\nIn an effort to improve the quality of medical care, the philosophy of patient-centered care has become integrated into almost every aspect of the medical community. Despite its widespread acceptance, among patients and practitioners, there are concerns that rapid advancements in AI may threaten elements of patient-centered care, such as personal relationships with care providers and patient-driven choices. This study explores the extent to which patients are confident in and comfortable with the use of these technologies when it comes to their own individual care and identifies areas that may align with or threaten elements of patient-centered care.\\n\\nMethods\\nAn exploratory, mixed-method approach was used to analyze survey data from 600 US-based adults in the State of Florida. The survey was administered through a leading market research provider (August 10–21, 2023), and responses were collected to be representative of the state’s population based on age, gender, race/ethnicity, and political affiliation.\\n\\nResults\\nRespondents were more comfortable with the use of AI in health-related tasks that were not associated with doctor-patient relationships, such as scheduling patient appointments or follow-ups (84.2%). Fear of losing the ‘human touch’ associated with doctors was a common theme within qualitative coding, suggesting a potential conflict between the implementation of AI and patient-centered care. In addition, decision self-efficacy was associated with higher levels of comfort with AI, but there were also concerns about losing decision-making control, workforce changes, and cost concerns. A small majority of participants mentioned that AI could be useful for doctors and lead to more equitable care but only when used within limits.\\n\\nConclusion\\nThe application of AI in medical care is rapidly advancing, but oversight, regulation, and guidance addressing critical aspects of patient-centered care are lacking. While there is no evidence that AI will undermine patient-physician relationships at this time, there is concern on the part of patients regarding the application of AI within medical care and specifically as it relates to their interaction with physicians. Medical guidance on incorporating AI while adhering to the principles of patient-centered care is needed to clarify how AI will augment medical care.\\n'\n",
      " '<span lang=\"EN-US\">There are a wide range of potential uses for both the forward (generating face drawings from actual images) and backward (generating photos from synthetic face sketches). However, photo/sketch synthesis is still a difficult problem to solve because of the distinct differences between photos and sketches. Existing frameworks often struggle to acquire a strong mapping among the geometry of drawing and its corresponding photo-realistic pictures because of the little amount of paired sketch-photo training data available. In this study, we adopt the perspective that this is an image-to-image translation issue and investigate the usage of the well-known enhanced pix2pix generative adversarial networks (GANs) to generate high-quality photo-realistic pictures from drawings; we make use of three distinct datasets. While recent GAN-based approaches have shown promise in image translation, they still struggle to produce high-resolution, photorealistic pictures. This technique uses supervised learning to train the generator\\'s hidden layers to produce low-resolution pictures initially, then uses the network\\'s implicit refinement to produce high-resolution images. Extensive tests on three sketch-photo datasets (two publicly accessible and one we produced) are used to evaluate. Our solution outperforms existing image translation techniques by producing more photorealistic visuals with a peak signal-to-noise ratio of 59.85% and pixel accuracy of 82.7%.\\xa0</span>'\n",
      " 'AbstractOur interdisciplinary study examines the effectiveness of US law in addressing the complex challenges posed by GenAI systems to fundamental human values, including physical and mental well-being, privacy, autonomy, diversity, and equity. Through the analysis of diverse hypothetical scenarios developed in collaboration with experts, we identified significant shortcomings and ambiguities within the existing legal protections. Constitutional and civil rights law currently struggles to hold AI companies responsible for AI-assisted discriminatory outputs. Moreover, even without considering the liability shield provided by Section 230, existing liability laws may not effectively remedy unintentional and intangible harms caused by AI systems. Demonstrating causal links for liability claims such as defamation or product liability proves exceptionally difficult due to the intricate and opaque nature of these systems. To effectively address these unique and evolving risks posed by GenAI, we propose a “Responsible AI Legal Framework”  that adapts to recognize new threats and utilizes a multi-pronged approach. This framework would\\xa0enshrine fundamental values in legal frameworks, establish comprehensive safety guidelines, and implement liability models tailored to the complexities of human-AI interactions. By proactively mitigating unforeseen harms like mental health impacts and privacy breaches, this framework aims to create a legal landscape capable of navigating the exciting\\xa0yet precarious future brought forth by GenAI technologies.'\n",
      " 'Phishing attacks pose a constant threat to online security, necessitating the development of efficient tools for identifying malicious URLs. In this article, we propose a novel approach to detect phishing URLs employing a generative adversarial network (GAN) with a variational autoencoder (VAE) as the generator and a transformer model with self-attention as the discriminator. The VAE generator is trained to produce synthetic URLs. In contrast, the transformer discriminator uses its self-attention mechanism to focus on the different parts of the input URLs to extract crucial features. Our model uses adversarial training to distinguish between legitimate and phishing URLs. We evaluate the effectiveness of the proposed method using a large set of one million URLs that incorporate both authentic and phishing URLs. Experimental results show that our model is effective, with an impressive accuracy of 97.75%, outperforming the baseline models. This study significantly improves online security by offering a novel and highly accurate phishing URL detection method.'\n",
      " 'Defense and security organizations depend upon science and technology to meet operational needs, predict and counter threats, and meet increasingly complex demands of modern warfare. AI and robotics could provide solutions to a wide range of military gaps and deficiencies. At the same time, the unique and rapidly evolving nature of AI and robotics challenges existing polices, regulations, and values, and introduces complex ethical issues that might impede their development, evaluation, and use by the Canadian Armed Forces (CAF). Early consideration of potential ethical issues raised by military use of emerging AI and robotics technologies in development is critical to their effective implementation. This article presents an ethics assessment framework for emerging AI and robotics technologies. It is designed to help technology developers, policymakers, decision makers, and other stakeholders identify and broadly consider potential ethical issues that might arise with the military use and integration of emerging AI and robotics technologies of interest. We also provide a contextual environment for our framework, as well as an example of how our framework can be applied to a specific technology. Finally, we briefly identify and address several pervasive issues that arose during our research.'\n",
      " 'AI (AI), like many revolutionary technologies in human history, will have a profound impact on societies. From this viewpoint, we analyze the combined effects of AI to raise important questions about the future form and function of cities. Combining knowledge from computer science, urban planning, and economics while reflecting on academic and business perspectives, we propose that the future of cities is far from being a determined one and cities may evolve into ghost towns if the deployment of AI is not carefully controlled. This viewpoint presents a fundamentally different argument, because it expresses a real concern over the future of cities in contrast to the many publications who exclusively assume city populations will increase predicated on the neoliberal urban growth paradigm that has for centuries attracted humans to cities in search of work.'\n",
      " 'The travel industry has been undergoing a revolution for a few years now due to rapid technological advancements. This article assesses the application of GenAI in travel planning, focusing on itinerary generation, low-fare finding, no-crowd planning, and route optimization. The study employed a quantitative methodology with 10 participants using an AI-powered website. Structured surveys gathered feedback on usability, efficiency, and satisfaction. Users were very satisfied with the AI-enhanced website, especially in terms of navigation, personalized itineraries, price accuracy, and data security. However, areas for improvement in time efficiency were indicated. The study concludes that GenAI significantly improves trip planning, offering convenience, personalization, and efficiency. Future work should focus on refining AI features and exploring additional applications to further optimize travel planning.'\n",
      " 'AI in Education (AIEd) offers advanced tools that can personalize learning experiences and enhance teachers’ research capabilities. This paper explores the beliefs of 425 university teachers regarding the integration of GenAI in educational settings, utilizing the UTAUT2 model to predict their acceptance and usage patterns through the Partial Least Squares (PLS) method. The findings indicate that performance expectations, effort expectancy, social influence, facilitating conditions, and hedonic motivation all positively impact the intention and behavior related to the use of AIEd. Notably, the study reveals that teachers with constructivist pedagogical beliefs are more inclined to adopt AIEd, underscoring the significance of considering teachers’ attitudes and motivations for the effective integration of technology in education. This research provides valuable insights into the factors influencing teachers’ decisions to embrace AIEd, thereby contributing to a deeper understanding of technology integration in educational contexts. Moreover, the study’s results emphasize the critical role of teachers’ pedagogical orientations in their acceptance and utilization of AI technologies. Constructivist educators, who emphasize student-centered learning and active engagement, are shown to be more receptive to incorporating AIEd tools compared to their transmissive counterparts, who focus on direct instruction and information dissemination. This distinction highlights the need for tailored professional development programs that address the specific beliefs and needs of different teaching philosophies. Furthermore, the study’s comprehensive approach, considering various dimensions of the UTAUT2 model, offers a robust framework for analyzing technology acceptance in education.'\n",
      " 'Author Arthur C. Clarke famously argued that in science fiction literature “any sufficiently advanced technology is indistinguishable from magic” (Clarke). On 30 November 2022, technology company OpenAI publicly released their Large Language Model (LLM)-based chatbot ChatGPT (Chat Generative Pre-Trained Transformer), and instantly it was hailed as world-changing. Initial media stories about ChatGPT highlighted the speed with which it generated new material as evidence that this tool might be both genuinely creative and actually intelligent, in both exciting and disturbing ways. Indeed, ChatGPT is part of a larger pool of Generative Artificial Intelligence (AI) tools that can very quickly generate seemingly novel outputs in a variety of media formats based on text prompts written by users. Yet, claims that AI has become sentient, or has even reached a recognisable level of general intelligence, remain in the realm of science fiction, for now at least (Leaver). That has not stopped technology companies, scientists, and others from suggesting that super-smart AI is just around the corner. Exemplifying this, the same people creating generative AI are also vocal signatories of public letters that ostensibly call for a temporary halt in AI development, but these letters are simultaneously feeding the myth that these tools are so powerful that they are the early form of imminent super-intelligent machines. For many people, the combination of AI technologies and media hype means generative AIs are basically magical insomuch as their workings seem impenetrable, and their existence could ostensibly change the world. This article explores how the hype around ChatGPT and generative AI was deployed across the first six months of 2023, and how these technologies were positioned as either utopian or dystopian, always seemingly magical, but never banal. We look at some initial responses to generative AI, ranging from schools in Australia to picket lines in Hollywood. We offer a critique of the utopian/dystopian binary positioning of generative AI, aligning with critics who rightly argue that focussing on these extremes displaces the more grounded and immediate challenges generative AI bring that need urgent answers. Finally, we loop back to the role of schools and educators in repositioning generative AI as something to be tested, examined, scrutinised, and played with both to ground understandings of generative AI, while also preparing today’s students for a future where these tools will be part of their work and cultural landscapes.'\n",
      " 'GenAI (AI) holds significant potential for revolutionizing the Architecture, Engineering, and Construction (AEC) industry by automating complex tasks such as construction scheduling, hazard recognition, resource leveling, information retrieval from BIM, etc. However, realizing this potential requires a strategic approach to ensure effective utilization and maximum benefit. This paper presents guidelines for prompt design and engineering to elicit desired responses from GenAI, a GenAI tool, in AEC applications. Key steps include understanding user intent, leveraging model capabilities, and optimizing prompt structures. By following these guidelines, stakeholders in the AEC industry can harness the power of GenAI to improve construction scheduling processes, increase project efficiency, and ultimately drive innovation and growth in the industry. Several illustrative examples on construction scheduling and hazard recognition are provided to demonstrate the methodology proposed in this research. It is concluded that GenAI, when effectively utilized, significantly enhances project scheduling and hazard recognition capability in the AEC industry with minimal error.'\n",
      " 'AbstractThis paper explores the status of AI (AI) for healthcare research in Africa. The aim was to use bibliometric and thematic analysis methods to determine the publication counts, leading authors, top journals and publishers, most active institutions and countries, most cited institutions, funding bodies, top subject areas, co-occurrence of keywords and co-authorship. Bibliographic data were collected on April 9 2022, through the Lens database, based on the critical areas of authorship studies, such as authorship pattern, number of authors, etc. The findings showed that several channels were used to disseminate the publications, including articles, conference papers, reviews, and others. Publications on computer science topped the list of documented subject categories. The Annals of Tropical Medicine and Public Health is the top journal, where articles on AI have been published. One of the top nations that published AI research was the United Kingdom. With 143 publications, Harvard University was the higher education institution that produced the most in terms of affiliation. It was discovered that the Medical Research Council was one of the funding organizations that supported research, resulting in the publication of articles in AI. By summarizing the current research themes and trends, this work serves as a valuable resource for researchers, practitioners, and funding organizations interested in AI for healthcare research in Africa.'\n",
      " 'Abstract\\nUrbanAI Art is based on the concept of artist-driven AI art that acknowledges AI’s (AI’s) potential in art. Artist-driven AI art is artist oriented, concept oriented, and unique. Artists use their work as the input, and they manage the overall concept and production of the artwork. Each AI art piece is distinctive and original. UrbanAI Art, by Jussi Lahtinen, is based on his Metropolis series (2015–), with code developed together with a programmer. UrbanAI Art was released in Spring 2023, and it has been screened at major events in Europe since then.'\n",
      " \"AbstractThe tremendous rise of GenAI has reached every part of society—including the news environment. There are many concerns about the individual and societal impact of the increasing use of GenAI, including issues such as disinformation and misinformation, discrimination, and the promotion of social tensions. However, research on anticipating the impact of GenAI is still in its infancy and mostly limited to the views of technology developers and/or researchers. In this paper, we aim to broaden the perspective and capture the expectations of three stakeholder groups (news consumers; technology developers; content creators) about the potential negative impacts of GenAI, as well as mitigation strategies to address these. Methodologically, we apply scenario-writing and use participatory foresight in the context of a survey (n\\u2009=\\u2009119) to delve into cognitively diverse imaginations of the future. We qualitatively analyze the scenarios using thematic analysis to systematically map potential impacts of GenAI on the news environment, potential mitigation strategies, and the role of stakeholders in causing and mitigating these impacts. In addition, we measure respondents' opinions on a specific mitigation strategy, namely transparency obligations as suggested in Article 52 of the draft EU AI Act. We compare the results across different stakeholder groups and elaborate on different expected impacts across these groups. We conclude by discussing the usefulness of scenario-writing and participatory foresight as a toolbox for GenAI impact assessment.\"\n",
      " \"This paper explores recent advancements and implications of AI (AI) technology, with a specific focus on Large Language Models (LLMs) like GenAI 3.5, within the realm of higher education. Through a review of the academic literature, this paper highlights the unprecedented growth of these models and their wide-reaching impact across various sectors. The discussion sheds light on the complex issues and potential benefits presented by LLMs, providing a overview of the field's current state.\\nIn the context of higher education, the paper explores the challenges and opportunities posed by LLMs. These include issues related to educational assessment, potential threats to academic integrity, privacy concerns, the propagation of misinformation, EDI aspects, copyright concerns and inherent biases within the models. While these challenges are multifaceted and significant, the paper emphasizes the availability of strategies to address them effectively and facilitate the successful adoption of LLMs in educational settings.\\nFurthermore, the paper recognises the potential opportunities to transform higher education. It emphasises the need to update assessment policies, develop guidelines for staff and students, scaffold AI skills development, and find ways to leverage technology in the classroom. By proactively pursuing these steps, higher education institutions (HEIs) can harness the full potential of LLMs while managing their adoption responsibly.\\nIn conclusion, the paper urges HEIs to allocate resources to handle the adoption of LLMs effectively. This includes ensuring staff AI readiness and taking steps to modify their study programmes to align with the evolving educational landscape influenced by emerging technologies.\"\n",
      " \" It's impossible to escape GenAI and other large language model AIs that are promising to disrupt everything from homework to hacking. GenAI has a lot to offer organisations looking to find efficiencies in their business processes. But it has to be approached intelligently and with a full understanding of the potential security pitfalls, not least to your data security. \"\n",
      " 'This white paper documents the consensus opinion of the AI Surgery (AIS) task force on AI (AI) Ethics and the AIS Editorial Board Study Group on Ethics on the ethical considerations and current trustworthiness of AI and autonomous actions in surgery. The ethics were divided into 6 topics defined by the Task Force: Reliability of robotic and AI systems; Respect for privacy and sensitive data; Use of complete and representative (i.e., unbiased) data; Transparencies and uncertainties in AI; Fairness: are we exacerbating inequalities in access to healthcare?; Technology as an equalizer in surgical education. Task Force members were asked to research a topic, draft a section, and come up with several potential consensus statements. These were voted on by members of the Task Force and the Study Group, and all proposals that received > 75 % agreement were adopted and included in the White Paper.'\n",
      " \"Abstract\\nBackground\\nPrecision medicine, targeting treatments to individual genetic and clinical profiles, faces challenges in data collection, costs, and privacy. GenAI offers a promising solution by creating realistic, privacy-preserving patient data, potentially revolutionizing patient-centric healthcare.\\n\\nObjective\\nThis review examines the role of deep generative models (DGMs) in clinical informatics, medical imaging, bioinformatics, and early diagnostics, showcasing their impact on precision medicine.\\n\\nMethods\\nAdhering to PRISMA guidelines, the review analyzes studies from databases such as Scopus and PubMed, focusing on AI's impact in precision medicine and DGMs' applications in synthetic data generation.\\n\\nResults\\nDGMs, particularly Generative Adversarial Networks (GANs), have improved synthetic data generation, enhancing accuracy and privacy. However, limitations exist, especially in the accuracy of foundation models like Large Language Models (LLMs) in digital diagnostics.\\n\\nConclusion\\nOvercoming data scarcity and ensuring realistic, privacy-safe synthetic data generation are crucial for advancing personalized medicine. Further development of LLMs is essential for improving diagnostic precision. The application of GenAI in personalized medicine is emerging, highlighting the need for more interdisciplinary research to advance this field.\\n\"\n",
      " \"PurposeThe research aims to explore the dynamic relationship between digital service innovation (DSI), AI (AI) and business performance (BPer) in service-based models with a focus on how AI-enhanced insights from service use and customer feedback can strengthen business strategies. The aims are to show that DSI and AI are key to driving growth and efficiency in the digital economy and to underscore AI’s role in utilizing contextual data to improve decision-making and business outcomes.Design/methodology/approachThe study uses general structural equation modeling to analyze Spanish manufacturing firms, focusing on medium-sized enterprises and including both business-to-business and business-to-consumer orientations. Data are drawn from the Iberian Balance Analysis System [Sistema de Análisis de Balances Ibéricos (SABI)] database, complemented by a Qualtrics survey to assess the integration of AI in decision-making processes. The methodology is designed to evaluate the interplay between DSI, AI and BPer, with the aim of identifying actionable insights for service-based business orientations.Findings The study clarifies the relationships between DSI, AI and BPer, providing new theoretical and empirical insights. The findings confirm DSI's direct positive impact on performance and suggest AI’s nuanced mediating role, emphasizing the need for strategic DSI-AI integration in manufacturing firms for enhanced performance.Research limitations/implications The research explains the synergistic bond between DSI and AI in boosting BPer and discovering how by-product data can be transformed into strategic insights.Practical implications This study advises manufacturing sector leaders to integrate DSI and AI for enhanced performance and competitive advantage, emphasizing the value of high-quality, contextual data for AI learning and decision-making.Originality/value Researchers will observe that the study confirms the positive impact of DSI on BPer, while also highlighting the significant role of AI in enhancing this effect.\"\n",
      " 'AbstractPoor self-regulation has been linked to various behaviors that contribute to pressing societal issues, including rising household debt, inefficient use of sustainable resources, and increasing healthcare demands. In light of this observation, the prospect of individuals receiving automated, tailored support by “e-coaching systems” to scaffold and improve their self-regulation is thought to hold promise for making society-wide progress in addressing such issues. Though there may be legitimate reasons for promoting the use of such systems, and individuals might welcome the support, our aim in the present article is to contribute to the ethics of e-coaching by showing how societal pressures towards the widespread adoption of automated e-coaching systems raise concerns in relation to three distinct aspects of social justice. We argue that societal inequalities may be introduced or exacerbated by (1) unequal access to the technologies, (2) unequally distributed restrictions to liberty and subjection to coercion, and (3) the potentially disparate impact of the use of e-coaching technologies on (self-)stigmatizing perceptions of competence. The article offers a research agenda for studying and addressing these concerns.'\n",
      " 'AbstractThis paper considers ethical concerns with regard to replacing human relations with humanoid robots. Many have written about the impact that certain types of relations with robots may have on us, and why we should be concerned about robots replacing human relations. There has, however, been no consideration of this issue from an African philosophical perspective. Ubuntu philosophy provides a novel perspective on how relations with robots may impact our own moral character and moral development. This paper first discusses what humanoid robots are, why and how humans tend to anthropomorphise them, and what the literature says about robots crowding out human relations. It then explains the ideal of becoming “fully human”, which pertains to being particularly moral in character. In ubuntu philosophy, we are not only biologically human, but must strive to become better, more moral versions of ourselves, to become fully human. We can become fully human by having other regarding traits or characteristics within the context of interdependent, or humane, relationships (such as by exhibiting human equality, reciprocity, or solidarity). This concept of becoming fully human is important in ubuntu philosophy. Having explained that idea, the main argument of the paper is then put forward: that treating humanoid robots as if they are human is morally concerning if they crowd out human relations, because such relations prevent us from becoming fully human. This is because we cannot experience human equality, solidarity, and reciprocity with robots, which can be seen to characterise interdependent, or humane, relations with human beings.'\n",
      " '\\xa0\\r\\nMarwan Omar\\r\\n1Illinois Institute of Technology\\r\\n\\xa0Email:\\xa0 momar3@iit.edu\\xa0 \\r\\n\\xa0\\r\\nAbstract\\r\\nThe rapid advancement of AI (AI), particularly in the domain of generative models, has led to impressive achievements in content creation and natural language processing. However, these models are inherently limited by their reliance on pattern recognition and lack of true understanding. In contrast, Objective-Driven AI offers a promising alternative by focusing on goal-oriented behavior, causal reasoning, and the development of world models. This paper explores the limitations of GenAI, highlighting its inability to grasp context, causality, and ethical considerations. It then presents the concept of Objective-Driven AI, emphasizing its potential to operate effectively in complex, real-world environments where understanding and reasoning are critical. The paper concludes with a discussion of future research directions, including advanced world modeling techniques, ethical AI, and robustness against adversarial attacks, which are essential for the further development of Objective-Driven AI systems.\\r\\nKeywords\\r\\nObjective-Driven AI, GenAI, Causal Reasoning, World Modeling, Ethical AI, AI, Adversarial Attacks, Machine Learning, Autonomous Systems'\n",
      " 'AbstractAI (AI) is being increasingly applied in healthcare. The expansion of AI in healthcare necessitates AI-related ethical issues to be studied and addressed. This systematic scoping review was conducted to identify the ethical issues of AI application in healthcare, to highlight gaps, and to propose steps to move towards an evidence-informed approach for addressing them. A systematic search was conducted to retrieve all articles examining the ethical aspects of AI application in healthcare from Medline (PubMed) and Embase (OVID), published between 2010 and July 21, 2020. The search terms were “AI” or “machine learning” or “deep learning” in combination with “ethics” or “bioethics”. The studies were selected utilizing a PRISMA flowchart and predefined inclusion criteria. Ethical principles of respect for human autonomy, prevention of harm, fairness, explicability, and privacy were charted. The search yielded 2166 articles, of which 18 articles were selected for data charting on the basis of the predefined inclusion criteria. The focus of many articles was a general discussion about ethics and AI. Nevertheless, there was limited examination of ethical principles in terms of consideration for design or deployment of AI in most retrieved studies. In the few instances where ethical principles were considered, fairness, preservation of human autonomy, explicability and privacy were equally discussed. The principle of prevention of harm was the least explored topic. Practical tools for testing and upholding ethical requirements across the lifecycle of AI-based technologies are largely absent from the body of reported evidence. In addition, the perspective of different stakeholders is largely missing.'\n",
      " 'Contact centers in healthcare facilities face a myriad of challenges. Amongst them are the high workload due to numerous patient inquiries, the inability to respond to queries fast, the inability to effectively collect and process patient data, and increasing operational costs to meet the growing workload. GenAI is an emerging technology that promises to address these issues. The technology can automate engagements hence reducing workloads and improving response time to inquiries. It also reduces operational costs and offers big data benefits. This document discusses the applications and benefits of GenAI in healthcare contact centers.'\n",
      " '<span id=\"docs-internal-guid-8df40bfb-7fff-fcb8-b52f-54f39570d649\"><span>HPCC systems, an open source cluster computing platform for big data analytics consists of generalized neural network bundle with a wide variety of features which can be used for various neural network applications. To enhance the functionality of the bundle, this paper proposes the design and development of generative adversarial networks (GANs) on HPCC systems platform using ECL, a declarative language on which HPCC systems works. GANs have been developed on the HPCC platform by defining the generator and discriminator models separately, and training them by batches in the same epoch. In order to make sure that they train as adversaries, a certain weights transfer methodology was implemented. MNIST dataset which has been used to test the proposed approach has provided satisfactory results. The results obtained were unique images very similar to the MNIST dataset, as it were expected.</span></span>'\n",
      " 'This study examines whether AI can address the loneliness experienced by modern individuals, based on a review of relevant literature. While ad-vancements in technology have reduced physical distances, the COVID-19 pandemic has exacerbated emotional distances between people, leading to weakened emotional support networks. The intensification of urbaniza-tion and industrialization has not only diminished familial bonds but also reduced emotional collaboration between individuals and communities, creating a space for AI technologies to emerge as a potential solution to alleviate loneliness. AI has shown promise not only in providing emotional support but also in contributing to education, healthcare, and daily life. This study closely examines the relationship between human-AI interactions and the mitigation of loneliness, while also exploring the limitations of these interactions. Furthermore, the ethical implications of AI technology are con-sidered, assessing the potential risks and opportunities within human-AI interactions.'\n",
      " \"The Defense Advanced Research Project Agency's (DARPA) mission is to make pivotal investments leading to research breakthroughs that support national security. DARPA AI (AI) programs have emphasized the need for machines to perceive and interact with the world around them; to frame problems and to arrive at solutions and decisions based on reasoning; to implement those decisions, perhaps through consultation with a human or another machine; to learn; to explain the rationale for decisions; to adhere to rules of ethical behavior defined for humans; to adapt to dynamic environments; and, to do all of this in real‐time. In short, DARPA has always been interested in AI frameworks that integrate AI and computer science technologies, and the application of those frameworks to DARPA‐hard problems. In this article, we describe the significant role that DARPA has played in the establishment of AI, and introduce six articles that explore DARPA's Three Waves of AI.\"\n",
      " 'AbstractAI and edge devices have been used at an increased rate in managing the COVID-19 pandemic. In this article we review the lessons learned from COVID-19 to postulate possible solutions for a Disease X event. The overall purpose of the study and the research problems investigated is the integration of AI\\xa0function in digital healthcare systems. The basic design of the study includes a systematic state-of-the-art review, followed by an evaluation of different approaches to managing global pandemics. The study design then engages with constructing a new methodology for integrating algorithms in healthcare systems, followed by analysis of the new methodology and a discussion. Action research is applied to review existing state of the art, and a qualitative case study method is used to analyse the knowledge acquired from the COVID-19 pandemic. Major trends found as a result of the study derive from the synthesis of COVID-19 knowledge, presenting new insights in the form of a conceptual methodology—that includes six phases for managing a future Disease X event, resulting with a summary map of various problems, solutions and expected results from integrating functional AI in healthcare systems.'\n",
      " 'GenAI can produce content that is similar to human ingenuity, revolutionizing a number of industries with lifelike outputs like music and images. Misinformation and intellectual property rights give rise to ethical concerns. Notwithstanding these difficulties, GenAI has the potential to spur additional innovation in a variety of sectors, subject to moral issues. The goal of explainable AI (XAI) is to improve AI systems’ accountability and transparency, which is essential for their inclusion into industries like banking and healthcare. However, in order to effectively explain complicated AI systems, strong XAI techniques are required. Quantum AI (QAI) promises improvements in cryptography and optimization by using quantum physics to speed up AI systems. However, there are still difficulties in creating practical quantum computers and improving quantum AI algorithms. The present overview provides new insights into developing a platform to explore AI in various arenas of life sciences and technologies and social up-gradation.'\n",
      " 'AbstractThis paper examines the ethical obligations companies have when implementing GenAI (AI). We point to the potential cyber security risks companies are exposed to when rushing to adopt GenAI solutions or buying into “AI hype”. While the benefits of implementing GenAI solutions for business have been widely touted, the inherent risks associated have been less well publicised. There are growing concerns that the race to integrate GenAI is not being accompanied by adequate safety measures. The rush to buy into the hype of GenAI and not fall behind the competition is potentially exposing companies to broad and possibly catastrophic cyber-attacks or breaches. In this paper, we outline significant cyber security threats GenAI models pose, including potential ‘backdoors’ in AI models that could compromise user data or the risk of ‘poisoned’ AI models producing false results. In light of these the cyber security concerns, we discuss the moral obligations of implementing GenAI into business by considering the ethical principles of beneficence, non-maleficence, autonomy, justice, and explicability. We identify two examples of ethical concern, overreliance and over-trust in GenAI, both of which can negatively influence business decisions, leaving companies vulnerable to cyber security threats. This paper concludes by recommending a set of checklists for ethical implementation of GenAI in business environment to minimise cyber security risk based on the discussed moral responsibilities and ethical concern.'\n",
      " 'Project management stands at the precipice of a significant transformation driven by GenAI (GenAI). This paper delves into the profound impact of GenAI on project managers, exploring how it reshapes roles, responsibilities, and the future of the field. We begin by outlining the evolution of AI, highlighting the emergence of GenAI and its ability to go beyond analysis and create novel content. GenAI will transform project management responsibilities from fully automated activities to a blend of assisted and augmented tasks, requiring collaboration and strategic application of this innovative technology. The paper explores the evolution of project management methodologies and the evolving skillset required of successful project managers in the age of AI and offers a \"Project Manager\\'s Guide to Thriving in the GenAI Tsunami\" by outlining the three pillars of the PMI Talent Triangle: Ways of Working, Power Skills, and Business Acumen. Each pillar is examined in detail, highlighting the role of GenAI in enhancing mastery and providing illustrative examples of AI-powered tools and frameworks. This paper equips project managers with the knowledge and tools to not only survive but thrive in the age of GenAI, ensuring their continued value and leadership in shaping successful projects.'\n",
      " 'This article delves into the captivating synergy between GenAI (GenAI) and Quantum Computing, illuminating their transformative impact on the economy, society, the job market, and the looming emergence of Artificial Super Intelligence (ASI). GenAI, a creative powerhouse, is revolutionizing content creation and streamlining operations across industries. Quantum Computing, computing’s quantum leap, offers unprecedented processing power, promising to optimize supply chains, drive innovation, and address complex global challenges. The fusion of GenAI and Quantum Computing amplifies their potential, creating a future where AI-driven solutions tackle profound problems. However, this transformative journey poses challenges to the job market, necessitating workforce adaptation. As we chart this course, we must address ethical and policy considerations, shaping a future where technology serves humanity’s best interests, inching closer to the realm of Artificial Super Intelligence. The article navigates this exciting landscape, offering insights into the future that is unfolding before us.'\n",
      " 'Using AI as an artistic medium comes with moral implications and responsibilities which can be difficult to anticipate. How can ethics help us unpick these?'\n",
      " 'Various organizations have created AI ethics standards and protocols in an era of rapidly expanding AI, all to ensure ethical AI use for the benefit of society. However, the ethical issues raised by AI’s societal applications in the actual world have generated scholarly debates. Through the prism of framing theory in media and communication, this study examines AI ethics principles from three significant organizations: Microsoft, NIST, and the AI HLEG of the European Commission. Institutional AI ethics communication must be closely examined in this rapidly changing technical environment because of how institutions frame their AI principles.'\n",
      " 'AbstractThe increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one’s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees’ experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, ‘tending the machine’, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions.\\n'\n",
      " 'AbstractThe rapid development of facial recognition technologies (FRT) has led to complex ethical choices in terms of balancing individual privacy rights versus delivering societal safety. Within this space, increasingly commonplace use of these technologies by law enforcement agencies has presented a particular lens for probing this complex landscape, its application, and the acceptable extent of citizen surveillance. This analysis focuses on the regulatory contexts and recent case law in the United States (USA), United Kingdom (UK), and European Union (EU) in terms of the use and misuse of FRT by law enforcement agencies. In the case of the USA, it is one of the main global regions in which the technology is being rapidly evolved, and yet, it has a patchwork of legislation with less emphasis on data protection and privacy. Within the context of the EU and the UK, there has been a critical focus on the development of accountability requirements particularly when considered in the context of the EU’s General Data Protection Regulation (GDPR) and the legal focus on Privacy by Design (PbD). However, globally, there is no standardised human rights framework and regulatory requirements that can be easily applied to FRT rollout. This article contains a discursive discussion considering the complexity of the ethical and regulatory dimensions at play in these spaces including considering data protection and human rights frameworks. It concludes that data protection impact assessments (DPIA) and human rights impact assessments together with greater transparency, regulation, audit and explanation of FRT use, and application in individual contexts would improve FRT deployments. In addition, it sets out ten critical questions which it suggests need to be answered for the successful development and deployment of FRT and AI more broadly. It is suggested that these should be answered by lawmakers, policy makers, AI developers, and adopters.'\n",
      " 'Background With the arrival of GenAI (genAI) tools, psychology educators are rethinking their assessment practices. Objective This paper describes one approach to integrating genAI into an assessment designed to promote psychological literacy. Method Students used GenAI to generate a media release about a published article and then wrote a critique. We evaluated whether students were able to use the marking rubric to assess the GenAI output, and whether working with the rubric early in the assessment process had benefits for their grades on subsequent tasks. Results The results show that students accurately assessed the GenAI output against the marking rubric, judging the output to be stylistically good but lacking in accurate coverage of the aims, methods, and results of the research. Working with genAI and the marking rubric early in the assessment process had benefits for performance, relative to cohorts that had engaged in peer review. Conclusion By allowing students to use genAI and scaffolding the process of critiquing and revising, students gained competencies in psychological, feedback, and AI literacies. Teaching implications Integrating genAI presents opportunities for learning, if educators can think beyond the artifact and design assessment that allows our students to showcase their learning process. '\n",
      " 'IntroductionAssessments of interactional competence have traditionally been limited in large-scale language assessments. The listening portion suffers from construct underrepresentation, whereas the speaking portion suffers from limited task formats such as in-person interviews or role plays. Human-delivered tasks are challenging to administer at large scales, while automated assessments are typically very narrow in their assessment of the construct because they have carried over the limitations of traditional paper-based tasks to digital formats. However, computer-based assessments do allow for more interactive, automatically administered tasks, but come with increased complexity in task creation. Large language models present new opportunities for enhanced automated item generation (AIG) processes that can create complex content types and tasks at scale that support richer assessments.MethodsThis paper describes the use of such methods to generate content at scale for an interactive listening measure of interactional competence for the Duolingo English Test (DET), a large-scale, high-stakes test of English proficiency. The Interactive Listening task assesses test takers’ ability to participate in a full conversation, resulting in a more authentic assessment of interactive listening ability than prior automated assessments by positing comprehension and interaction as purposes of listening.Results and discussionThe results of a pilot of 713 tasks with hundreds of responses per task, along with the results of human review, demonstrate the feasibility of a human-in-the-loop, GenAI-driven approach for automatic creation of complex educational assessments at scale.'\n",
      " 'In the awakening era of the technological landscape, the emergence of key technologies such as GenAI and AI (AI) has been instrumental in exercising an effective data mining process. The proliferated demand for best data mining practices continues to express how critical it is for growth in many sectors across different landscapes of human engagements and businesses.'\n",
      " 'BackgroundImbalanced datasets pose challenges for developing accurate seizure detection systems based on electroencephalogram (EEG) data. GenAI techniques may help augment minority class data to facilitate automatic epileptic seizure detection.New methodThis study investigates the impact of various data augmentation (DA) approaches, including Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), Vanilla GAN, Conditional GAN (CGAN), and Cramer GAN, on classification performance with Random Forest models. The best-performing GAN variant, WGAN-GP, was then integrated with a bidirectional Long Short-Term Memory (LSTM) architecture and compared against traditional and synthetic oversampling methods.ResultsThe evaluation of different GAN variants for data augmentation with Random Forest classifiers identified WGAN-GP as the most effective approach. The integration of WGAN-GP with bidirectional LSTM yielded substantial performance improvements, outperforming traditional oversampling methods and achieving an accuracy of 91.73% on the augmented data, compared to 86% accuracy on real data without augmentation.Comparison with existing methodsThe proposed GenAI approach combining WGAN-GP and recurrent neural network models outperforms comparative synthetic oversampling methods on metrics relevant for reliable seizure detection from imbalanced EEG datasets.ConclusionsIncorporating the WGAN-GP GenAI technique for data augmentation and integrating it with bidirectional LSTM elevates seizure detection accuracy for imbalanced EEG datasets, surpassing the performance of traditional oversampling and class weight adjustment methods. This approach shows promise for improving epilepsy monitoring and management through enhanced automated detection system effectiveness.'\n",
      " '<p class=\"p1\"><span lang=\"EN-US\">Talent sourcing is one of the most effective mechanisms to engage with the talent pool and convert a candidate into an applicant. Today, machine learning has emerged as a trend to assist employers in addressing recruitment challeng-es with the help of tools such as neuro-linguistic programming (NLP) and automated assessments. 80% of the executives strongly believe deep learning makes candidate screening highly efficient. Including current start-ups globally, only 15% use AI (AI) and are expected to increase by 31%. The study focused on the impact of AI in recruitment process. There are a few metrics, such as application completion rate, number of candidates per filled position, cost per hire, and so on. Here we would like to analyze the impact of using AI in various phases of hiring in the organization.</span></p>'\n",
      " 'This research paper delves into industries that can benefit from the implementation of AI, such, as IT operations, healthcare, finance and gaming. The potential of AI lies in its ability to enhance customer service create personalized content assist in research endeavors optimize investment strategies and create virtual environments. However businesses often encounter challenges when moving from AI proof of concept to implementation. These challenges involve scalability, integration with existing systems, data governance considerations aligning objectives and meeting requirements. To tackle these concerns head on this paper suggests the utilization of a converged infrastructure platform that combines computing power with network capabilities and storage resources using NVIDIA GPUs. It recommends evaluating existing AI proof of concepts and providing the infrastructure to transform each concept into an use case. The primary goal of this research study is to explore the process involved in converting AI proof of concepts into use cases while understanding its significance in harnessing AI capabilities, within organizations.'\n",
      " 'Customer support plays a pivotal role in shaping customer satisfaction and fostering loyalty within any business. This paper delves into how the integration of intent detection and GenAI (GenAI) can transform customer support systems. At the core of this transformation is the ability to understand user intent, which is essential for directing customers effectively through the support funnel to the appropriate services. By employing sophisticated natural language processing (NLP) techniques, training LLM to perform RAG and machine learning models, businesses can precisely discern customer intents. This capability allows for the delivery of tailored, immediate responses. The paper further explores the methodologies employed, the advantages gained, and the challenges faced in the adoption of these advanced technologies in customer support systems.'\n",
      " 'AbstractHenry Ford once said, “For most purposes, a man with a machine is better than a man without a machine.” To this, engineers today propose an addendum – “and a man that is a machine is best of all” – which they have made their goal. The world over, engineers are working to make the ultimate machine, “the holy grail of AI,” a conscious humanoid. On the one hand, such a “machine” will be capable of relieving us of all our burdens. On the other hand, in so doing, will we not have “birthed,” as it were, a new class of slaves? In this essay I seek to summarize the various arguments made in this debate, bring to bear moral positions from the philosophy of technology, philosophy of law and philosophy of religion, as well as demonstrate the moral impropriety of such an endeavor from each of the classic moral approaches (i.e., Virtue Ethics, Consequentialism, Kantian Deontology). Finally, given that the debate centers around what is the “good life” for human or humanoid, I expand upon Aristotle’s Eudemonia and Maimonides’ Summum Bonum to argue that life is precious in its affordance to allow conscious beings, human or humanoid, to aspire to the best life possible.'\n",
      " '\\nPurpose\\nAI (AI) and automation are currently changing human life with a great implication in the communication field. This research focusses on understanding the current and growing impact of AI and automation in the role of communication professionals to identify what skills and training are needed to face its impacts leading to a recommendation.\\n\\n\\nDesign/methodology/approach\\nThe research involves methodological triangulation, analysing and comparing data gathered from consulting with experts using the Delphi method, focus group with communication students, and literature review.\\n\\n\\nFindings\\nFindings show that the likely impacts are on the one hand the enhancing of efficiency and productivity, as well as freeing communication professionals to focus on the creative side, strategy and analytical thinking, on the other hand, repetitive and low-level jobs could be lost, being higher position jobs or those involving creativity and decision making harder to automate. Two types of training are needed: to gather experience with the current AI and automated tools, and to focus on developing human qualities that AI cannot replicate.\\n\\n\\nOriginality/value\\nThe outcomes of this research are valuable to help current and future communication practitioners, as well as organisations, to be one step ahead and survive the age AI and automation, being aware of its current and near-future impacts. The paper offers a list of recommended soft and technical skills, as well as training needed, categorizing them in low, medium and high priority.\\n'\n",
      " 'AI has evolved as an alternative to human intelligence. It affects the lives of billions of people. It mimics humans by solving problems and understanding the task. These AI technologies must have some moral values and ethics incorporated within itself. The usage of AI is growing worldwide, posing more ethical issues to consider. In recent years, many companies have used various AI tools such as chatbots and face recognition software for fulfilling their hiring needs. This research work will focus on such devices that help manage one of the important functions of human resources: recruitment. It will identify various challenges and ethical issues that a firm faces while assimilating AI tools in the process of Recruitment. The hiring companies need to make the job seekers realize that AI-powered tools would be free from discrimination and safeguard privacy. The purpose of the study is to identify the ethical issues while incorporating AI into hiring needs. The study will be based on reviews and features of applications. The study mentions various applications whose features might be unethical for job seekers. Findings reveal that the significant unethical issues faced by the hiring companies are Data privacy and unconscious biasness. The biasness is due to the algorithm that works according to the inputs fed to build it, and the programmer might have subconscious biasness in his mind. AI has restored concerns regarding privacy and data protection. According to a report by UNESCO, Women make up only 22% of all AI professionals. Gender prejudices and stereotyping are perpetuated in AI technologies due to their underrepresentation in the sector. Virtual personal assistants like Siri, Alexa, and Cortana are “female” by default, which is no accident. The submissiveness they display is an illustration of how AI (AI) might continue to support and extend gender bias in our society.'\n",
      " 'Üsküdar University Head of the Department of Sociology Prof. Barış Erdoğan evaluated the effects of AI on human life.'\n",
      " 'In popular discourse, AI (AI) has turned into one of the most inexplicable issues It has turned into an artifact that people do not dare to question [...]'\n",
      " 'The article discusses key aspects of AI creation, including issues of free will, self-awareness and ethics. The focus is on the neurobiological basis of consciousness, in particular the structure and functions of the new cerebral cortex, as well as the mechanisms of recognition, memory and prediction, which are important for modelling cognitive processes in artificial systems. The paper discusses the role of neural networks in reproducing cognitive functions, such as perception and decision making, and presents modern approaches to training neural networks. A separate part of the paper is devoted to the issue of modelling self-awareness and subjective experience in AI and how realistic it is to create self-aware machines. Ethical issues of AI creation are at the centre of the discussion, including the topics of the rights of self-aware machines, their responsibilities and their role in society. The article considers the possible social consequences of the emergence of artificial personalities, the need to develop new legal frameworks and legal protections for such beings. It also discusses the problem of free will in the context of both biological and artificial systems, citing experiments and philosophical theories that question free will as a phenomenon. It concludes that the creation of AI has great potential, but requires careful ethical and legal analysis to ensure the harmonious integration of artificial persons into social and legal structures.'\n",
      " 'As AI (AI) becomes more prevalent, protecting personal privacy is a critical ethical issue that must be addressed. This article explores the need for ethical AI systems that safeguard individual privacy while complying with ethical standards. By taking a multidisciplinary approach, the research examines innovative algorithmic techniques such as differential privacy, homomorphic encryption, federated learning, international regulatory frameworks, and ethical guidelines. The study concludes that these algorithms effectively enhance privacy protection while balancing the utility of AI with the need to protect personal data. The article emphasises the importance of a comprehensive approach that combines technological innovation with ethical and regulatory strategies to harness the power of AI in a way that respects and protects individual privacy.'\n",
      " 'GenAI (AI) refers to algorithms capable of creating novel, realistic digital content autonomously. Recently, generative models have attained groundbreaking results in domains like image and audio synthesis, spurring vast interest in the field. This paper surveys the landscape of modern techniques powering the rise of creative AI systems. We structurally examine predominant algorithmic approaches including generative adversarial networks (GANs), variational autoencoders (VAEs), and autoregressive models. Architectural innovations and illustrations of generated outputs are highlighted for major models under each category. We give special attention to generative techniques for constructing realistic images, tracing rapid progress from early GAN samples to modern diffusion models like Stable Diffusion. The paper further reviews generative modeling to create convincing audio, video, and 3D renderings, which introduce critical challenges around fake media detection and data bias. Additionally, we discuss common datasets that have enabled advances in generative modeling. Finally, open questions around evaluation, technique blending, controlling model behaviors, commercial deployment, and ethical considerations are outlined as active areas for future work. This survey presents both long-standing and emerging techniques molding the state and trajectory of GenAI. The key goals are to overview major algorithm families, highlight innovations through example models, synthesize capabilities for multimedia generation, and discuss open problems around data, evaluation, control, and ethics. Please let me know if you would like any clarification or modification of this proposed abstract.'\n",
      " '<p>Nowadays, many pedestrians are injured or killed in traffic accidents. As a result, several artificial vision solutions based on pedestrian detection have been developed to assist drivers and reduce the number of accidents. Most pedestrian detection techniques work well on sunny days and provide accurate traffic data. However, detection decreases dramatically in rainy conditions. In this paper, a new pedestrian detection system (PDS) based on generative adversarial network (GAN) module and the real-time object detector you only look once (YOLO) v3 is proposed to mitigate adversarial weather attacks. Experimental evaluations performed on the VOC2014 dataset show that our proposed system performs better than models based on existing noise reduction methods in terms of accuracy for weather situations.</p>'\n",
      " 'AbstractThis paper argues that the AI ethics has generally neglected the issues related to the science communication of AI. In particular, the article focuses on visual communication about AI and, more specifically, on the use of certain stock images in science communication about AI — in particular, those characterized by an excessive use of blue color and recurrent subjects, such as androgyne faces, half-flesh and half-circuit brains, and variations on Michelangelo’s The Creation of Adam. In the first section, the author refers to a “referentialist” ethics of science communication for an ethical assessment of these images. From this perspective, these images are unethical. While the ethics of science communication generally promotes virtues like modesty and humility, similar images are arrogant and overconfident. In the second section, the author uses French philosopher Jacques Rancière’s concepts of “distribution of the sensible,” “disagreement,” and “pensive image.” Rancière’s thought paves the way to a deeper critique of these images of AI. The problem with similar images is not their lack of reference to the “things themselves.” It rather lies in the way they stifle any possible forms of disagreement about AI. However, the author argues that stock images and other popular images of AI are not a problem per se, and they can also be a resource. This depends on the real possibility for these images to support forms of pensiveness. In the conclusion, the question is asked whether the kind of ethics or politics of AI images proposed in this article can be applied to AI ethics tout court.'\n",
      " 'GenAI (AI) has garnered significant attention for its remarkable ability to generate text, images, and other forms of content. However, an inherent and increasingly concerning issue within GenAI systems is bias. These AI models often exhibit an Anglo-centric bias and tend to overlook the importance of diversity. This can be attributed to their training on extensive datasets sourced from the internet, which inevitably inherit the biases present in those data sources. Employing these datasets leads to AI-generated content that mirrors and perpetuates existing biases, encompassing various aspects such as gender, ethnic and cultural stereotypes. Addressing bias in GenAI is a complex challenge that necessitates substantial efforts. In order to tackle this issue, we propose a methodology for constructing moderately sized datasets with a social inclination. These datasets can be employed to rectify existing imbalances in datasets or to train models to generate socially inclusive material. Additionally, we present preliminary findings derived from training our model on these socially inclined datasets.'\n",
      " 'AbstractThis article examines the implications of the artworks and public performances of the robot artist Ai-Da. While the project claims to advance AI public literacy and foster critical debate around intelligent systems, it instead ends up perpetuating popular misunderstandings about AI creativity, agency, and consciousness. Built in 2019, Ai-Da is a humanoid robot capable of creating drawings, paintings, and composing poetry. However, the project often conceals or miscommunicates the technical aspects of Ai-Da’s capabilities in a manner that encourages the public to misattribute human-like traits to the robot. This lack of transparency in the presentation of Ai-Da’s abilities and the creative processes involved risks reinforcing existing misconceptions about AI, rather than promoting a more nuanced understanding. By employing discourse analysis and drawing on scholarship on machine and computational creativity, anthropomorphism in social robots, and posthuman embodiment, this article uses the Ai-Da project as a case study to illustrate how the dangers of AI hype can be obscured when presented through the lens of public art. The analysis examines how the Ai-Da project, despite its stated goals of advancing AI literacy, fails to effectively challenge and may even exacerbate public misperceptions about the nature of AI-generated art and creativity.'\n",
      " '<p><span lang=\"EN-US\">Research in the field of speech recognition is a challenging research area. Various approaches have been applied to build robust models. A problem faced in speech recognition research is overfitting, especially if there is insufficient data to train the model. A large enough amount of data can train the model well, resulting in high accuracy. Data augmentation is an approach often used to increase the quantity of dataset. This research uses a data augmentation approach, namely pitch shifting, to increase the quantity of speech dataset, which is then processed into spectrogram data and then classified using a generative adversarial network (GAN). Using the pitch shifting-generative adversarial network (PS-GAN) model, this research produces high accuracy performance in multi-ethnic speech recognition, namely 98.43%, better than several similar studies.</span></p>'\n",
      " 'The article examines the impact of the rapid development of AI (AI) technologies on the creative industries and the concerns of workers in this field regarding the potential deterioration of their working conditions and displacement from the labor market. The aim of the study is to identify the degree of concern among freelancers engaged in intellectual and creative professions regarding competition with AI and to assess their perception of AI’s current capabilities in making creative content. The empirical basis was provided by online survey data of 778 Russian freelancers receiving jobs through the Freelance.ru digital platform, conducted in spring 2024. It was found that many respondents are already actively using AI in their work. The majority of freelancers note AI’s high current capabilities in creating texts, images, translation, and other areas, and more than a third believe that in the coming years AI will be able to do their typical work as well or even better than they do it themselves. Those who were least likely to experience concerns about their future were individuals who had been trained in AI, used it to perform job tasks, satisfied with their work, and had a high level of income, i.e., generally had a stable position in the labor market. Despite the concerns of some workers, the development of AI opens up new opportunities for the creative industries; however, regular monitoring of the situation is required to develop measures to adapt the labor market.'\n",
      " 'This paper examines the intricate links between AI (AI) and education, delving into both theoretical and practical aspects while evaluating possible ramifications for labor market dynamics, professional activity, and wider educational paradigms. Our research methodology involved analyzing relevant scientific literature, classifying data, consulting with subject matter experts, and synthesizing the results. Our research suggests that AI has the ability to greatly improve pedagogical processes, personalize learning experiences to meet individual student needs, and successfully address the time and financial limitations that are inherent in traditional educational models. However, our study also reveals challenges related to data confidentiality, potential plagiarism and fraud associated with AI use, and socioeconomic disparities resulting from unequal technology access. Additionally, we identified a significant gap in current AI usage standards legislation. It is essential for researchers, educators, and policymakers to recognize the potential risks of AI implementation in educational settings and proactively develop strategies that prioritize ethics, safety, and effectiveness. With labor market trends favoring specialists knowledgeable in utilizing AI tools, a consequent change in curricula is expected. In response to our findings, we recommend the creation of new academic disciplines that concentrate on the cultivation of AI expertise; the establishment of comprehensive national AI strategies; the crafting of retraining roadmaps for those who may be affected by AI automation; the inclusion of online AI courses in existing educational programs; and the promotion of grant funding for future AI research. Our future research will concentrate on reducing the potential negative impacts of integrating AI into educational systems.'\n",
      " 'In recent years, AI (AI) has emerged as an important theme in Indian cinema. Taking note of Indian filmmakers’ interest in AI, this article examines the Hindi-language short film Anukul directed by Sujoy Ghosh. Based on a short story by the legendary auteur Satyajit Ray, the film draws us to a posthuman world order in which machines have assumed rights and threaten to push humans out of the loop. The AI–human interface in Anukul provokes a number of ethical questions and this article aims to think through some of the ethical and legal concerns raised in the film.'\n",
      " 'The current study examined university students’ insights into GenAI writing tools regarding their familiarity with, perceived concerns about, and perceived benefits of these tools in their academic work. The study used a cross-sectional descriptive research design, and data were collected using a questionnaire instrument. The participants were ninety-five undergraduate and graduate students from a College of Education at a university in Jordan. The results show that university students show moderate familiarity with GenAI writing tools (M = 3.14, SD = 0.81), especially in engagement but lacking technical knowledge. They also have moderate concerns (M = 3.35, SD = 0.85), particularly about misinformation and data security. Despite these concerns, students recognize the benefits (M = 3.62, SD = 0.81), especially regarding the capabilities of these tools in simulating creativity and fostering innovation. In addition, the results showed that gender and educational level appear to have little effect on familiarity, concerns, and perceived benefits regarding these tools. Based on the findings, the study recommends enhancing students’ familiarity with GenAI tools through providing technical training, hands-on opportunities, and ethical discussions. In addition, the study recommends addressing students’ concerns regarding GenAI writing tools by improving data security related to GenAI, providing ethical guidelines regarding the use of these tools, and boosting AI literacy. Finally, it is recommended to enhance students’ perceptions of the benefits of GenAI writing tools by highlighting the creative potential of these tools within the educational setting, using these tools to offer personalized learning experiences that adapt to individual learning styles, and promoting collaboration through GenAI writing tools.'\n",
      " 'The use of AI in law represents one of the biggest challenges across different legal systems. Supporters of predictive systems believe that decisionmaking could be more efficient, consistent and predictable by using AI. European legislation and legal scholars, however, identify areas where AI developments are at high risk or too dangerous to be used in judicial proceedings. In this article, we contribute to this debate by problematizing predictive systems based on previous judgments and the growing use of GenAI in judicial proceedings. Through illustrations from real criminal cases in Italian courts and prosecution offices, we show misalignments between the functions of AI systems and the essential features of legal decision-making and identify possible legitimate usages. We argue that current predictive systems and GenAI crunch the complexity of judicial proceedings, the dynamics of fact-finding and legal encoding. They reduce the delivery of justice to statistical connections between data or metadata, cutting off the emotive-cognitive process that lies at the core of legal decision-making.'\n",
      " 'AbstractAs it is the case for many business processes and activities disciplines, AI (AI) is increasingly integrated in human resources management (HRM). While AI has great potential to augment the HRM activities in organizations, automating the management of humans is not without risks and limitations. The identification of these risks is fundamental to promote responsible use of AI in HRM. We thus conducted a review of the empirical academic literature across disciplines on the affordances and responsible principles of AI in HRM. This is the first review of responsible AI in HRM that focuses solely on studies containing observations, measurements, and tests about this phenomenon. The multi-domain and multidisciplinary approach and empirical focus provides a better understanding of the reality of the development, study, and deployment of AI in HRM and sheds light on how these are conducted responsibly. We conclude with a call for research based on what we identified as the most needed and promising avenues.'\n",
      " 'Abstract: Visual memory is the strongest in learning; It is 60,000 times more powerful than text and memory. This important fact shows that there is an urgent need to make changes in the education process, moving away from old, monotonous practices and towards a dynamic, effective and permanent educational support. Inspired by the effectiveness of the invisible aspects of visual learning, this article introduces GenClassroom, a new learning tool that promises to revolutionize the traditional teaching method. GenClassroom uses the power of AI (AI) to translate and transform teacher lessons into beautiful images, providing students with a unique learning experience beyond the boundaries of the classroom environment. Seamlessly integrating speech-to-image capabilities into dynamic virtual classroom environments, GenClassroom enables educators to create engaging, interactive lessons that resonate with students and promote understanding, retention, and engagement. Through a qualitative study of GenClassroom’s design, functionality, and application content, this article outlines the evolution of the vision of AI-enabled education to shape the future of learning. As the ed- ucational landscape changes dramatically, GenClassroom serves as a beacon of innovation, ushering in a new era of personalized, meaningful, and empowering learning. By embracing the endless possibilities of visual learning enhanced by AI, GenClassroom paves the way for a future where learning has no boundaries and every student can reach their potential.'\n",
      " 'AbstractThe European Union’s AI Act (AI Act) is a groundbreaking regulatory framework that integrates technical concepts and terminology from the rapidly evolving ecosystems of AI research and innovation into the legal domain. Precise definitions accessible to both AI experts and lawyers are crucial for the legislation to be effective. This paper provides an interdisciplinary analysis of the concepts of AI system, general purpose AI system, foundation model and GenAI across the different versions of the legal text (Commission proposal, Parliament position and Council General Approach) before the final political agreement. The goal is to help bridge the understanding of these key terms between the technical and legal communities and contribute to a proper implementation of the AI Act. We provide an analysis of the concept of AI system considering its scientific foundation and the crucial role that it plays in the regulation, which requires a sound definition both from legal and technical standpoints. We connect the outcomes of this discussion with the analysis of the concept of general purpose AI system and its evolution during the negotiations. We also address the distinct conceptual meanings of AI system vs AI model and explore the technical nuances of the term foundation model. We conclude that rooting the definition of foundation model to its general purpose capabilities following standardised evaluation methodologies appears to be most appropriate approach. Lastly, we tackle the concept of GenAI, arguing that definitions of AI system that include “content” as one of the system’s outputs already captures it, and concluding that not all GenAI is based on foundation models.'\n",
      " \"Les technologies d’IA générative telles que Chat GPT-4, DALL.E 2 et Stable Diffusion sont au premier plan des discussions, s’agissant de leur impact sur des secteurs tels que le commerce, l'éducation et la création, en particulier en ce qui concerne les droits de propriété intellectuelle et les risques potentiels de violation de ces derniers. Ces technologies remettent en question les lois existantes sur le droit d’auteur, notamment en termes de droits de reproduction et d’adaptation, créant un équilibre complexe entre l’innovation technologique et les titulaires de droits. La Directive sur le droit d’auteur dans le marché unique numérique de l’Union européenne prévoit certaines exceptions pour l’entraînement de l’IA à travers le minage de textes et de données, mais celles-ci ne s'étendent pas à tous les droits, conduisant à un paysage juridique nuancé. De plus, les spécificités locales en matière de droits de propriété intellectuelle, comme celles de l’UE, du Royaume-Uni, de l’Espagne et de l’Allemagne, compliquent davantage les choses, en particulier en ce qui concerne les bases de données, les photographies et les images de personnes réelles. Cette complexité est accentuée par les débats et les défis juridiques en cours dans différents pays, comme l’UE, le Royaume-Uni et les États-Unis, sur la question de savoir si les œuvres générées par l’IA peuvent être éligibles à la protection du droit d’auteur, reflétant la nature évolutive et incertaine du droit d’auteur à l'ère de l’IA.\"\n",
      " \"Objectives  In this study, we explored practical teaching and learning approaches that utilize GenAI, which already influences various aspects of our lives, to assist students in their writing endeavors.\\nMethods  I proposed concrete teaching and learning methods for utilizing the GenAI, Luton, in the stage of content generation in writing. I explored application methods for addressing writing issues that authors encounter in areas such as topic selection, generating ideas, and content creation. Additionally, I investigated the possibility of implementing a program for self-assessment, enabling authors to receive evaluations of their writing outputs and make self-revisions accordingly.\\nResults  GenAI (AI) can be used as a tool to provide inspiration during creative activities, offer solutions for content creation, and assist in generating ideas for simple outlines or storyboards. Additionally, it proved helpful in producing writing materials and facilitating checks and feedback on written work.\\nConclusions  We hope to enhance writing instruction and improve students' writing abilities through the utilization of GenAI (AI).\"\n",
      " 'The development of AI generative systems (AIGS) in the modern world requires addressing issues related to the quality, stability, and efficiency of the generated content. In this context, resonance diagnostics become of paramount importance. The purpose of this study is to explore the possibilities of applying resonance diagnostics for detecting, analyzing, and resolving problems in AI generative systems. To achieve the set goal, the following tasks were identified: analysis of the theoretical foundations of resonance diagnostics; investigation of the potential of using resonance signals to adjust AIGS learning parameters; studying the impact of resonance diagnostics on the stability and adaptation of AIGS to changing operating conditions. The study conducted an analysis of resonance diagnostics in the context of AIGS and revealed its powerful influence on addressing issues related to system quality and productivity. The research demonstrated that resonance diagnostics can be used to achieve realism, diversity, and quality of generated content. Additionally, it was determined that it can contribute to enhancing the stability and adaptation of systems to varying operational conditions'\n",
      " '<p>Research in AI has built upon the tools and techniques of many different disciplines.Study in the AI has given rise to rapidly growing technology known as expert system. Rapid development in this field made human more dependent on this technology. More advancement will lead to side effects of that technology because after a certain point, everything is harmful.</p>'\n",
      " 'Thanks to the rapid development of generative deep learning models, AI Generated Content (AIGC) has attracted more and more research attention in recent years, which aims to learn models from massive data to generate relevant content based on input conditions. Different from traditional single-modal generation tasks that focus on content generation for a particular modality, such as image generation, text generation, or semantic generation, AIGC trains a single model that can simultaneously understand language, images, videos, audio, and more. AIGC marks the transition from traditional decision-based AI to GenAI, which has been widely applied in various fields. Focusing on the key technologies and representative applications of AIGC, this paper identifies several key technical challenges and controversies in the field. These include defects in cross-modal and multimodal generation, issues related to model stability and data consistency, privacy concerns, and questions about whether advanced generative models like GenAI can be considered general AI (AGI). While this dissertation provides valuable insights into the revolution and challenge of GenAI in art and education, it acknowledges the sensitivity of generated content and the ethical dilemmas it may pose, and ownership rights for AI-generated works and the need for new intellectual property norms are subjects of ongoing discussion. To address the current technical bottlenecks in cross-modal and multimodal generation, future research aims to quantitatively analyze and compare existing models, proposing practical optimization strategies. With the rapid advancement of GenAI, we anticipate a transition from user-generated content (UGC) to AI-generated content (AIGC) and, ultimately, a new era of human-computer co-creation with strong interactive potential in the near future.'\n",
      " 'AbstractAs AI (AI) models continue to scale up, they are becoming more capable and integrated into various forms of decision-making systems. For models involved in moral decision-making (MDM), also known as artificial moral agents (AMA), interpretability provides a way to trust and understand the agent’s internal reasoning mechanisms for effective use and error correction. In this paper, we bridge the technical approaches to interpretability with construction of AMAs to establish minimal safety requirements for deployed AMAs. We begin by providing an overview of AI interpretability in the context of MDM, thereby framing different levels of interpretability (or transparency) in relation to the different ways of constructing AMAs. Introducing the concept of the Minimum Level of Interpretability (MLI) and drawing on examples from the field, we explore two overarching questions: whether a lack of model transparency prevents trust and whether model transparency helps us sufficiently understand AMAs. Finally, we conclude by recommending specific MLIs for various types of agent constructions, aiming to facilitate their safe deployment in real-world scenarios.'\n",
      " 'AbstractThe right to life is fundamental and primary and is a precondition for exercising other rights (Ramcharan in Ramcharan (ed), The right to life in International Law, Martinus Nijhoff Publishers, Dordrecht, 1985). Its universal recognition in the arena of international law is associated with the concept of a human being endowed with inherent and inalienable dignity. Categorization of the circle of entities covered with the right to life today seems obvious and indisputable. Intense development of AI, also the fact that it has passed the Turing test which checks AI’s thinking ability in a way similar to human reasoning, inspires a reflection on AI’s future legal status. This study will investigate a thesis of whether AI may be entitled to the right to life. The analysis will be carried out around an exploratory question: what are the requirements for being afforded protection of the right to life?'\n",
      " 'Cybersecurity threats continue to evolve in complexity and scale every year. The need for more effective vulnerability management has become more important now than ever.'\n",
      " \"This study examines AI's huge impact on visual art performance. This study examines how AI's history, tools, and uses in visual art have transformed processes and immersed audiences. Machine learning, computer vision, and GANs let artists create, curate, and alter visual art with unprecedented creativity. AI creates visual art performance concepts, styles, and aesthetics. AI helps artists analyze massive data sets, find trends, and try new art forms. Case studies demonstrate how AI has been used in many artistic disciplines to create groundbreaking performances, interactive installations, and fascinating experiences. AI-powered inventions have changed art genres and captivated viewers. Collaborative art has pushed creativity and innovativeness. Audiences can participate in the creative process and co-create meaning and narrative in personalized, immersive, and interactive AI-powered art experiences. AI in visual art performance affects biases, ownership, copyright, transparency, and accountability. The paper advocates for ethical, legal, transparent, and interpretable AI systems in the arts to promote equality and fairness. Examine future AI visual art performance adjustments, enhancements, and challenges. It enhances AI algorithms for artistic expression, emotions, and aesthetic. AI researchers, visual artists, composers, dancers, and performers will create more complex, interactive cross-disciplinary works. Interpretability, bias reduction, and ethics research advance the field.\"\n",
      " 'AbstractGenAI enables automated, effective manipulation at scale. Despite the growing general ethical discussion around GenAI, the specific manipulation risks remain inadequately investigated. This article outlines essential inquiries encompassing conceptual, empirical, and design dimensions of manipulation, pivotal for comprehending and curbing manipulation risks. By highlighting these questions, the article underscores the necessity of an appropriate conceptualisation of manipulation to ensure the responsible development of GenAI technologies.'\n",
      " 'AI (AI) is a pivotal domain within computer science, profoundly influencing the software development lifecycle, particularly during the implementation phase. Here, developers grapple with the task of translating software requirements and designs into executable code. Automated Code Generation (ACG) leveraging AI emerges as a promising solution in this context. The automation of code generation processes is gaining traction as a means to tackle diverse software development challenges while boosting productivity. This paper presents a thorough review and discourse on both traditional and AI-driven techniques employed in ACG, highlighting their respective challenges and constraints. Through an examination of pertinent literature, we identify various AI methodologies and algorithms utilized in ACG, extracting evaluation metrics such as Accuracy, Efficiency, Scalability, Correctness, Generalization, among others. These metrics serve as the basis for a comparative analysis of AI-driven ACG methods, delving into their applications, strengths, weaknesses, performance metrics, and future prospects.'\n",
      " 'This article is an account of a social work academic’s first engagement with GenAI (AI). The aim is to introduce this emerging and fast-growing technology to the social work community in order to promote a dialogue about its potential use for learning in social work practice learning placements. Examples are included to stimulate ideas and motivate educators to use GenAI for teaching and learning. The case is made that students and educators need to understand how to use AI responsibly and skilfully to be agile and equipped for the workplace of the future. Although AI can be useful, it has limitations and cannot replace human interaction which is a fundamental aspect of social work education in the workplace.'\n",
      " \"This opinion piece highlights the integral role of GenAI (AI) in learning within Higher Education Institutions (HEIs). Employing social learning theories, this opinion piece aims to explore GenAI as a stakeholder in learning. By weaving in social constructivist and learning theories, this opinion paper aims to uncover the capacity of GenAI to facilitate and enhance the learning process. Central to this opinion piece proposition is cultivating a learning community that leverages AI's potential as a new learning stakeholder. This opinion piece aims to contribute to ongoing discussions in the field of learning development by offering a fresh outlook on how AI can be an asset in knowledge co-creation and collaborative learning. The paper does this in the following ways: (1) highlights how GenAI can effectively contribute to learning and knowledge co-creation, and (2) provides some guidance for integrating GenAI in collaborative learning.\"\n",
      " ' This paper explores the potential impact of GenAI (GenAI) on developing countries, considering both positive and negative effects across various domains of information, culture, and industry. GenAI refers to AI (AI) systems that generate content, such as text, audio, or video, aiming to produce novel and creative outputs based on training data. Compared to conversational AI, GenAI systems have the unique capability of not only providing replies but also generating the content of those responses. Recent advancements in AI during the Fourth Industrial Revolution, exemplified by tools like GenAI, have gained popularity and reshaped content production and creation. However, the benefits of GenAI are not equally accessible to all, especially in developing countries, where limited access to cutting-edge technologies and inadequate infrastructure pose challenges. This paper seeks to understand the potential impact of GenAI technologies on developing countries, considering economic growth, access to technology, and the potential paradigm shift in education, healthcare, and the environment. The findings emphasize the importance of providing the necessary support and infrastructure to ensure that GenAI contributes to inclusive development rather than deepening existing inequalities. The study highlights the significance of integrating GenAI into the context of the Fourth Industrial Revolution in developing countries, where technological change is a crucial determinant of progress and equitable growth. '\n",
      " 'In the early 2020s, advances in transformer-based deep neural networks enabled the development and growth of a number of GenAI (GenAI) systems notable for accepting natural language prompts as input. These include large language model chatbots such as GenAI, Bard, and others. GenAI has applications across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, and more. In this paper, we place these recent advances in a historical, cybernetic context. We analyze ethical issues that arise in the area of software engineering and cyber-physical systems. In addition, we explore AI-based challenges in healthcare and medicine, including a number involving GenAI. This research shows the importance of rigorous ethical analysis and resulting safeguards to address the emerging issues with AI.'\n",
      " 'The manic flurry of activity following the recent introduction of Open AI’s GenAI-4, Google’s Bard and other similar advanced Large Language Models (LLMs) has tended to generate rather more heat than light in both popular and academic discourse about the main implications of the new applications. Debate has ranged from doom-laden apocalyptic warnings to hyperbolic accounts of how AI will revolutionise and enhance all aspects of human activity. Attempting to steer a middle way between these extremes, this article concentrates on the key issues of regulation, control and alignment of the new systems since these are the areas that are likely to be of the first importance in informing and influencing the ways in which AI impacts all aspects of our lives. The key themes examined here build on my previous article on the educational implications of AI which was published in Qeios (Hyland, 2023a), and there are some overlaps with this piece and the current discussion so as to provide a background for those who may not have read the original.\\n'\n",
      " 'AbstractThis paper discusses two opposing views about the relation between AI (AI) and human intelligence: on the one hand, a worry that heavy reliance on AI technologies might make people less intelligent and, on the other, a hope that AI technologies might serve as a form of cognitive enhancement. The worry relates to the notion that if we hand over too many intelligence-requiring tasks to AI technologies, we might end up with fewer opportunities to train our own intelligence. Concerning AI as a potential form of cognitive enhancement, the paper explores two possibilities: (1) AI as extending—and thereby enhancing—people’s minds, and (2) AI as enabling people to behave in artificially intelligent ways. That is, using AI technologies might enable people to behave as if they have been cognitively enhanced. The paper considers such enhancements both on the level of individuals and on the level of groups.'\n",
      " 'With growing power of computer and blend of intelligent soft wares, the interpretation and analytical capabilities of the system had shown an excellent growth, providing intelligence solutions to almost every computing problem. In this direction here we are trying to identify how different geocomputation techniques had been implemented for estimation of parameters on water bodies so as to identify the level of contamination leading to the different level of eutrophication. The main mission of this paper is to identify state-of-art in artificial neural network paradigms that are prevailing and effective in modeling and combining spatial data for anticipation. Among this, our interest is to identify different analysis techniques and their parameters that are mainly used for quality inspection of lakes and estimation of nutrient pollutant content in it, and different neural network models that offered the forecasting of level of eutrophication in the water bodies. Different techniques are analyzed over the main steps;-assimilation of spatial data, statistical interpretation technique, observed parameters used for eutrophication estimation and accuracy of resultant data.'\n",
      " 'Digital technologies are making their mark in medicine, and especially also in art therapy, offering innovative therapeutic interventions for patients, including those with melanoma skin cancer. However, the integration of novel technologies, such as AI-generated art, brings along ethical, psychological, and technical challenges that are viewed differently among therapists. We aim to gauge art therapists’ views on the ethical, application, and challenge facets of utilizing AI-generated art from medical images in therapy. The focus is on assessing its applicability and limitations for melanoma patients. Art therapists were surveyed via a questionnaire focusing on their experience, digital tool familiarity, and views on AI in therapy, encompassing ethics, benefits, challenges, and applicability for melanoma. Art therapists have already implemented digital technologies and acknowledged potential therapeutic benefits of creating personalized artworks with GenAI. Attention needs to be given to technological hurdles and the necessity for supplementary interventions. Views on the method’s adaptability varied, underscoring a need for tailored, patient-focused applications. Art therapists are welcoming AI-generated art as a promising creative therapeutic tool and acknowledge potential therapeutic benefits. There are ethical, technical, and psychological challenges that must be addressed for application in therapeutic sessions. Therapists should navigate AI integration with sensitivity, adhering to ethical norms around consent and privacy. Future studies should show the therapeutic benefit in practice with emphasis on equipping therapists to manage the technical complexities effectively. Furthermore, it is important to ensure that patients can influence the AI output, allowing for creative moments in the process.'\n",
      " 'Medical errors are not generally disclosed but they do happen and vary in severity. By prioritising patient safety, Dr Kohei Tanaka, a clinical engineer from the Tokyo University of Technology, wants to find a solution for preventing medical errors or, at the very least, ensuring they\\n don’t escalate into serious incidents. The solution Tanaka is working on combines AI (AI) with augmented reality (AR) glasses. The idea is that the glasses will provide medical professionals with accurate and reliable information at critical times. By providing them\\n with rapid access to real-time data, the expectation is that this will reduce critical errors. As part of the validation process, newly qualified nurses will compare current training methods with training using his AR glasses and also complete a questionnaire on the viability of the glasses.\\n So far, the researchers have been able to verify the retention of data provided through the glasses for a period of about three months and believe large-scale verification will reveal the mechanism of long-term memory in the future. By providing accurate, up-to-date information in a visual\\n (still images and video) and auditory format, the glasses assist with the rapid delivery of critical data. However, there remain question marks regarding how much data can be effectively presented to the operator at the point of use as information overloading is to be avoided. The system included\\n a voice-synthesised text reading guide as well as the display through the bone conduction earpiece within the device, which means the user can continue with the procedure while listening to the voice guide, reading reliance on visuals and thereby increasing safety.'\n",
      " 'AbstractIn most domains of human life, we are willing to accept that there are experts with greater knowledge and competencies that distinguish them from non-experts or laypeople. Despite this fact, the very recognition of expertise curiously becomes more controversial in the case of “moral experts”. Do moral experts exist? And, if they indeed do, are there ethical reasons for us to follow their advice? Likewise, can emerging technological developments broaden our very concept of moral expertise? In this article, we begin by arguing that the objections that have tried to deny the existence (and convenience) of moral expertise are unsatisfactory. After that, we show that people have ethical reasons to ask for a piece of moral advice in daily life situations. Then, we argue that some AI (AI) systems can play an increasing role in human morality by becoming moral experts. Some AI-based moral assistants can qualify as artificial moral experts and we would have good ethical reasons to use them.'\n",
      " 'AI (AI) may appear to be one of the newest and most talked about areas of science amidst the current 4th Industrial Revolution (4IR), but it has, in fact, been under development since the beginning of time, from Arabic Alchemy to (Jewish) Talmudic scholar Rabbi Judah Loew ben Bezalel’s 16th century interpretation of Golem. More recently discussed only in the realm of science fiction movies, AI has now comfortably and securely entered the highest circles of academia, industry, and government. However, experts have only just begun to look at the impact of AI on human rights violations and God. As AI and technology become integral parts of our working lives, this essay aims to answer the question of whether the scientist or AI will be held liable when a Believer’s human rights are violated (physical and psychological violations) and whether the European Union’s Directive 85/374/EEC legislation is adequate in tackling this currently very niche issue.'\n",
      " 'AbstractSince Chinese scholars are playing an increasingly important role in shaping the national landscape of discussion on AI ethics, understanding their ethical concerns and preferred solutions is essential for global cooperation on governance of AI. This article, therefore, provides the first elaborated analysis on the discourse on AI ethics in Chinese academia, via a systematic literature review. This article has three main objectives. (1) to identify the most discussed ethical issues of AI in Chinese academia and those being left out (the question of “what”); (2) to analyze the solutions proposed and preferred by Chinese scholars (the question of “how”); and (3) to map out whose voices are dominating and whose are in the marginal (the question of “who”). Findings suggest that in terms of short-term implications, Chinese scholars’ concerns over AI resemble predominantly the content of international ethical guidelines. Yet in terms of long-term implications, there are some significant differences needed to be further addressed in a cultural context. Further, among a wide range of solution proposals, Chinese scholars seem to prefer strong-binding regulations to those weak ethical guidelines. In addition, this article also found that the Chinese academic discourse was dominated by male scholars and those who are from elite universities, which arguably is not a unique phenomenon in China.'\n",
      " 'In modern life, the application of AI (AI) has promoted the implementation of data-driven algorithms in high-stakes domains, such as healthcare. However, it is becoming increasingly challenging for humans to understand the working and reasoning of these complex and opaque algorithms. For AI to support essential decisions in these domains, specific ethical issues need to be addressed to prevent the misinterpretation of AI, which may have severe consequences for humans. However, little research has been published on guidelines that systematically addresses ethical issues when AI techniques are applied in healthcare. In this systematic literature review, we aimed to provide an overview of ethical concerns and related strategies that are currently identified when applying AI in healthcare. The review, which followed the PRISMA guidelines, revealed 12 main ethical issues: justice and fairness, freedom and autonomy, privacy, transparency, patient safety and cyber security, trust, beneficence, responsibility, solidarity, sustainability, dignity, and conflicts. In addition to these 12 main ethical issues, we derived 19 ethical sub-issues and associated strategies from the literature.'\n",
      " 'The integration of AI (AI) into Library and Information Science (LIS) has gained significant attention in recent years, offering promising opportunities to enhance library services and user experiences. This paper presents a comprehensive review of the literature on AI in LIS, synthesizing key themes, findings, and implications from existing research.\\nThe review identifies various opportunities afforded by AI technologies, including improved information retrieval, personalized recommendation systems, virtual assistance, data analytics, and digital preservation. Scholars highlight the potential of AI to revolutionize library services, streamline operations, and promote accessibility and inclusivity.\\nHowever, the review also discusses several challenges and limitations associated with AI implementations in LIS, such as algorithmic bias, privacy concerns, digital divide, cost and resource requirements, and ethical considerations, Researchers emphasize the need for careful consideration of these challenges to ensure responsible and equitable AI user in libraries.\\nUser perspectives and experiences with AI-driven library services are examined, revealing insights into adoption factors, user preferences, and concerns about privacy, data quality, and trust in AI technologies. The evolving roles and skills of librarians and information professional in the AI era are also discussed, highlighting the importance of digital literacy, data management, and ethical decision-making.\\nCase studies and best practices showcase successful examples of AI implantation in libraries, providing valuable lessons learned and insights for library practitioners. Finally, future directions and research agenda for AI in LIS are identified, including the development of AI-driven tools are services, exploration of ethical and social implications, and interdisciplinary collaborations to advance understanding and innovation in this rapidly evolving field.\\nOverall, the review underscores the transformative potential of AI in LIS while emphasizing the importance of addressing challenges and ethical considerations to ensure responsible AI implantation and maximize its benefits for libraries and their patrons.'\n",
      " 'The education landscape is shifting towards automation and digitalization to cater to the increasing demand for personalized learning experiences and more efficient teaching methods. In response to this trend, we propose the development of an integrated educational automation fusion platform that aims to overhaul educating and learning practices across various educational sectors. The integration of cutting-edge language models like GPT-3.5 and Gemini Pro in information retrieval and conversational AI has opened fresher opportunities, even within the realm of education. With its advanced features, LangChain, a powerful framework for large language models, enables seamless integration of AI-driven functionalities, including document analysis, question generation, and chatbot interaction, revolutionizing the educational landscape. Also, by harnessing the vast resources of the OpenAI API, our platform empowers educators and learners to engage in dynamic conversations with educational materials, generate personalized assessments, and gain deeper insights from complex datasets within a single forum. This single platform disseminates information on all facets of research and development in educational domain on the grounds of fusion practices and applications. This system is successful in combining multiple models for intelligent systems. On evaluation, our system was successful in generating decent performance compared to existing systems, even though they are singular modules. Overall, our platform aims to empower educators, students, and institutions to embrace the digital era of learning and unlock new avenues for fusion-based knowledge acquisition and innovation.'\n",
      " 'GenAI tools introduce new and accessible forms of media creation for youth. They also raise ethical concerns about the generation of fake media, data protection, privacy and ownership of AI-generated art. Since GenAI is already being used in products used by youth, it is critical that they understand how these tools work and how they can be used or misused. In this work, we facilitated students’ GenAI learning through expression of their imagined future identities. We designed a learning workshop - Dreaming with AI - where students learned about the inner workings of GenAI tools, used text-to-image generation algorithms to create their imaged future dreams, reflected on the potential benefits and harms of GenAI tools and voiced their opinions about policies for the use of these tools in classrooms. In this paper, we present the learning activities and experiences of 34 high school students who engaged in our workshops. Students reached creative learning objectives by using prompt engineering to create their future dreams, gained technical knowledge by learning the abilities, limitations, text-visual mappings and applications of GenAI, and identified most potential societal benefits and harms of GenAI.'\n",
      " 'No abstract available'\n",
      " \"PurposeThe widespread usage of AI (AI) is prompting a number of ethical issues, including those involving concerns for fairness, surveillance, transparency, neutrality and human rights. The\\xa0purpose of this manuscript is to explore possibility of developing cognitive morality in AI systems.Design/methodology/approachThis is explorative research. The manuscript investigates the likelihood of cognitive moral development in AI systems as well as potential pathways for such development. Concurrently, it proposes a novel idea for the characterization and development of ethically conscious and artificially intelligent robotic machines.FindingsThis manuscript explores the possibility of categorizing AI machines according to the level of cognitive morality they embody, and while doing so, it makes use of Lawrence Kohlberg's study related to cognitive moral development in humans. The manuscript further suggests that by providing appropriate inputs to AI machines in accordance with the proposed concept, humans may assist in the development of an ideal AI creature that would be morally more responsible and act as moral agents, capable of meeting the demands of morality.Research limitations/implicationsThis manuscript has some restrictions because it focuses exclusively on Kohlberg's perspective. This theory is not flawless. Carol Gilligan, one of Kohlberg's former doctoral students, said that Kohlberg's proposal was unfair and sexist because it didn't take into account the views and experiences of women. Even if one follows the law, they may still be engaging in immoral behaviour, as Kohlberg argues, because laws and social norms are not perfect. This study makes it easier for future research in the field to look at how the ideas of people like Joao Freire and Carl Rogers can be used in AI systems.Originality/valueIt is an original research that derives inspiration from the cognitive moral development theory of American Professor named Lawrence Kohlberg. The authors present a fresh way of thinking about how to classify AI systems, which should make it easier to give robots cognitive morality.\"\n",
      " 'AbstractThe societal and ethical implications of AI (AI) have sparked discussions among academics, policymakers and the public around the world. What has gone unnoticed so far are the likewise vibrant discussions in China. We analyzed a large sample of discussions about AI ethics on two Chinese social media platforms. Findings suggest that participants were diverse, and included scholars, IT industry actors, journalists, and members of the general public. They addressed a broad range of concerns associated with the application of AI in various fields. Some even gave recommendations on how to tackle these issues. We argue that these discussions are a valuable source for understanding the future trajectory of AI development in China as well as implications for global dialogue on AI governance.'\n",
      " \"In today's research and development, AI (AI) ethics are a complex and urgent issue. Concerns about AI (AI) systems' possible effects on people, communities, and the larger global environment are raised as these systems are incorporated into more and more facets of society. This study examines the ethical implications of AI (AI), looking at topics including privacy, fairness, accountability, transparency, and the possibility of prejudice and discrimination in AI algorithms and decision-making processes. The study endeavours to contribute to the establishment of frameworks and rules that encourage the responsible and ethical use of AI technologies, guaranteeing their conformity with society values and the preservation of human rights, by critically assessing these ethical issues.  Keywords:-AI ethics , AI, ethics, machine ethics, robotics, challenges.\"\n",
      " \"As advances in large language models (LLMs) and multimodal techniques continue to mature, the development of general-purpose multimodal large language models (MLLMs) has surged, offering significant applications in interpreting natural images. However, the field of pathology has largely remained untapped, particularly in gathering high-quality data and designing comprehensive model frameworks. To bridge the gap in pathology MLLMs, we present PathAsst, a multimodal generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology. The development of PathAsst involves three pivotal steps:  data acquisition, CLIP model adaptation, and the training of PathAsst's multimodal generative capabilities. Firstly, we collect over 207K high-quality pathology image-text pairs from authoritative sources. Leveraging the advanced power of GenAI, we generate over 180K instruction-following samples. Furthermore, we devise additional instruction-following data specifically tailored for invoking eight pathology-specific sub-models we prepared, allowing the PathAsst to effectively collaborate with these models, enhancing its diagnostic ability. Secondly, by leveraging the collected data, we construct PathCLIP, a pathology-dedicated CLIP, to enhance PathAsst's capabilities in interpreting pathology images. Finally, we integrate PathCLIP with the Vicuna-13b and utilize pathology-specific instruction-tuning data to enhance the multimodal generation capacity of PathAsst and bolster its synergistic interactions with sub-models. The experimental results of PathAsst show the potential of harnessing AI-powered generative foundation model to improve pathology diagnosis and treatment processes. We open-source our dataset, as well as a comprehensive toolkit for extensive pathology data collection and preprocessing at https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology.\"\n",
      " \"Local governments are in charge of housing, transportation, cleaning, and welfare that directly affect people's daily lives, so there is a high need to apply AI (AI) technologies such as AI CCTV and GenAI to administrative services and policy-making processes. However, compared to the size of local governments' interest in the use of AI, local governments lack the preparation to use AI. In addition, AI has problems such as technical imperfections, privacy infringement, and the spread of discrimination by algorithms. In particular, GenAI that can be applied to various fields will be a key issue. In order for local governments to use AI safely and effectively, local governments should limit the purpose and scope of AI use, increase residents' understanding and ability to use AI, and local governments should more actively protect residents' personal information and establish more public data.\"\n",
      " 'AI (AI) technologies have received significant attention since the launch of GenAI in late 2022. People are experimenting with AI technologies in different aspects of daily life, including the use of AI tools in the scholarly writing process. Researchers and journal publishers are debating the impact of AI technologies on the quality and accountability of scholarly works. Indeed, scholarly journals play an important role in the dissemination of research and should be advising authors on the appropriate and acceptable use of AI technologies in scholarly publishing. Yet very few studies have examined how journals are providing AI-related guidance to authors.\\nThis work-in-progress (WIP) research explores how scholarly journals advise authors about the use of AI in the scholarly writing process by conducting a content analysis of journal policies. Specifically, the study sample was comprised of the top 20 journals, identified using journal metrics provided by Google Scholar in the following subject areas: STEM, humanities, literature & arts, social sciences, and library and information sciences. Policies from these 80 journals were collected from publicly available websites and then examined in August 2024 to assess how journals are currently providing AI-related guidance to authors. The guiding research questions and content analysis focused on the following aspects: 1) The presence or absence of AI in the journal policy; 2) Definition / examples of AI; 3) Guidance on the use of AI for authors; 4) Guidelines about AI for peer reviewers. In this WIP poster, preliminary findings from the content analysis are presented.'\n",
      " 'Since the pandemic, a tremendous amount of research has been conducted on the bio signals and detection of any symptoms early on. Catching symptoms early using the bio-signals would enable early detection, preventive care in some cases, and the potential to create a cure plan for the individual. There are many ways in which the bio-signals can be detected and processed meaningfully. These data would help the individual and be used to train the biosignalbased models. Having these models generate large amounts of data trained on this dataset would enable the detection, diagnosis, and preventive cure more efficiently than ever.'\n",
      " '<p>Predictive maintenance (PdM) is a cost-cutting method that involves avoiding breakdowns and production losses. Deep learning (DL) algorithms can be used for defect prediction and diagnostics due to the huge amount of data generated by the integration of analog and digital systems in manufacturing operations. To improve the predictive maintenance strategy, this study uses a hybrid of the convolutional neural network (CNN) and conditional generative adversarial neural network (CGAN) model. The proposed CNN-CGAN algorithm improves forecast accuracy while substantially reducing model complexity. A comparison with standalone CGAN utilizing a public dataset is performed to evaluate the proposed model. The results show that the proposed CNN-CGAN model outperforms the conditional GAN (CGAN) in terms of prediction accuracy. The average F-Score is increased from 97.625% for the CGAN to 100% for the CNN-CGAN.</p>'\n",
      " 'AbstractRecent research papers and tests in real life point in the direction that machines in the future may develop some form of possibly rudimentary inner life. Philosophers have warned and emphasized that the possibility of artificial suffering or the possibility of machines as moral patients should not be ruled out. In this paper, I reflect on the consequences for moral development of striving for AGI. In the introduction, I present examples which point into the direction of the future possibility of artificial suffering and highlight the increasing similarity between, for example, machine–human and human–human interaction. Next, I present and discuss responses to the possibility of artificial suffering supporting a cautious attitude for the sake of the machines. From a virtue ethical perspective and the development of human virtues, I subsequently argue that humans should not pursue the path of developing and creating AGI, not merely for the sake of possible suffering in machines, but also due to machine–human interaction becoming more alike to human–human interaction and for the sake of the human’s own moral development. Thus, for several reasons, humanity, as a whole, should be extremely cautious about pursuing the path of developing AGI—Artificial General Intelligence.'\n",
      " 'In this exploratory work, we investigate cutting-edge techniques in machine learning known as GenAI (GenAI). The costs of trial and error during product development can be significantly reduced if faster, more affordable, and more accurate multi-scale materials simulations powered by fully GenAI are available. Engineers have spent decades attempting to develop humanoid robots that are both practical and resemble people in appearance and behavior. Because it enables us to circumvent the inherent dimensionality of this obstacle, GenAI has the potential to be a beneficial instrument for the current creation process. Moreover, the research underlines that GenAI, capable of producing media such as text, images, and audio in response to prompts, appears to improve daily. In addition, numerous technological companies are currently building and releasing their competing systems.'\n",
      " \"Incorporating AI (AI) into Human Resource Management (HRM) has become a significant driving force in shaping contemporary workplaces. This paper comprehensively examines AI's influence on HRM, from its foundational concepts to its practical applications, advantages, challenges, ethical considerations, legal ramifications, anticipated trends, and actionable recommendations. Commencing with an introductory framework, the paper navigates the intricate facets of AI within HRM, elucidating its diverse components and functionalities. It further scrutinizes AI's specific roles in recruitment, training, performance management, and employee engagement, emphasizing its transformative potential. Additionally, the paper articulates the manifold benefits AI affords HRM, such as process optimization, informed decision-making, and enhanced employee engagement, juxtaposed against the inherent challenges, including data integrity, privacy concerns, biases, and algorithmic transparency issues. Addressing AI's ethical and legal dimensions in HRM, the paper underscores the imperative of conscientious AI integration and governance. Furthermore, it anticipates forthcoming AI trends and furnishes strategic guidance for organizations navigating this evolving landscape. Ultimately, the paper advocates for ethical, transparent, and human-centric approaches to AI adoption, underscoring its profound impact on HRM practices and workplace dynamics.\"\n",
      " 'AbstractThe adoption of innovative wearable technologies is potentially increasing as a new trend. Jumping into the augmented reality (AR) and Metaverse, Facebook (now known as Meta) launched smart glasses partnering with Ray-Ban sunglasses brand’s parent company EssilorLuxottica. Ray-Ban stories has several technical features for entertainment and socializing; more importantly, these features can be adopted in the future for more advanced wearable. However, these smart glasses also came with many ethical and privacy concerns along with their potential benefits. Furthermore, the unbridled deployment of these smart glasses brought several challenging questions for public social interaction when we will have more such devices in our lives. This short article has discussed the Ray-Ban stories’ ethical and privacy issues for social interaction and public places.'\n",
      " '<p>AI (AI) is likely to transform the way we live and work. Due to its high potential, its adoption is being treated as the fourth industrial revolution. As with any major advancement in technology, it brings with it a spectrum of opportunities as well as challenges. On one hand, several applications have been developed or under development with potential to improve the quality of life significantly. As per a study, it is expected to double the annual economic growth rate of 12 developed countries by 2035. On the other hand, there is a possibility of loss of jobs. As per the available reports, the loss of jobs during the next 10-20 years is estimated to be 47% in the US, 35% in the UK, 49% in Japan, 40% in Australia, and 54% in the EU. In the era of globalization, no country can isolate itself from the impact of the advances in technology. However, the benefits can be maximized and losses can be minimized by putting necessary infrastructure and policy in place. Though several countries have decided their strategy for AI, India has not yet formulated its strategy. The report reviews the international as well as national scenario and suggests way forward for India.\\xa0</p>'\n",
      " ' This paper analyzes the scope of AI (AI) from the perspective of a multimodal grammar. Its focal point is GenAI, a technology that puts so-called Large Language Models to work. The first part of the paper analyzes GenAI, based as it is on the statistical probability of one token (a word or part of a word) following another. If the relation of tokens is meaningful, this is circumstantial and no more, because its mechanisms of statistical analysis eschew any theory of meaning. This is the case not only for the written text that GenAI leverages, but by extension image and multimodal forms of meaning that it can generate. The AI can only work with non-textual forms of meaning after applying language labels, and to that extent is captive not only to the limits of probabilistic statistics but the limits of written language as well. While acknowledging gains arising from the brute statistical power of GenAI, in its second part the paper goes on to map what is lost in its statistical and text-bound approaches to multimodal meaning-making. Our measure of these gains and losses is guided by the concept of grammar, defined here as a theory of the elemental patterns of meaning in the world—not just written text and speech, but also image, space, object, body, and sound. Ironically, a good deal of what is lost by GenAI is computable. The third and final part of the paper briefly discusses educational applications of GenAI. Given both its power and intrinsic limitations, we have been experimenting with the application of GenAI in educational settings and the ways it might be put to pedagogical use. How does a grammatical analysis help us to identify the scope of worthwhile application? Finally, if more of human experience is computable than can be captured in text-bound AI, how might it be possible at the level of code to create a synthesis in which grammatical and multimodal approaches complement GenAI? '\n",
      " 'This essay explores the integration of GenAI (AI) models, including Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), in graphical big data analysis. GenAI offers the generation of synthetic graphical data, improves data visualizations, and aids in pattern recognition within complex datasets. It presents innovative solutions to the challenges posed by large and intricate graphical datasets, enhancing the depth and accuracy of data analysis.'\n",
      " '\\n      \\n        We argue that it is crucial to the future of AI that our students be trained in multiple complementary modes of ethical reasoning, so that they may make ethical design and implementation choices, ethical career decisions, and that their software will be programmed to take into account the complexities of acting ethically in the world.\\n      \\n    '\n",
      " 'Brain-computer interface (BCI) is an interface (or sort of a system) by which humans can communicate with computers. The real question arises about why humans must communicate with the computer via brain signals. There are over a million or more people suffering from diseases or malfunctions of motor ability where mobility is limited, or there is no mobile at all. This interface allows these individuals to communicate with the outside world. Such diseases would rise yearly as more techniques and methods become available to diagnose them. While there is no cure for such injuries or diseases, there may be a stopgap to fill the communication void. We take communication for granted, whereas a person with limited mobility is a boon.'\n",
      " 'The advent of AI (AI) is gradually reshaping society and impacting more and more areas, not excluding media. However, if we want to exploit the potential of this new technological phenomenon as effectively as possible, and in order to maintain established norms of media production, it is necessary to examine the capabilities of AI tools and compare them with human creations. One popular AI tool is GenAI. In media production, it is used, for example, in the creation of journalistic texts, as it is specialized to generate texts in a ‘human way’ based on input data. Therefore, the research paper aims to assess this AI tool in the context of the criteria of press release production as a basic journalistic genre. The object of investigation is to assess and evaluate the fulfilment of the basic criteria set for a quality press release, for two groups of media content – human-generated and GenAI-generated. In the evaluation, the authors will emphasize the fulfillment of the specific criteria formulated in the assignment, noting also the AI’s ability to learn and improve its creations. In its theoretical framework and analytical argumentation, the paper draws on existing knowledge from the literature, including scholarly studies by experts such as H. Pravdová (2016), T. Rončáková (2011), B. Jones et al. (2022), A. Tušer (2010), J. Mistrík (1989), M. Richter (2023), A. Kellerman (2023), B. Dhiman (2023), D. Zagorulko (2023) and others.'\n",
      " '\\n      \\n        This paper reports on two generative systems that work in the domain of textiles: the Hoopla system that generates patterns for embroidery samplers, and the Foundry system that creates foundation paper piecing patterns for quilts. Generated patterns are enacted and interpreted by the human who stitches the final product, following a long and laborious, yet entertaining and leisurely, process of stitching and sewing. The blending of digital and physical spaces, the tension between machine and human authorship, and the juxtaposition of stereotypically masculine computing with highly feminine textile crafts, leads to the opportunity for new kinds of tools, experiences, and artworks. This paper argues for the values of textiles as a domain for generative methods research, and discusses generalizable research problems that are highlighted through operating in this new domain.\\n      \\n    '\n",
      " 'AbstractThe digital divide remains an ongoing societal concern, with digital exclusion shown to have a significantly detrimental impact on people’s quality of life. AI (AI), the latest wave of digitalisation, is being integrated into the fabric of society at an accelerated rate, the speed of which has prompted ethical concerns. Without addressing the digital divide, the AI revolution risks exacerbating the existing consequences of digital exclusion and limiting the potential for all people to reap the benefits provided by AI. To understand the factors that might contribute to experiences of AI, and how these might be related to digital exclusion, we surveyed a diverse online community sample (N\\u2009=\\u2009303). We created a novel measure of digital confidence capturing individual levels of awareness, familiarity, and sense of competence with digital technology. Results indicated that measures of digital confidence were predicted by structural, behavioural, and psychological differences, such that women, older people, those on lower salaries, people with less digital access, and those with lower digital well-being, reported significantly less digital confidence. Furthermore, digital confidence significantly moderated the relationship between people’s experiences with everyday AI technologies and their general attitudes towards AI. This understanding of the spill-over effects of digital exclusion onto experiences of AI is fundamental to the articulation and delivery of inclusive AI.'\n",
      " 'AbstractIn the growing literature on AI (AI) impact assessments, the literature on data protection impact assessments is heavily referenced. Given the relative maturity of the data protection debate and that it has translated into legal codification, it is indeed a natural place to start for AI. In this article, we anticipate directions in what we believe will become a dominant and impactful forthcoming debate, namely, how to conceptualise the relationship between data protection and AI impact. We begin by discussing the value canvas i.e. the ethical principles that underpin data and AI ethics, and discuss how these are instantiated in the context of value trade-offs when the ethics are applied. Following this, we map three kinds of relationships that can be envisioned between data and AI ethics, and then close with a discussion of asymmetry in value trade-offs when privacy and fairness are concerned.'\n",
      " \"We deploy a prompt-augmented GPT-4 model to distill comprehensive datasets on the global application of debt-for-nature swaps (DNS), a pivotal financial tool for environmental conservation. Our analysis includes 195 nations and identifies 21 countries that have not yet used DNS before as prime candidates for DNS. A significant proportion demonstrates consistent commitments to conservation finance (0.86 accuracy as compared to historical swaps records). Conversely, 35 countries previously active in DNS before 2010 have since been identified as unsuitable. Notably, Argentina, grappling with soaring inflation and a substantial sovereign debt crisis, and Poland, which has achieved economic stability and gained access to alternative EU conservation funds, exemplify the shifting suitability landscape. The study's outcomes illuminate the fragility of DNS as a conservation strategy amid economic and political volatility.\"\n",
      " 'AbstractThe aim of this paper is to investigate the relationship between AI urbanism and sustainability by drawing upon some key concepts of Bruno Latour’s philosophy. The idea of a sustainable AI urbanism - often understood as the juxtaposition of smart and eco urbanism - is here critiqued through a reconstruction of the conceptual sources of these two urban paradigms. Some key ideas of smart and eco urbanism are indicated as incompatible and therefore the fusion of these two paradigms is assessed as an unstable basis for shaping sustainable AI urbanism. The concepts in question - modernity, science and nature – are subsequently redefined following Latour’s philosophical perspective, in an attempt to define a different theoretical basis for a sustainable AI urbanism in the Anthropocene. Finally, the principles of a design philosophy shaped by Latour are used to change the design culture that informs AI urbanism towards a more sustainable practice. This paper constructs and promotes a dialogue between the disciplines of philosophy and urban theory with urban design in the conviction that the principles produced by the former and the practices carried out by the latter must start a biunivocal relationship. The paper reveals that in order to change design culture in the field of AI urbanism, it is necessary to rethink some of the key ideas that inform the Western and modern worldview through novel philosophical reflections.'\n",
      " 'AI (AI) is reshaping the world and technology, no longer a futuristic concept but a present reality in our daily lives. Businesses are rapidly adopting AI to automate processes, leading to the creation of intelligent agents known as chatbots. These chatbots have revolutionized business communication and significantly enhanced customer satisfaction. This paper explores the history and development platforms of chatbots, examining their integration into daily life despite often undefined purposes. Chatbots use pattern recognition to generate responses, raising questions about moral issues, security, and legitimacy due to their growing popularity. A key focus is on ChatKanoon, a multilingual AI chatbot designed for the Indian legal system. This study analyzes its impact on the Indian legal framework and its potential to revolutionize legal aid in India and other developing countries. Additionally, the research paper covers the basic features, connectivity, services offered, accuracy, and technology providers of chatbots and virtual assistants implemented by Indian banks.'\n",
      " 'This paper examines the impact and implications of GenAI and other GenAI technologies within the African context while looking at the ethical benefits and concerns that are particularly pertinent to the continent. Through a robust analysis of GenAI and other GenAI systems using established approaches for analysing the ethics of emerging technologies, this paper provides unique ethical benefits and concerns for these systems in the African context. This analysis combined approaches such as anticipatory technology ethics (ATE), ethical impact assessment (EIA), and ethical issues of emerging ICT applications with AI (ETICA) with specific issues from the literature. The findings show that GenAI and other GenAI systems raise unique ethical concerns such as bias, intergenerational justice, exploitation of labour and cultural diversity in Africa but also have significant ethical benefits. These ethical concerns and benefits are considered crucial in shaping the design and deployment of GenAI and similar technologies responsibly. It further explores the potential applications of GenAI in critical domain areas such as education, agriculture, and healthcare, thereby demonstrating the transformative possibilities that these technologies can have on Africa. This paper underscores the critical role of AI governance as Africa increasingly adopts GenAI and similar AI systems. It argues that a comprehensive understanding of AI governance is essential not only for maximising the benefits of GenAI systems but also for facilitating a global dialogue. This dialogue aims to foster shared knowledge and insights between the Global North and the Global South, which is important for the development and creation of inclusive and equitable AI policies and practices that can be beneficial for all regions.'\n",
      " ' This paper critically examines Carlos Montemayor’s human rights-based approach to AI ethics, as presented in his 2023 book The Prospect of a Humanitarian AI. Montemayor proposes that the concept of human rights, grounded in the cognitive needs of human beings, should guide AI development. This paper challenges Montemayor’s moral value-realism (the belief in objective moral values) by arguing for a more inclusive ethical framework that reconciles moral value-realism with skepticism. By proposing an agnostic stance towards moral truths, it suggests a new framework for AI ethics based on subjective intrinsic valuations and shared moral commitments, rather than on objective moral truths. In this proposed framework, without either denying or asserting the existence of absolute values and moral truths, human rights in AI ethics are grounded in collective moral commitments to value human beings intrinsically, rather than in inherent moral truths. This facilitates a more pragmatic and inclusive solution that allows for a diversity of ethical and metaethical perspectives while aligning with the complex nature of AI’s societal integration. The paper concludes that while Montemayor’s work is foundational, it invites further adaptation to develop AI systems that are ethically sound and in harmony with a broad spectrum of human values. '\n",
      " 'As in other healthcare professions, AI will influence midwifery education. To prepare midwifes for a future where AI plays a significant role in healthcare, educational requirements need to be adapted. This scoping review aims to outline the current state of research regarding the impact of AI on midwifery education. The review follows the framework of Arksey and O’Malley and the PRISMA-ScR. Two databases (Academic Search Premier and PubMed) were searched for different search strings, following defined inclusion criteria, and six articles were included. The results indicate that midwifery practice and education is faced with several challenges as well as opportunities when integrating AI. All articles see the urgent need to implement AI technologies into midwifery education for midwives to actively participate in AI initiatives and research. Midwifery educators need to be trained and supported to use and teach AI technologies in midwifery. In conclusion, the integration of AI in midwifery education is still at an early stage. There is a need for multidisciplinary research. The analysed literature indicates that midwifery curricula should integrate AI at different levels for graduates to be prepared for their future in healthcare.'\n",
      " 'AI (AI) has become a multifaceted breakthrough in healthcare with the promise of transforming patient care and clinical practices. The paper presents a comprehensive retrospective mainly concerned with AI and its future scope in health-care services. The paper offers an overview of prevailing trends, illustrating AI’s transformative potential towards diagnostic accuracy, treatment efficiency and operational productivity in healthcare systems. This research paper will delve into the rise of AI in healthcare, from its early stages to technologies that are cutting edge and influencing the future medicine. Furthermore, we will investigate how AI affects patient outcomes, healthcare staff dynamics and the overall healthcare ecosystem through aprism of multidimensionality. The goal of the research as such is to equip all   takeholders with historical trends, current advancements and future trajectories so that they can use AI in healthcare effectively but responsibly. The aim is to create a healthcare environment where there are AI driven improvements in patient care which provide equal opportunity for all.'\n",
      " 'This study presents a method for implementing GenAI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in GenAI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of GenAI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of GenAI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings.'\n",
      " 'In recent years, the field of digital marketing has seen a substantial impact from AI (AI). Digital marketing methods that are more successful and efficient because of the use of AI have changed how firms communicate with their clients. The ability to collect and analyse vast volumes of data using AI-powered tools and technologies has improved marketers understanding of consumer behaviour and preferences. More personalized marketing initiatives have resulted from this, which are more likely to connect with consumers and increase conversion rates. Furthermore, AI has made it possible for companies to automate some marketing processes, including lead generation and customer support, freeing up resources and enabling marketers to concentrate on more complex duties. Aside from privacy issues, the use of AI in digital marketing also prompts worries about the possibility of biases being incorporated into the decision-making process. It will be crucial for marketers to carefully assess the ethical implications of AI use as it develops and try to reduce any bad effects. In general, AI has had a favourable impact on digital marketing, allowing companies to contact and interact with their target consumers more successfully.'\n",
      " \"Counterintelligence (CI) and AI (AI) represent two distinct yet interconnected domains that play pivotal roles in safeguarding National and International Security. On the first hand, CI involves activities and measures taken to identify, prevent and counter any Intelligence activities of hostile entities, such as spying, sabotage and information gathering. On the other hand, AI refers to the development and use of computer systems that can perform tasks that typically require human intelligence, such as learning, reasoning and problem-solving. Subsequently, in the ever-evolving landscape of global security, the rise of AI has ushered in a new era of CI practices.\\xa0The present paper delves into the intersection of CI and AI, exploring the profound impact of AI on the CI processes and how it is transforming National Security strategies, highlighting at the same time the fields of mutually influence. Ultimately, underscores the imperative of harnessing AI's potential to strengthen CI efforts in an ever-evolving threat landscape. Plus, it investigates the ethical concerns and privacy implications associated with AI in CI emphasizing the imperative of responsible AI development and deployment. Finally, through comprehensive international case studies, offers insights into how United States, China, Russia and Israel have integrated AI into their Intelligence and CI strategies, shedding light on the diverse approaches and challenges faced by different countries.\\xa0Summarizing, the paper underscores the potential synergy between AI and CI, while also acknowledging the formidable challenges it presents, such as privacy concerns and adversarial AI. Striking a balance between harnessing AI's power and safeguarding national interests remains a pivotal task for policymakers and intelligence agencies in the ever-evolving landscape of national security.\"\n",
      " \"PurposeUsing AI to strengthen creativity and problem-solving capabilities of professionals involved in innovation management holds huge potential for improving organizational decision-making. However, there is a lack of research on the use of AI technologies by innovation managers. The study uses the theory of appropriation to explore how specific factors – agile leadership (AL), innovation orientation (IO) and individual creativity (IC) – impact innovation managers' use of GenAI tools, such as GenAI (CGA).Design/methodology/approachThe research model is tested through a large-scale survey of 222 Italian innovation managers. Data have been analyzed using structural equation modeling following a two-step approach. First, the measurement model was assessed to ensure the constructs reliability. Subsequently, the structural model was analyzed to draw the conclusions on theorized model relationships and their statistical significance.FindingsThe research findings reveal positive associations between IO and IC with CGA, demonstrating that innovation managers who exhibit strong innovation orientations and higher Individual Creativity are more likely to adopt and personalize GenAI. However, the study did not confirm a significant association between AL and CGA.Originality/valueOur findings have important implications for organizations seeking to maximize the potential of GenAI in innovation management. Understanding the factors that drive the adoption and customization of GenAI tools can inform strategies for better integration into the innovation process, thereby leading to enhanced innovation outcomes and improved decision-making processes.\"\n",
      " 'This study delves into the factors that drive teachers’ adoption of GenAI (GenAI) technologies in higher education. Anchored by the technology acceptance model (TAM), the research expands its inquiry by integrating the constructs of intelligent technological pedagogical content knowledge (TPACK), AI literacy, and perceived trust. Data were gathered from a sample of 237 university teachers through a structured questionnaire. The study employed structural equation modeling (SEM) to determine the relationships among the constructs. The results revealed that both AI literacy and perceived ease were the most influential factors affecting teachers’ acceptance of GenAI. Notably, intelligent TPACK and perceived trust were found to be pivotal mediators in this relationship. The findings underscore the importance of fostering AI literacy and adapting intelligent TPACK frameworks to better equip educators in the age of AI. Furthermore, there is a clear need for targeted professional development initiatives focusing on practical training that enhances AI literacy. These programs should provide hands-on experience with GenAI tools, boosting educators’ confidence and ability to integrate them into their teaching practices.'\n",
      " 'In the world of sudden pandemic, there has been always a need to develop interactive and novel solutions in the field of education when compared to other sectors.'\n",
      " 'AI (AI) has emerged as one of the central topics of 2023 with extensive media coverage of the most relevant technologies and issues associated with this subject. In a highly competitive digital media landscape, search engine optimization (SEO) has become cybermedia’s primary strategy to increase visibility and attract more readers. The objective of this paper is to analyze the visibility of content published by the media relating to AI, focusing on a selection of related keywords. The research also aims to investigate how this visibility has impacted both the technologies themselves and the analyzed media outlets. A total of 69 media outlets from 12 European Union countries, the United States, and the United Kingdom were examined. The results reveal a pronounced dominance of U.S. media, closely followed by Spanish media. There is an uneven distribution of media outlets across most of the countries analyzed, with two or three most of the of visibility. The search queries that contribute the most visibility to the analyzed media align with an informational intent, are of the long-tail type, and are associated with OpenAI technologies, particularly GenAI. Moreover, these queries are primarily found in news sections dedicated to science and technology. The findings underscore both the increasing interest in the subject and the effective SEO practices of certain media outlets.'\n",
      " 'AbstractThe NSF AI Institute for AI and Fundamental Interactions (IAIFI, pronounced /aI‐faI/) is one of the inaugural NSF AI research institutes (https://iaifi.org). The IAIFI is enabling physics discoveries and advancing foundational AI through the development of novel AI approaches that incorporate first principles from fundamental physics. By combining state‐of‐the‐art research with early career talent and a growing AI + physics community in the Boston area and beyond, the IAIFI is enabling researchers to develop AI technologies to tackle some of the most challenging problems in physics, and transfer these technologies to the broader AI community. Since trustworthy AI is as important for physics discovery as it is for other applications of AI in society, IAIFI researchers are applying physics principles to develop more robust AI tools and to illuminate existing AI technologies. To cultivate human intelligence, the IAIFI promotes training, education, and public engagement at the intersection of physics and AI. In these ways, the IAIFI is fusing deep learning with deep thinking to gain a deeper understanding of our universe and AI.'\n",
      " 'AbstractThe advancement of AI (AI) and Machine Learning (ML) has profound implications for both the utility and security of our digital interactions. This paper investigates the transformative role of GenAI in Social Engineering (SE) attacks. We conduct a systematic review of social engineering and AI capabilities and use a theory of social engineering to identify three pillars where GenAI amplifies the impact of SE attacks: Realistic Content Creation, Advanced Targeting and Personalization, and Automated Attack Infrastructure. We integrate these elements into a conceptual model designed to investigate the complex nature of AI-driven SE attacks—the GenAI Social Engineering Framework. We further explore human implications and potential countermeasures to mitigate these risks. Our study aims to foster a deeper understanding of the risks, human implications, and countermeasures associated with this emerging paradigm, thereby contributing to a more secure and trustworthy human-computer interaction.'\n",
      " 'The utilisation of AI (AI) technology has caused remarkable changes that have taken place in the educational landscape. Through the integration of AI in online learning systems, an entirely new educational experience has been introduced, altering the ways learners and educators can interact. The emergence and evolution of AI technology have increased efficiency and productivity, enhancing teaching and learning outcomes. AI in online learning provides a distinct advantage by providing real-time feedback to learners. Traditional learning environments often suffer from the limitation of delayed feedback, impeding learners’ progress and demotivating them. However, AI-powered online learning systems excel in delivering immediate feedback to learners, enabling them to promptly identify and rectify mistakes and enhance their performance in real-time. This timely feedback fosters a supportive learning environment that encourages learners to engage in the learning process actively. The research by Vanlehn, Lynch, Schulze, Shapiro, Shelby, Taylor et al. (2005) on the Andes physics tutoring system serves as a valuable resource for understanding the lessons learned from utilising AI to support learner-instructor interaction. In contrast to traditional learning environments that offer delayed feedback, impeding the progress of learners and possibly dampening their motivation, AI-powered online learning systems provide real-time feedback. With real-time feedback, learners can instantly correct mistakes and improve their performance, thereby advancing their learning outcomes (Zhou & Mei, 2021). This literature review explores the impact of AI on learner-instructor interaction in online learning environments. The review considers how AI technology enhances and diversifies the learning process, focusing on personalised learning, real-time feedback provision, and content delivery.'\n",
      " 'PurposeThe paper aims to examine the impacts and ethics of utilizing AI (AI) in Indian policing. It explores both the positive and negative consequences of using AI, as well as the ethical considerations that have be taken into account.Design/methodology/approachThis study is based on secondary sources of information, such as national and international reports, journal articles, and institutional websites that discuss the use of AI technology by the police in India.FindingsAI has proven to be effective in policing, from preventing crime to identifying criminals, by detecting potential crimes in advance with fewer resources and in more areas. In India, the police use AI technology not only for facial recognition but also for crime mapping, analysis, and building blocks. However, factors such as caste, religion, language, and gender continue to cause conflict. India has shown a strong interest in using AI technology for policing, and wishes to accelerate its implementation in various policing contexts, including law and order. This paper calls for an assessment of the complexities and uncertainties brought about by new technologies in policing with ethical considerations.Originality/valueThis paper can provide valuable insights for policy-makers, academics, and practitioners engaged in discussions and debates concerning the ethical considerations associated with the adoption of AI tools in policing practices.'\n",
      " 'AI (AI)-based generative imaging systems such as DALL·E, Midjourney, Stable Diffusion, and Adobe Firefly, which work by transforming natural language descriptions into images, are revolutionizing computer vision. In this exploratory and qualitative research, we have replicated requests for images of women in different professions by comparing these representations in previous studies with DALL·E, observing that this model continues to provide in its last version, DALL·E 3, inequitable results in terms of gender. In addition, Bing Image Creator, Microsoft’s free tool that is widely used among the population and runs under DALL·E, has been tested for the first time. It also presents a sexualization of women and stereotypical children’s representations. The results reveal the following: 1. A slight improvement in terms of the presence of women in professions previously shown only with men. 2. They continue to offer biased results in terms of the objectification of women by showing sexualized women. 3. The representation of children highlights another level of gender bias, reinforcing traditional stereotypes associated with gender roles from childhood, which can impact future decisions regarding studies and occupations.'\n",
      " 'AI technology has gradually matured, and new technologies are being innovated in all walks of life, and are widely used in various disciplines such as psychology, linguistics, medicine and philosophy. In the field of radio and television, the emergence of \"AI\" synthetic anchors has made the hosts feel the pressure and challenges, what kind of path is the future development of \"AI\" synthetic anchors? In this article, we will start from Xinhua News Agency\\'s \"AI\" synthetic anchor \"New Xiaohao\" and \"New Xiaowei\" to discuss the development of \"AI\" synthetic anchors in the context of AI. The development path of \"AI\" synthetic anchor in the background of AI.'\n",
      " 'AbstractHumans are responsible moral agents in part because they can competently respond to moral reasons. Several philosophers have argued that artificial agents cannot do this and therefore cannot be responsible moral agents. I present a counterexample to these arguments: the ‘Moral Decision Machine’. I argue that the ‘Moral Decision Machine’ responds to moral reasons just as competently as humans do. However, I suggest that, while a hopeful development, this does not warrant strong optimism about ‘artificial moral agency’. The ‘Moral Decision Machine’ (and similar agents) can only respond to moral reasons by deferring to others, and there are good reasons to think this is incompatible with responsible moral agency. While the challenge to artificial moral agency based on moral reasons-responsiveness can be satisfactorily addressed; the challenge based on moral deference remains an open question. The right way to understand the challenge, I argue, is as a route to the claim that artificial agents are unlikely to be responsible moral agents because they cannot be authentic.'\n",
      " 'AbstractThis paper reflects on the tech industry’s colonization of the AI ethics research field and addresses conflicts of interest in public policymaking concerning AI. The AI ethics research community faces two intertwined challenges: In the first place, we have a tech industry heavily influencing the AI ethics research agenda. Secondly, cleaning up after the tech industry has implied that we have turned to value-driven design methods to bring ethics to AI design. But by framing research questions relevant to a technical practice, we have facilitated the technological solutionism behind the tech industry’s business model. Therefore, this paper takes the first steps to reshape the AI ethics research agenda by suggesting moving toward an emancipatory framework that brings politics to design while, at the same time, bearing in mind that AI is not to be treated as an inevitability. As a research community, we must focus on the repressive power dynamics exacerbated by AI and address challenges facing the vulnerable groups seldom heard, despite the fact that they are the ones most negatively affected by AI initiatives.'\n",
      " 'The article analyzes the interaction between creator and audience that occurs in the new modes of art practices. Within this field, experimenting with technology is accompanied by emergence of new art forms and genres. Thus, it seems appropriate to view technologies as a mediator in the dynamic process of communication between the creator and viewer. In this context, a number of innovative projects were considered that emerged in the art practices of the recent decades. The choice of the projects is determined by the specific expressive means and by the features of interaction of these means on the basis of contemporary technologies. Creation of these projects resulted from the ideas and achievements of the 1970s–1990s. At first, it was \"pure\" experimentation, aimed at expanding the range of new expressive components and testing them. Afterwards, modern art products created within this direction are mature and complete. To evoke the interest of the audience, the use of multimedia and installations based on interactive technologies are employed. Technologies stimulate further evolution of art, i.e. they contribute to forming the new genres, and trends. It was concluded that technologies constitute a toolkit that de facto serves as a catalyst enabling practical realization of the artistic polylogue within the creative process: from the point when the idea is conceived, through its fulfillment in the creator’s design and up to its presentation when its communicative models of influence aimed at the art communities are activated.'\n",
      " 'ABSTRACT\\nRecent applications of new innovations in AI have brought up questions about how this new technology will change the landscape and practices in a wide range of industries and sectors. This article focuses on the impact of generative large language models on teaching, learning, and academic assessment in political science education by analyzing two novel surveys administered by the discipline’s major professional body, the American Political Science Association. We present the results of these surveys and conclude with recommendations.'\n",
      " \"AbstractAn appropriate ethical framework around the use of AI (AI) in healthcare has become a key desirable with the increasingly widespread deployment of this technology. Advances in AI hold the promise of improving the precision of outcome prediction at the level of the individual. However, the addition of these technologies to patient–clinician interactions, as with any complex human interaction, has potential pitfalls. While physicians have always had to carefully consider the ethical background and implications of their actions, detailed deliberations around fast-moving technological progress may not have kept up. We use a common but key challenge in healthcare interactions, the disclosure of bad news (likely imminent death), to illustrate how the philosophical framework of the 'Felicific Calculus' developed in the eighteenth century by Jeremy Bentham, may have a timely quasi-quantitative application in the age of AI. We show how this ethical algorithm can be used to assess, across seven mutually exclusive and exhaustive domains, whether an AI-supported action can be morally justified.\"\n",
      " 'In the context of the emerging digital environment, GenAI (GAI) is quickly becoming implemented in different spheres of life and even begins to replace people in some professions. This means that GAI is leading a new round of technological and industrial revolution. The application and growth of AI has improved the society as well as the economy and but has issued many ethical and social problems thus making ethical governance of AI more relevant. To contribute to the further development of the concept GAI under the conditions of sustainable development of human society and science, industries and scholars around the world have started researches on this technology. However, as GAI is still an embryonic field, more research efforts must be directed toward this field in the future. Researched articles that compare the use of GAI to the effects on ethical and societal concerns will form the basis of this paper and the resulting discussion of the pros and cons of this technology, this paper considers and demonstrates the difficulties of students, educators, and academics facing the consequences of GAI development. Finally, it has suggestion for the governance of GAI’s next phase of growth.'\n",
      " 'GenAI, especially with regard to the generative adversarial network (GAN), is an important research area in radiology as evidenced by a number of literature reviews on the role of GAN in radiology published in the last few years. However, no review article about GAN in pediatric radiology has been published yet. The purpose of this paper is to systematically review applications of GAN in pediatric radiology, their performances, and methods for their performance evaluation. Electronic databases were used for a literature search on 6 April 2023. Thirty-seven papers met the selection criteria and were included. This review reveals that the GAN can be applied to magnetic resonance imaging, X-ray, computed tomography, ultrasound and positron emission tomography for image translation, segmentation, reconstruction, quality assessment, synthesis and data augmentation, and disease diagnosis. About 80% of the included studies compared their GAN model performances with those of other approaches and indicated that their GAN models outperformed the others by 0.1–158.6%. However, these study findings should be used with caution because of a number of methodological weaknesses. For future GAN studies, more robust methods will be essential for addressing these issues. Otherwise, this would affect the clinical adoption of the GAN-based applications in pediatric radiology and the potential advantages of GAN could not be realized widely.'\n",
      " 'The objective of this research is 1) to develop an AI Artist Assistant (AIAA) model for the purpose of innovative digital storytelling in digital art education, 2) to evaluate the AIAA model, and 3) to study the results of the implemented model. The sample consists of two groups. The first group is made up of five experts in the field of AI, digital art, and storytelling, while the second group consists of 33 volunteers; they were tasked with creating animated storytelling. The research results show that the developed model consists of 3 elements. The first element is input, the second element is the AIAA process, and the third element is output. The five experts awarded the AIAA model the highest level of satisfaction (xˉ = 4.93, S.D. = 0.13), suitable for promoting storytelling. In addition, the 33 volunteers who tested the model awarded it a high level of satisfaction (xˉ = 3.78, S.D. = 0.83), that such AIAA model can help artists create better storytelling and enhance the storytelling process, in terms of speed of the process and details that enhance the story.'\n",
      " 'AbstractBased on the dynamic capabilities (DC) theory, the aim of this study is to investigate the contribution of GenAI (GAI) to the development of customer personalisation (CP) within business organisations, particularly SMEs. This paper also explores how the function of GAI in the development of CP is supported by technological advancements like deep learning (DL), smart data (SD), and the Internet of Things (IoT). Using a theoretical\\xa0framework based on DC theory and an analysis of the literature on GAI, DL, SD, IoT, and CP, the relationship between GAI and CP is theoretically studied. The dependent variable in this theoretical framework is CP, and the independent variable is GAI. Furthermore, while DL and SD just mediate the connection between GAI and CP, IoT moderates the relationship between GAI and SD. Figure\\xa01 presents the theoretical framework and research propositions. On the basis of the constructs in this study, research propositions\\xa0were developed and discussed. Eight significant research propositions on the relationship between GAI and CP development were developed using the theoretical framework used in this study. According to the suggested theoretical framework and research propositions, context-oriented CP can be created by GAI using DL and SD in conjunction with IoT when high-level customer attributes are retrieved in a structured, accurate, and real-time manner. Additionally, it results in important marketing outcomes including interactive marketing, value co-creation, and consumer loyalty. This study develops a theoretical framework and research propositions that theorise the relationship between GAI and CP which is rooted in literature and also based on DC perspective. The mediating roles of DL and SD on the relationship between GAI and CP, and the moderating role of IoT on the relationship between GAI and SD, provide support to GAI in the development of CP. This study also provides insight into SMEs’ adoption of GAI to generate context-oriented CP that may impact on their marketing development in areas such as interactive marketing, value co-creation, better targeting and customer loyalty.'\n",
      " 'The GenAI concept, which enables users to create text, image, and video content through prompts, is revolutionizing the content side and AI applications in marketing. Despite the increasing popularity of GenAI applications, the market perception regarding GenAI remains underexplored. This study aims to explore the GenAI market perception through the context of mobile applications with the help of user reviews. The study follows a structured approach including identifying the GenAI mobile applications, assessing the context through rating scores and install amounts of mobile applications, and using a topic modeling approach (BerTopic) for online reviews to identify the topics included in the conversation. 8159 user reviews from 22 mobile applications are used as sample of the study and the average rating score for the sample found as 4,06 which signals a positive perception of market. The study concludes top ten topics as; “Dissatisfaction About Amount of Advertisements in app”, “NSFW Content and Moderation”, “Praise of Application”, “Functionality Problems & Crashes”, “Payment Necessity and Trial Problems”, “In-App Purchase Restoration Problems”, “Specific Feature in App”, “Chat Function”, “Credit System” and “Excess of Ads”. The study reveals the main issues of Ai Art mobile applications for marketing decision-making processes.'\n",
      " 'The purpose of this study is to examine the benefits and drawbacks of applying AI in media. The research focuses on the evolution of AI and the moral quandaries that it raises. To begin, a historical overview of AI is offered. Then its use in the media is described. Following that, the benefits and drawbacks of AI are discussed. Finally, the potential for future advancement and ethical consequences are examined. AI is a powerful tool with diverse applications, but it currently has severe disadvantages, particularly on an ethical level'\n",
      " 'AbstractThis study investigates how patterns of media use and exposure to media messages are related to attitudes about AI (AI) image generators. In doing so, it builds on theoretical accounts of media framing and public opinion about science and technology topics, including AI. The analyses draw on data from a survey of the US public (N\\u2009=\\u20091,035) that included an experimental manipulation of exposure to tweets framing AI image generators in terms of real art, artists’ concerns, artists’ outrage, or competing interpretations. The results show that technology news use and science fiction viewing predicted support for AI art but also predicted belief that AI image generators will take jobs and steal art styles from human artists. In addition, the experimental results demonstrate that exposure to specific media messages can influence these responses. The findings carry implications for understanding the future adoption, use, and regulation of AI image generators.'\n",
      " \"Despite the growing prominence of GenAI (GenAI) in the education landscape, there is limited research regarding its acceptance in the Philippines. Hence, the researchers studied the intention to use and acceptance of GenAI among college students and educators at Bulacan State University utilizing the constructs from the Unified Theory of Acceptance and Use of Technology framework. The study employed a quantitative approach through a survey questionnaire and interviews to gather actionable insights. Structural Equation Modeling (SEM) was used to investigate how the constructs affect the college students' intention to use and acceptance of GenAI while the Welch's t-test was used to determine if a significant difference exists in their acceptance of GenAI. The findings revealed that 85.84% college students used GenAI while 76.11% educators used the tool. Moreover, both groups demonstrated a moderate knowledge of GenAI's limitations, with Welch's t-test revealing no significant difference exists in their acceptance levels of GenAI. Key findings showcase that effort expectancy and behavioral intention affect the acceptance of college students on GenAI tools, while performance expectancy and facilitating conditions affect their behavioral intention. However, social influence does not significantly affect their intention to use and acceptance of GenAI. Out of all factors, only facilitating conditions displayed a significant total effect on their GenAI acceptance, revealing the importance of the institution's role regarding this technology.\"\n",
      " 'AbstractSeveral technological developments, such as self-service technologies and AI (AI), are disrupting the retailing industry by changing consumption and purchase habits and the overall retail experience. Although AI represents extraordinary opportunities for businesses, companies must avoid the dangers and risks associated with the adoption of such systems. Integrating perspectives from emerging research on AI, morality of machines, and norm activation, we examine how individuals morally behave toward AI agents and self-service machines. Across three studies, we demonstrate that consumers’ moral concerns and behaviors differ when interacting with technologies versus humans. We show that moral intention (intention to report an error) is less likely to emerge for AI checkout and\\xa0self-checkout machines compared with human checkout. In addition, moral intention decreases as people consider the machine less humanlike. We further document that the decline in morality is caused by less guilt displayed toward new technologies. The non-human nature of the interaction evokes a decreased feeling of guilt and ultimately reduces moral behavior. These findings offer insights into how technological developments influence consumer behaviors and provide guidance for businesses and retailers in understanding moral intentions related to the different types of interactions in a shopping environment.'\n",
      " '\\nBackground\\nEmerging AI (AI) applications have the potential to improve health, but they may also perpetuate or exacerbate inequities.\\n\\n\\nObjective\\nThis review aims to provide a comprehensive overview of the health equity issues related to the use of AI applications and identify strategies proposed to address them.\\n\\n\\nMethods\\nWe searched PubMed, Web of Science, the IEEE (Institute of Electrical and Electronics Engineers) Xplore Digital Library, ProQuest U.S. Newsstream, Academic Search Complete, the Food and Drug Administration (FDA) website, and ClinicalTrials.gov to identify academic and gray literature related to AI and health equity that were published between 2014 and 2021 and additional literature related to AI and health equity during the COVID-19 pandemic from 2020 and 2021. Literature was eligible for inclusion in our review if it identified at least one equity issue and a corresponding strategy to address it. To organize and synthesize equity issues, we adopted a 4-step AI application framework: Background Context, Data Characteristics, Model Design, and Deployment. We then created a many-to-many mapping of the links between issues and strategies.\\n\\n\\nResults\\nIn 660 documents, we identified 18 equity issues and 15 strategies to address them. Equity issues related to Data Characteristics and Model Design were the most common. The most common strategies recommended to improve equity were improving the quantity and quality of data, evaluating the disparities introduced by an application, increasing model reporting and transparency, involving the broader community in AI application development, and improving governance.\\n\\n\\nConclusions\\nStakeholders should review our many-to-many mapping of equity issues and strategies when planning, developing, and implementing AI applications in health care so that they can make appropriate plans to ensure equity for populations affected by their products. AI application developers should consider adopting equity-focused checklists, and regulators such as the FDA should consider requiring them. Given that our review was limited to documents published online, developers may have unpublished knowledge of additional issues and strategies that we were unable to identify.\\n'\n",
      " 'Nutmeg seeds can produce a lot of oil if they have optimal maturity, in other words, they have little moisture content. Based on observations I made at one of the refineries in Sukabumi, farmers do not pay attention to the maturity level of nutmeg seeds after drying which can cause a decrease in the quality of nutmeg seeds and the quality of the oil produced. This study aims to make it easier for nutmeg farmers to classify the maturity of nutmeg seeds. This study used the Convolutional Neural Network (CNN) method to help with classification problems and several image processing methods. This program will be run through an android application. The results of CNN model training accuracy are 97.92%. Thus, it can be concluded that the design and testing of a model to classify the maturity level of nutmeg seeds using AI and the implementation of the model into an android application has been successfully carried out.'\n",
      " 'This study is an in-depth exploration of the nascent field of Natural Language Processing (NLP) and GenAI (AI), and it concentrates on the vital task of distinguishing between human-generated text and content that has been produced by AI models. Particularly, this research pioneers the identification of financial text derived from AI models such as GenAI and paraphrasing tools like QuillBot. While our primary focus is on financial content, we have also pinpointed texts generated by paragraph rewriting tools and utilized GenAI for various contexts this multiclass identification was missing in previous studies. In this paper, we use a comprehensive feature extraction methodology that combines TF–IDF with Word2Vec, along with individual feature extraction methods. Importantly, combining a Random Forest model with Word2Vec results in impressive outcomes. Moreover, this study investigates the significance of the window size parameters in the Word2Vec approach, revealing that a window size of one produces outstanding scores across various metrics, including accuracy, precision, recall and the F1 measure, all reaching a notable value of 0.74. In addition to this, our developed model performs well in classification, attaining AUC values of 0.94 for the ‘GPT’ class; 0.77 for the ‘Quil’ class; and 0.89 for the ‘Real’ class. We also achieved an accuracy of 0.72, precision of 0.71, recall of 0.72, and F1 of 0.71 for our extended prepared dataset. This study contributes significantly to the evolving landscape of AI text identification, providing valuable insights and promising directions for future research.'\n",
      " 'PurposeAI (AI) and the more recent generative technologies are disrupting many activities related to strategy and operations within organizations. Business model design is no exception. We define business model design as an iterative process involving a combination of creativity, decisions, and tests, consisting of envisioning and creating a business model (for a brand-new activity) or a new business model (for an existing activity), to change an existing situation into a preferred one. In this paper, we discuss the potential impact of generative technologies on the business model design process, highlighting the opportunities and challenges that these technologies present and suggesting some methods for using generative technologies for business model design.\\r\\nDesign/Methodology/ApproachWe build on knowledge about business model design and on documentation from forums, social networks, and media about generative technologies. We also used GenAI platforms to test dozens of prompts related to business model design.\\r\\nFindingsWe propose the IDEATe process for business model design and identify six major changes in the process or the outcome of business model design that generative technologies can trigger. We also discuss blind spots and risks associated with the use of generative technologies for business model design. Finally, we advance some functions of generative technologies that may support this process.\\r\\nOriginality/ValueInstead of focusing on how generative technologies could change business models, we investigate how these technologies could impact the design of business models. We make propositions to use these technologies properly for business model design.'\n",
      " ' Large Language Models (LLMs), exemplified by GPT-4, have transcended traditional boundaries in language processing, demonstrating remarkable capabilities in understanding and generating nuanced text. Crucially, these models are pioneering a paradigm shift in AI (AI) applications — from solving narrowly defined problems to navigating complex, real-world scenarios. Such a shift is based on a simple and fundamental principle: LLMs can process any data that can be serialized and tokenized, enabling them to engage in multifaceted reasoning and utilize diverse tools. This capability positions LLMs to operate effectively in broader, more intricate contexts, marking a leap in AI’s practical applicability and potential. '\n",
      " 'Abstract\\n\\nObjectives:\\nTools based on GenAI (AI) such as GenAI have the potential to transform modern society, including the field of medicine. Due to the prominent role of language in psychiatry, e.g., for diagnostic assessment and psychotherapy, these tools may be particularly useful within this medical field. Therefore, the aim of this study was to systematically review the literature on GenAI applications in psychiatry and mental health.\\n\\n\\nMethods:\\nWe conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. The search was conducted across three databases, and the resulting articles were screened independently by two researchers. The content, themes, and findings of the articles were qualitatively assessed.\\n\\n\\nResults:\\nThe search and screening process resulted in the inclusion of 40 studies. The median year of publication was 2023. The themes covered in the articles were mainly mental health and well-being in general – with less emphasis on specific mental disorders (substance use disorder being the most prevalent). The majority of studies were conducted as prompt experiments, with the remaining studies comprising surveys, pilot studies, and case reports. Most studies focused on models that generate language, GenAI in particular.\\n\\n\\nConclusions:\\nGenAI in psychiatry and mental health is a nascent but quickly expanding field. The literature mainly focuses on applications of GenAI, and finds that GenAI performs well, but notes that it\\xa0is limited by significant safety and ethical concerns. Future research should strive to enhance transparency of methods, use experimental designs, ensure clinical relevance, and involve users/patients in the design phase.\\n'\n",
      " 'Public and private investments into developing digital health technologies—including AI (AI)—are intensifying globally. Japan is a key case study given major governmental investments, in part through a Cross-Ministerial Strategic Innovation Promotion Program (SIP) for an “Innovative AI Hospital System.” Yet, there has been little critical examination of the SIP Research Plan, particularly from an ethics approach. This paper reports on an analysis of the Plan to identify the extent to which it addressed ethical considerations set out in the World Health Organization’s 2021 Guidance on the Ethics and Governance of AI for Health. A coding framework was created based on the six ethical principles proposed in the Guidance and was used as the basis for a content analysis. 101 references to aspects of the framework were identified in the Plan, but attention to the ethical principles was found to be uneven, ranging from the strongest focus on the potential benefits of AI to healthcare professionals and patients (n\\u2009=\\u200944; Principle 2), to no consideration of the need for responsive or sustainable AI (n\\u2009=\\u20090; Principle 6). Ultimately, the findings show that the Plan reflects insufficient consideration of the ethical issues that arise from developing and implementing AI for healthcare purposes. This case study is used to argue that, given the ethical complexity of the use of digital health technologies, consideration of the full range of ethical concerns put forward by the WHO must urgently be made visible in future plans for AI in healthcare.'\n",
      " 'The medical technological revolution has transformed the nature with which we deliver care. Adjuncts such as AI and machine learning have underpinned this. The applications to the field of endoscopy are numerous. Malignant polyps represent a significant diagnostic dilemma as they lie in an area in which mischaracterisation may mean the difference between an endoscopic procedure and a formal bowel resection. This has implications for patients’ oncological outcomes, morbidity and mortality, especially if post-procedure histopathology upstages disease. We have made significant strides with the applications of AI to colonoscopic detection. Deep learning algorithms are able to be created from video and image databases. These have been applied to traditional, human-derived, classification methods, such as Paris or Kudo, with up to 93% accuracy. Furthermore, multimodal characterisation systems have been developed, which also factor in patient demographics and colonic location to provide an estimation of invasion and endoscopic resectability with over 90% accuracy. Although the technology is still evolving, and the lack of high-quality randomised controlled trials limits clinical usability, there is an exciting horizon upon us for AI-augmented endoscopy. '\n",
      " 'AI (AI) is revolutionizing the healthcare sector in various ways, from boosting diagnostic performance and patient management to speeding up clinical operations and lowering medical costs. Medical imaging analysis, medication discovery, patient monitoring, and patient communication and assistance are just a few of the uses for AI-powered solutions. The influence of AI in healthcare is broad, with the potential to change healthcare delivery. Implementing AI in healthcare would enhance patient outcomes, safety, and experience and empower healthcare organizations to function efficiently and effectively. Although there are some reservations regarding the ethical and privacy implications of AI in healthcare, the benefits are evident as technology evolves and progresses. As AI develops extensively and is incorporated into the healthcare business, we may expect to see even more significant and positive outcomes in the coming years. The purpose of this paper is to examine the effects of AI on healthcare and to investigate its potential benefits and challenges.'\n",
      " 'AbstractThe current state of human–machine interaction has set forth a process of hybridization of human identity. Technology—and most notably AI—is used as an effective cognitive extender, which enables the extension of human personhood to include artificial elements, leading to the emergence of artificial identity. Discussing—and accommodating—anthropomorphization in human–machine interaction should no longer be the primary focus. Rather, the scope and quality of frameworks in which the hybridization of human identity occurs and evolves has significant ethical implications that pose very pragmatic challenges to users, the industry, and regulators. This paper puts forth a few main principles upon which such a discussion should evolve. We illustrate why disruptiveness can easily turn into human harm when the frameworks facilitating it overlook the human vulnerabilities that arise from hybrid identity, notably the asymmetric and asynchronous relationship between the human and artificial counterparts. Finally, we claim that these new types of vulnerabilities, to which a person is exposed due to the intimate degree of pairing with technology, justifies introducing and protecting artificial identity as well.'\n",
      " 'Creative designs workshop with GenAI was held'\n",
      " 'AI (AI) and Machine Learning (ML) have shown great success in many areas such as computer vision, natural language processing, and knowledge discovery. However, AI research to deliver social benefits and impacts is less explored while imminent needed. Guided by the United Nations’ Sustainable Development Goals, my research involves the development of advanced AI techniques, in particular Deep Graph Learning (DGL), to address the grand societal challenges and further apply them to various social good applications for improving our society and people’s daily life, namely DGL for Social Good (DGL4SG). Achieving the goal is not easy since challenges come from the increasing complexity of many factors including problems, data, and techniques, which require long-term and concentrated effort. DGL presents a good opportunity to build better solutions and tools due to its strong capability in learning and inferring graph data which is ideal for modeling many real-world social good systems. Fortunately, I have been working on DGL with continued contributions and impacts since my graduate study. The special research experience lifts me up to a unique position for conducting research that intersects AI, DGL, and social good, and pushing the field of DGL4SG forward.'\n",
      " \"This integrative literature review (ILR) examines the impact of AI (AI) on legal systems, focusing on technologies such as natural language processing (NLP), machine learning (ML), and AI-driven decision support systems. The research problem addresses the need to understand how AI enhances efficiency, precision, and data handling in legal operations, transforming tasks like document analysis and decision-making procedures. The ILR aims to comprehensively understand AI integration in legal systems, considering its advantages and difficulties. It is guided by a conceptual framework based on AI, legal analytics, and decision support systems to enhance efficiency, accuracy, and innovation. Using a systematic methodology, the review integrates and examines existing research, evaluating AI's tangible benefits and ethical implications. The findings indicate that while AI can revolutionize legal systems, the study underscores the importance of continuous oversight, frequent evaluations, and developing AI models with the ability to identify and correct biases. Future research should prioritize longitudinal studies to assess AI's enduring effects, address ethical considerations, and encompass various legal and geographical contexts. Encouraging cross-disciplinary cooperation and utilizing diverse research methodologies is crucial to ensure that AI improves legal services while maintaining the integrity and impartiality of judicial procedures, and it makes the audience feel included and part of the AI revolution in legal systems.\"\n",
      " 'The scientific article presents the results of the research on the peculiarities of AI technology’s impact on the transformation of business process management systems, management decision-making, and organizations’ management improvement in all sectors of the economy. The relevance of the work on the selected issue is determined by the formation of a digital economy model in which technology, including AI, contributes to improving the efficiency of management and the economic activities of business entities. The object of the study is AI (AI) technologies. The subject of the study is the impact of AI technologies on management practices and economic activities of commercial organizations. Within the framework of the scientific article, the theoretical and practical aspects of the concept of “AI” are considered. The factors that caused the development of AI technologies in modern economics and management are identified. The main directions of influence of AI technology in the management activities of organizations are analyzed. The prospects and possibilities of AI technology in economics and management are addressed. The actual problems that create threats and barriers to the introduction and effective use of AI technology with the improvement of the management system at the enterprise are identified. The conclusions of the article establish that the impact of AI on the economy and management forms a sustainable foundation for successful digital transformation by increasing the economic efficiency of economic activity and management.'\n",
      " 'AI (AI) has made incredible strides in several fields, revolutionising business and everyday life. Thoughts regarding the moral ramifications and fairness of AI systems have grown in prominence along with its fast development. This article explores the crucial issues of AI fairness and ethics, concentrating on ways to detect and reduce prejudice in AI systems while also discussing larger ethical implications. The paper emphasises the possible repercussions of biased decision-making while highlighting the many forms and sources of bias that might develop in AI models. There are several methods and strategies to deal with bias in AI systems, including data pretreatment, algorithmic changes, and transparency measures. In an effort to balance justice and efficacy, the trade-offs between fairness goals and overall model performance are examined. The article also emphasises how crucial it is for AI systems to be transparent and understandable in order to foster accountability. For the purpose of establishing ethical AI development and deployment practises, regulatory issues and ethical decision-making frameworks are also investigated. This study emphasises the need of ongoing research and development of moral AI systems to guarantee a just and equitable future for AI applications via in-depth analysis and case studies.'\n",
      " \"Lead propensity prediction is a data-driven method used to define the value of prospects, by assigning points to them based on their engagement with the business's digital channels, based on multiple key attributes correlating to their attraction to the proposed services or items. The resulting score is closely related to the financial worth of each lead and may be revealing its position in the buying cycle. The marketing teams can then focus on generated leads and prioritize the most prominent ones to improve the conversion rates, using the assigned score on the lead scoring step. The authors investigated using a combination of a data-driven approach and AI (AI) techniques for the lead-scoring process. The experimentation shows that the random forest (RF) is the most suitable model for this task with an accuracy score of 93.04% followed by the decision tree (DT) model of 91.47%. In contrast, when considering the training time, DT and logistic regression (LR) needed a shorter time to learn from the dataset while maintaining decent performances. In contrast, these models represent promising alternatives to the RF model especially in the case of a huge volume of transactions and prospects or in a big data context.\"\n",
      " 'This research explores the impact of AI (AI) on marketing strategy with a focus on contextual understanding of consumers, increasing operational efficiency, better personalization of content, decision-making effectiveness, and the need for integration with expertise. Through systematic literature analysis, this research identifies the positive potential and challenges faced by companies in adopting AI technology in their marketing strategies. The results provide deep insight into how the integration of AI can shape modern marketing and deliver significant benefits.'\n",
      " 'In the context of intensifying competition and evolving market dynamics, the deployment of cutting-edge technologies has become not merely a discretionary choice, but an indispensable imperative for any enterprise aspiring to achieve successful growth. GenAI, with its substantial potential for automation, personalisation and optimisation of business processes, is emerging as a highly promising avenue of digital transformation. This study is dedicated to investigating approaches and delineating strategies for aligning GenAI with the requirements of digital business transformation. The research examines the development of AI, with a focus on symbolic AI, machine learning, deep learning and GenAI. In addition, it considers the impact of these developments on business processes. The article identifies the potential benefits and challenges associated with the adaptation of GenAI to the needs of modern business, in the areas of marketing, sales and data analysis. The utilisation of diverse methodologies and techniques, including prompts, fine-tuning, and the incorporation of interactive guidance systems, can enhance the efficacy and precision of GenAI in a business setting, thereby facilitating optimal outcomes in a multitude of tasks. The authors put forth the proposition of employing GenAI technology in conjunction with Retrieval-Augmented Generation, with the objective of enhancing the quality and relevance of responses to user queries. Additionally, they advocate for the utilisation of agents or orchestration tools to provide guidance to models. The successful implementation of GenAI hinges on three key factors: the clear definition of objectives, the selection of suitable tools and technologies, and the assurance of managerial and staff support. The implementation of GenAI will contribute to increased efficiency through the automation of routine tasks, enhanced competitiveness through personalisation and innovation, optimised cost structures that increase profitability, and expanded opportunities for research and development.'\n",
      " \"In terms of language models, GenAI (GenAI), and more specifically GenAI, offer a significant technological achievement as a revolutionary tool for natural language processing (NLP) and a transformative educational business tool. GenAI users' suggestions have the ability to optimize teaching and learning, thereby having a substantial impact on the educational environment of the twenty-first century. Educational robots are getting easier to access for a number of reasons. The human-robot cooperation that has advanced scientifically in industry 5.0 extreme digital automation, will also probably become a regular aspect of life in the days to come. This study examines the prospective uses of GenAI for NLP synthesis as well as its potential role as a conversational agent in the classroom business. GenAI's capacity to understand and produce language that is human-like by employing NLP to generate semantics was essential to its ability to replicate the most advanced human technology through comprehensive assumptions of  patterns and structures it learns from its training data. With the rise of AI (AI) driven conversational agents, prompt engineering has become an important aspect of digital learning. It is essential to get ready for an AI-dominated future when general and educational technologies combine. The study demonstrated how society may impact and contribute to the development of AI pedagogic learning using an instructional robotics application driven by AI, emphasizing the responsibility of humans as producers to reduce any potential misfortunes. The study   highlights that since GenAI technologies have the potential to drastically change teaching and learning approaches and necessitate new ways of thinking, more research on organizational robotics, with a focus on human collaboration and education, will emerge from the technological concerns raised in this study.\"\n",
      " \"One kind of AI technology called GenAI is used to create new text, picture, audio, and video material. It may be used for many different things in education, such creating material, enhancing data, personalizing learning, simulating situations, and providing training. It also raises moral questions about prejudices, veracity, false information, intellectual property, loss of employment, and potential future developments like more realism and responsiveness. Content creation, personalized learning, administrative work automation, interactive learning environments, feedback and evaluation, natural language processing (NLP), forecasting and prediction, and collaborative learning are some of the educational applications of GenAI approaches. These technological advancements are intended to improve educational opportunities, streamline administrative duties, and provide individualized course materials. But there are still issues to be resolved, like protecting data privacy, managing human - AI interaction well, and preventing biases in information produced by AI. The process of creating a GenAI system for teaching includes gathering data, choosing a model, training it, and deploying it. Although scalable, personalized, and engaging learning solutions offered by GenAI hold great promise for revolutionizing education, there are a number of drawbacks that may restrict the technology's applicability and prevent it from being widely used. The difficulty of maintaining and upgrading these systems, ethical and privacy problems, and the caliber and bias of the produced information are examples of technical constraints. The applications, legal frameworks, and social consequences of GenAI will be shaped by its technological limits. To fully realize the benefits of AI in education, issues including data privacy breaches, possible bias in AI systems, and the digital divide must be resolved.\"\n",
      " \"This research investigates the influence of AI (AI) adoption, machine learning (ML) integration, and AI ethics on product innovation within Bogor's startup ecosystem. A quantitative approach was employed, collecting data through an online survey from 180 startups. Structural equation modeling with Partial Least Squares (PLS) 3 was utilized for data analysis. The results reveal significant positive relationships between AI adoption, ML integration, AI ethics, and product innovation. AI adoption and ML integration positively impact product innovation, while adherence to ethical AI practices also plays a crucial role. These findings highlight the importance of leveraging AI technologies responsibly and ethically to drive innovation within startup ecosystems. Policymakers, entrepreneurs, investors, and other stakeholders can utilize these insights to foster a conducive environment for sustainable growth and innovation in Bogor's startup community.\"\n",
      " 'AbstractThe pursuit of AMAs is complicated. Disputes about the development, design, moral agency, and future projections for these systems have been reported in the literature. This empirical study explores these controversial matters by surveying (AI) Ethics scholars with the aim of establishing a more coherent and informed debate. Using Q-methodology, we show the wide breadth of viewpoints and approaches to artificial morality. Five main perspectives about AMAs emerged from our data and were subsequently interpreted and discussed: (i) Machine Ethics: The Way Forward; (ii) Ethical Verification: Safe and Sufficient; (iii) Morally Uncertain Machines: Human Values to Avoid Moral Dystopia; (iv) Human Exceptionalism: Machines Cannot Moralize; and (v) Machine Objectivism: Machines as Superior Moral Agents. A potential source of these differing perspectives is the failure of Machine Ethics to be widely observed or explored as an applied ethic and more than a futuristic end. Our study helps improve the foundations for an informed debate about AMAs, where contrasting views and agreements are disclosed and appreciated. Such debate is crucial to realize an interdisciplinary approach to artificial morality, which allows us to gain insights into morality while also engaging practitioners.'\n",
      " 'AI (AI) is rapidly transforming various aspects of healthcare, including the field of diagnostics and treatment of diseases. This review article aimed to provide an in-depth analysis of the impact of AI, especially, radiomics in the diagnosis of neuro-oncology diseases. Indeed, it is a multidimensional task that requires the integration of clinical assessment, neuroimaging techniques, and emerging technologies like AI and radiomics. The advancements in these fields have the potential to revolutionize the accuracy, efficiency, and personalized approach to diagnosing neuro-oncology diseases, leading to improved patient outcomes and enhanced overall neurologic care. However, AI has some limitations, and ethical challenges should be addressed via future research.'\n",
      " 'This Viewpoint discusses the potential use of GenAI (AI) in medical care and the liability risks for physicians using the technology, as well as offers suggestions for safeguards to protect patients.'\n",
      " 'As a branch of computer science, AI (AI) attempts to understand the essence of intelligence, and produce new kinds of intelligent machines that can respond in a similar way to human intelligence, with broad research areas of machine and deep learning, data science, reinforcement learning, data mining, knowledge discovery, knowledge reasoning, speech recognition, natural language processing, language recognition, image recognition, computer vision, planning, robotics, gaming, and so on [...]'\n",
      " 'AbstractIn July 2017, China’s State Council released the country’s strategy for developing AI (AI), entitled ‘New Generation AI Development Plan’ (新一代人工智能发展规划). This strategy outlined China’s aims to become the world leader in AI by 2030, to monetise AI into a trillion-yuan (ca. 150 billion dollars) industry, and to emerge as the driving force in defining ethical norms and standards for AI. Several reports have analysed specific aspects of China’s AI policies or have assessed the country’s technical capabilities. Instead, in this article, we focus on the socio-political background and policy debates that are shaping China’s AI strategy. In particular, we analyse the main strategic areas in which China is investing in AI and the concurrent ethical debates that are delimiting its use. By focusing on the policy backdrop, we seek to provide a more comprehensive and critical understanding of China’s AI policy by bringing together debates and analyses of a wide array of policy documents.'\n",
      " 'Abstract\\nGenAI (AI) has enabled tasks in radiology, including tools for improving image quality. Recently, new hotspots have emerged, such as intra- or inter-modal image translation, task-specific image synthesis, and text generation. Advances in GenAI have facilitated the move towards low-dose, cost-effective, and high-quality radiological image acquisition. Large language models can aid radiologists by generating professional answers and facilitating patient-physician communications. However, radiologists must be aware of potential inaccuracies in the generated content and should only use such tools after rigorous validation of their performance.'\n",
      " 'A biologically inspired cognitive architecture is described which uses navigation maps (i.e., spatial locations of objects) as its main data elements. The navigation maps are also used to represent higher-level concepts as well as to direct operations to perform on other navigation maps. Incoming sensory information is mapped to local sensory navigation maps which then are in turn matched with the closest multisensory maps, and then mapped onto a best-matched multisensory navigation map. Enhancements of the biologically inspired feedback pathways allow the intermediate results of operations performed on the best-matched multisensory navigation map to be fed back, temporarily stored, and re-processed in the next cognitive cycle. This allows the exploration and generation of cause-and-effect behavior. In the re-processing of these intermediate results, navigation maps can, by core analogical mechanisms, lead to other navigation maps which offer an improved solution to many routine problems the architecture is exposed to. Given that the architecture is brain-inspired, analogical processing may also form a key mechanism in the human brain, consistent with psychological evidence. Similarly, for conventional AI systems, analogical processing as a core mechanism may possibly allow enhanced performance.'\n",
      " \"The research paper investigates the comparative functionalities, effectiveness, and selection criteria of Gemini and GenAI within the field of business management. Both AI platforms offer specialized advantages applicable across various domains, including market research, strategic planning, operations management, customer service, marketing, human resources, and decision-making. Gemini utilizes Google's vast index to excel in real-time market analysis, strategic planning, and data-driven decision-making. Its robust analytical capabilities facilitate swift identification of market trends, competitor analysis, and precise forecasting. Conversely, GenAI specializes in providing qualitative insights, analyzing customer feedback, and facilitating creative content generation, making it particularly valuable for customer interactions and marketing efforts. Regarding performance, both models significantly enhance operational efficiency, data analysis, and customer service automation. Gemini's proficiency lies in processing extensive datasets for insights and optimization, whereas GenAI's adaptability and conversational skills elevate customer experiences and creative content production. The paper delineates selection criteria tailored to specific business requirements and contexts. Considerations such as data sensitivity, bias mitigation, cost-effectiveness, accessibility, customization, and integration are pivotal in selecting between Gemini and GenAI. While Gemini may be favoured for its factual precision and integration within the Google ecosystem, GenAI offers flexibility, conversational capabilities, and potential for self-hosting. Comprehending the distinct strengths and limitations of each AI model is crucial for effectively harnessing their capabilities across diverse business management scenarios. The research delivers valuable insights for businesses seeking to optimize their operations and decision-making processes through AI integration.\"\n",
      " 'Large Language Models (LLMs) have emerged as powerful tools in the field of natural language processing and have transformed the way we interact with text data and generate textual content.'\n",
      " 'This paper explores the explanability imperative in the context of GenAI (GAI) and its crucial role in addressing the concerns posed by AI technology in Nigeria. This underscores the ethical necessity for AI systems, especially generative ones to provide clear and understandable explanations for their decisions and actions. Although the advent of GenAI undoubtedly heralds the future and however, has also exposed Nigerian society to new vulnerabilities that seemingly are detrimental to our epistemic agency and peaceful political settings. Employing the phenomenological method of philosophical inquiry here, we discovered that this new technology has posed big threats to the future world, and that Nigeria falls amongst this new technology users. To navigate the moral dilemma caused by GenAI, this paper suggests many proactive approaches like the development of localized AI explainability standards, the regulatory frameworks, and educational initiatives to promote awareness and understanding of AI systems in Nigeria. By prioritizing the Explanability Imperative, Nigeria can chart a path towards a future whereby AI technologies aligned with societal values, upholds standard education, and as well contributes positively to the nation’s development. This paper encapsulates the importance of AI explainability in Nigeria’s AI landscape and its potential to shape a more ethically responsible and transparent AI future.'\n",
      " 'Sketch drawings play an important role in assisting humans in communication and creative design since ancient period. This situation has motivated the development of AI (AI) techniques for automatically generating sketches based on user input. Sketch-RNN, a sequence-to-sequence variational autoencoder (VAE) model, was developed for this purpose and known as a state-of-the-art technique. However, it suffers from limitations, including the generation of lowquality results and its incapability to support multi-class generations. To address these issues, we introduced AI-Sketcher, a deep generative model for generating high-quality multiclass sketches. Our model improves drawing quality by employing a CNN-based autoencoder to capture the positional information of each stroke at the pixel level. It also introduces an influence layer to more precisely guide the generation of each stroke by directly referring to the training data. To support multi-class sketch generation, we provided a conditional vector that can help differentiate sketches under various classes. The proposed technique was evaluated based on two large-scale sketch datasets, and results demonstrated its power in generating high-quality sketches.'\n",
      " 'AbstractWhat are the implications of AI (AI) on human rights in the next three decades? Precise answers to this question are made difficult by the rapid rate of innovation in AI research and by the effects of human practices on the adaption of new technologies. Precise answers are also challenged by imprecise usages of the term “AI.” There are several types of research that all fall under this general term. We begin by clarifying what we mean by AI. Most of our attention is then focused on the implications of artificial general intelligence (AGI), which entail that an algorithm or group of algorithms will achieve something like superintelligence. While acknowledging that the feasibility of superintelligence is contested, we consider the moral and ethical implications of such a potential development. What do machines owe humans and what do humans owe superintelligent machines?'\n",
      " 'Aim: AI systems can be complex and opaque, making it challenging to understand how they make decisions. This raises concerns about fairness and accountability, as individuals may not understand the factors that influence the decisions made by AI systems. The aim of this study was to examine the ethical considerations surrounding the development and use of AI.\\r\\nMethods: The study adopted a desktop research design. Relevant books reference and journal articles for the study were identified using Google Scholar. The inclusion criteria entailed materials that were related to the ethics of AI.\\r\\nResults: The study found out that bias, privacy, accountability and transparency are the main ethical concerns that surround the development and use of AI technology in developed countries. Additionally, the studies emphasized the need for collaboration between stakeholders, including policymakers, researchers, and local communities, to ensure that ethical guidelines are developed and implemented. In African countries, the studies highlighted the need for a nuanced understanding of the cultural, political, and economic context of the region when considering ethical AI. Issues related to bias, data privacy, and the impact of AI on the labor market were identified as important ethical considerations in the region.\\r\\nConclusion: This study emphasizes the need for a human-centered approach that prioritizes the needs and values of local communities, as well as greater engagement with local stakeholders in the development of ethical guidelines.\\r\\nRecommendation: The study recommend development and implementation of ethical guidelines for AI. Policymakers, developers, and researchers should work together to develop and implement ethical guidelines for AI systems. These guidelines should address issues related to bias, transparency, accountability, and privacy, and should be grounded in a commitment to promoting human well-being and social good.'\n",
      " 'AI (AI) is scaling rapidly in higher education globally. Considering the increasing significance of AI in higher education (AIHEd) and the absence of a comprehensive review on it, this paper delves into the evolving landscape of AI in higher education (AIHEd), its academic integrity and ethical concerns. The study has applied qualitative approach by using literature review as a research design and method to facilitate the aim of the study.The analysis of the paper reveals that AI has the potential to make a significant contribution to enhancing teaching and learning experiences, improving productivity and efficiency, as well as fostering inclusivity and accessibility. On the contrary, the increasing utilization of AI in higher education (AIHEd) raises the concerns about academic integrity and ethical issues, as it has the potential to lead to plagiarism, impede critical thinking, suppress creativity, and erode originality in teaching, research, and scholarship. Hence, upholding the integrity of scientific research requires a rigorous commitment to ethical and academic principles, placing human intelligence and critical thinking at the forefront of the research process. The advancement of AI in higher education not only brings significant advantages, but also poses challenges to the fundamental principles, methodologies, standards, ethical considerations and academic integrity in both teaching and research. As a result, the primary focus should be on embracing the opportunities and benefits that arise from this advancement and effectively addressing any potential risks and challenges.'\n",
      " 'The world of AI (AI) is struggling to set standards that would be globally applied. In this struggle, ethics is extensively summoned to regulate the development and use of AI systems, but also to promote vested interests. The potential benefits associated with AI are such that many actors, public and private, have entered a race for AI dominance led by the United States and China. In this context some actors, such as the European Union, are slowly taking over AI regulation and setting the limits regarding what is ethically acceptable and what is not. Aware of the power of norms, the West has slowly spread its normative influence all around the world, releasing hundreds of documents pertaining to ethical principles, and denying the reality of a world made of a diversity of ethical stances. To impose its own views on ethics applied to AI, the West has developed an ethical narrative transforming ethics into cosm-ethics, that is mere make up through communication. This paper aims at opening a debate on the reality of ethics applied to AI. It contextualizes the subject in a wider setting of race for AI dominance, stressing the Western ethical hegemony over AI established through a pseudo ethical narrative. To illustrate these points, it focuses on the case of the European Union, to eventually stress the urgent need for cultural pluralism in the field of ethics applied to AI.'\n",
      " 'Wireless sensor networks and Internet of Things devices are revolutionizing the smart agriculture industry by increasing production, sustainability, and profitability as connectivity becomes increasingly ubiquitous. However, the industry has become a popular target for cyberattacks. This survey investigates the role of AI (AI) in improving cybersecurity in smart agriculture (SA). The relevant literature for the study was gathered from Nature, Wiley Online Library, MDPI, ScienceDirect, Frontiers, IEEE Xplore Digital Library, IGI Global, Springer, Taylor & Francis, and Google Scholar. Of the 320 publications that fit the search criteria, 180 research papers were ultimately chosen for this investigation. The review described advancements from conventional agriculture to modern SA, including architecture and emerging technology. It digs into SA’s numerous uses, emphasizing its potential to transform farming efficiency, production, and sustainability. The growing reliance on SA introduces new cyber threats that endanger its integrity and dependability and provide a complete analysis of their possible consequences. Still, the research examined the essential role of AI in combating these threats, focusing on its applications in threat identification, risk management, and real-time response mechanisms. The survey also discusses ethical concerns such as data privacy, the requirement for high-quality information, and the complexities of AI implementation in SA. This study, therefore, intends to provide researchers and practitioners with insights into AI’s capabilities and future directions in the security of smart agricultural infrastructures. This study hopes to assist researchers, policymakers, and practitioners in harnessing AI for robust cybersecurity in SA, assuring a safe and sustainable agricultural future by comprehensively evaluating the existing environment and future trends.'\n",
      " 'This research contributes valuable insights on the ongoing debate surrounding AI in HR. By diving into a specific context of the IT industry, the study offers a practical recommendation for maximizing the benefits of AI while mitigating potential risks. This study investigates the impact of AI (AI) on enhancing Human Resource practices in the IT industry.'\n",
      " \"Now AI (AI) is transforming the world, making the revolution in business operation and changing business models. AI (AI) has emerged as a transformative force in the financial industry, revolutionizing various aspects of financial services. With its ability to learn, reason, and make decisions on its own, AI has the potential to revolutionize the financial and business sectors of the economy. As machines take over critical decision-making processes that impact people's lives, it is important to consider the possible ethical implications of using AI. From privacy concerns to potential biases, it is important to examine the implications of AI in business and financial services. Along with the technological and managerial problems of introducing AI technologies, ethical aspects like job cuts, confidentiality and impartiality are becoming very important. It is for this reason that ethical issues in the application of AI (AI) have become a growing but important area of scientific research. The paper reveals that AI ethics must pay attention to the morally significant systemic consequences of AI use. The growing use of AI has brought ethicists and practitioners' attention to systemic risks that have yet to be clearly addressed in AI-related professional codes of conduct, industry standards, and ethical discussions in general. In this article, we examine the key ethical issues raised by advances in AI and technology projects related to AI and machine learning systems in the financial industry.\"\n",
      " 'The aim of the study is to present the current situation regarding the strategies and policies for the development of AI skills in public sector executives and to establish a holistic training framework based on European and international standards. The paper systematically presents the existing literature on AI, focusing on policy strategies for the training of public sector executives. Hence, the key points of the strategies for AI, as well as the UNESCO Competency Framework for Digital Transformation and AI, the e-CF, the DigComp and the EQF frameworks are presented. Based on the theoretical tools emerged from the literature review, an assessment of the existing situation and the identification of the needs of the Greek reality is presented. Most importantly, the paper attempts to create a holistic four-level strategic framework, which can be used by the public administration as a roadmap to lay the foundations for a basis for public sector training programmes, and which takes into account a number of factors, such as the hierarchical structure of the public administration, the various qualification and competence frameworks, as well as the principles of educational design and adult education.'\n",
      " ' This study examines the impact of AI (AI) on the ways in which users process and respond to misinformation in GenAI (GenAI) contexts. Drawing on the heuristic–systematic model and the concept of diagnosticity, our approach examines a cognitive model for processing misinformation in GenAI. The study’s findings revealed that users with a high-heuristic processing mechanism, which affects positive diagnostic perception, were more likely to proactively discern misinformation than users with low-heuristic processing and low-perceived diagnosticity. When exposed to misinformation from GenAI, users’ perceived diagnosticity of misinformation can be accurately predicted by the ways in which they perform heuristic systematic evaluations. With this focus on misinformation processing, this study provides theoretical insights and relevant recommendations for firms to be more resilient in protecting users from the detrimental impacts of misinformation. '\n",
      " '<span id=\"docs-internal-guid-bef24e0c-7fff-7c19-7865-2ba99054831c\"><span>The whole world is inundated with smaller devices equipped with wireless communication interfaces. At the same time, the amount of data generated by these devices is becoming more important. The smaller size of these devices has the disadvantage of being short of processing and storage resources (memory, processes, energy,...), especially when it needs to process larger amounts of data. In order to overcome this weakness and process massive data, devices must help each other. A low-resource node can delegate the execution of a set of computionly heavy tasks to another machine in the network to process them for it. The machine with sufficient computational resources must also deposit the appropriate environment represented by the adapted virtual machine. Thus, in this paper, in order to migrate the virtual machine to an edge server in a mobile edge computing environment, we have proposed an approach based on AI. More specifically, the main idea of this paper is to cut a virtual machine into several small pieces and then send them to an appropriate target node (Edge Server) using the ant colony algorithm. In order to test and prove the effectiveness of our approach, several simulations are made by NS3. The obtained results show that our approach is well adapted to mobile environments.</span></span>'\n",
      " '<span lang=\"EN-US\">Nowadays, AI (AI) in general and machine learning techniques in particular has been widely employed in automated systems. Increasing complexity of these machine learning based systems have consequently given rise to blackbox models that are typically not understandable or explainable by humans. There is a need to understand the logic and reason behind these automated decision-making black box models as they are involved in our day-to-day activities such as driving, facial recognition identity systems, online recruitment. Explainable AI (XAI) is an evolving field that makes it possible for humans to evaluate machine learning models for their correctness, fairness, and reliability. We extend our previous research work and perform a detailed analysis of the model created for text classification and sentiment analysis using a popular Explainable AI tool named local interpretable model agnostic explanations (LIME). The results verify that it is essential to evaluate machine learning models using explainable AI tools as accuracy and other related metrics does not ensure the correctness, fairness, and reliability of the model. We also present the comparison of explainability and interpretability of various machine learning algorithms using LIME.\\xa0</span>'\n",
      " ' In this article, we critically examine the implementation of what Carlos Montemayor calls Humanitarian AI from a decolonizing perspective. We highlight the dichotomy of optimism and fear surrounding AI, elucidating its potential to address fundamental human problems and the risks of monopolistic control. We critique Montemayor’s proposal to align AI with a human rights framework, arguing that it insufficiently addresses global inequalities. Our tripartite analysis focuses on the distribution of AI resources, language inclusion, and content diversity to ensure AI benefits all humanity. We emphasize the need for equitable access to AI, linguistic diversity in AI training data, and the preservation of marginalized epistemologies. We advocate for strategies to mitigate environmental impacts and avoid cultural imperialism disguised as altruism, calling for a balanced approach between private sector innovation and state regulation to foster a truly humanitarian AI. '\n",
      " 'GenAI (GenAI) is transforming marketing through advanced content creation, personalized customer interactions, and strategic optimization. This study explores GenAI’s impact on marketing processes, current applications, and related ethical and strategic challenges. A meta-analysis of the existing literature was conducted, focusing on GenAI integration in marketing. Relevant research was collected from various databases and rigorously evaluated, with case studies illustrating practical applications and benefits. The findings show that GenAI enhances marketing efficiency by automating content creation, improving customer service, and optimizing strategies using specialized AI tools. However, GenAI’s use is currently fragmented, focusing more on operational than strategic tasks. This study underscores the necessity for a comprehensive and integrated approach to fully leverage the potential of GenAI in marketing processes, with the intention of effecting a paradigm shift, particularly in operational marketing tasks. Future research should focus on developing integrated GenAI solutions that comprehensively address all facets of the marketing process, including strategic decisionmaking, ethical and regulatory considerations, and long-term impact assessment, while exploring innovative applications and optimizing existing technologies to fully harness GenAI’s potential in driving a holistic digital transformation of marketing.'\n",
      " \"The publication provides an overview of the noveltiesof the Ukrainian legislation «On Copyright and Related Rights» (2023) regarding the peculiarities of protection of non-original objects generated by a computer program (GenAI system) using sui generis law, in particular through the prism of exceptions and limitations in copyright.Ukraine has introduced one of the world's first models of the legal protection of AI output through a special sui generis legal regime. The author determines that the legislator sets forth three conditions for a non-original object generated by a computer program (GenAI system) to be protected by law: The AI output must differ from existing similar objects; the AI output must be generated as a result of the operation of a computerprogram without the direct participation of an individual in the generation of this object; and the rights of third parties must be respected when generating a non-original object.It is established that the existing exceptions and restrictions in Ukrainian copyright (free making of copies of works to search for text and data included in or related to scientific publications for research purposes and temporary reproduction) will allow limited operation of GenAI systems. However, it is necessary to consider that AI outputs do not unreasonably restrict the legitimate interests of the relevant copyright owners.In practice, the functioning of GenAI systems demonstrates one of the general principles of civil law - freedom of contract through self-regulation of the distribution of intellectual property rights to AI outputs. The assumption is made that it is not necessary to establish the «default» attribution of rights to such objects at the legislative level.The author suggests that in the future, depending on the requirements of sustainable economic development and the balance of interests between society and the relevant subjects of law, the terms of the legal protection of rights to AI outputs may be changed.The author provides recommendations for improving this area's legal regulation and enhancing law enforcement's efficiency.\"\n",
      " 'Abstract\\nBackground\\nDespite the recognition that developing AI (AI) that is trustworthy is necessary for public acceptability and the successful implementation of AI in healthcare contexts, perspectives from key stakeholders are often absent from discourse on the ethical design, development, and deployment of AI. This study explores the perspectives of birth parents and mothers on the introduction of AI-based cardiotocography (CTG) in the context of intrapartum care, focusing on issues pertaining to trust and trustworthiness.\\n\\nMethods\\nSeventeen semi-structured interviews were conducted with birth parents and mothers based on a speculative case study. Interviewees were based in England and were pregnant and/or had given birth in the last two years. Thematic analysis was used to analyze transcribed interviews with the use of NVivo. Major recurring themes acted as the basis for identifying the values most important to this population group for evaluating the trustworthiness of AI.\\n\\nResults\\nThree themes pertaining to the perceived trustworthiness of AI emerged from interviews: (1) trustworthy AI-developing institutions, (2) trustworthy data from which AI is built, and (3) trustworthy decisions made with the assistance of AI. We found that birth parents and mothers trusted public institutions over private companies to develop AI, that they evaluated the trustworthiness of data by how representative it is of all population groups, and that they perceived trustworthy decisions as being mediated by humans even when supported by AI.\\n\\nConclusions\\nThe ethical values that underscore birth parents and mothers’ perceptions of trustworthy AI include fairness and reliability, as well as practices like patient-centered care, the promotion of publicly funded healthcare, holistic care, and personalized medicine. Ultimately, these are also the ethical values that people want to protect in the healthcare system. Therefore, trustworthy AI is best understood not as a list of design features but in relation to how it undermines or promotes the ethical values that matter most to its end users. An ethical commitment to these values when creating AI in healthcare contexts opens up new challenges and possibilities for the design and deployment of AI.\\n'\n",
      " 'AI (AI) is an experiment on the intelligence of people who are created on machines and programmed to act like ordinary people. As we all know, the development of AI technology is increasingly rapid every day. The introduction of AI in various fields of real life has many positive impacts. However, this development must continue to be accompanied by the ideal application of AI ethics to ensure that existing technology does not exceed reasonable limits in the future and does not cause negative impacts on society. It should be noted that AI Ethics is a field that studies how to develop and use AI in a way that is fair, accountable, transparent, and respects human values. Therefore, debates and views arise regarding the use of AI within the scope of existing ethics and morality. This article aims to find out the form of debate and views regarding the use of AI in the context of ethics and morality. The author will create an article by implementing the literature study method, namely collecting data by finding sources from articles, books and other references related to the topic. this discussion.'\n",
      " \"As patient data continues to grow, the importance of efficient and precise analysis cannot be overstated. The employment of GenAI (AI), specifically Chat GPT-4, in the realm of medical data interpretation has been on the rise. However, its effectiveness in comparison to manual data analysis has been insufficiently investigated.This quality improvement project aimed to evaluate the accuracy and time-efficiency of GenAI (GPT-4) against manual data interpretation within extensive datasets pertaining to patients with orthopaedic injuries.A dataset, containing details of 6,562 orthopaedic trauma patients admitted to a district general hospital over a span of two years, was reviewed. Two researchers operated independently: one utilised GPT-4 for insights via prompts, while the other manually examined the identical dataset employing Microsoft Excel and IBM® SPSS® software. Both were blinded on each other's procedures and outcomes. Each researcher answered 20 questions based on the dataset including injury details, age groups, injury specifics, activity trends and the duration taken to assess the data.Upon comparison, both GPT-4 and the manual researcher achieved consistent results for 19 out of the 20 questions (95% accuracy). After a subsequent review and refined prompts (prompt engineering) to GPT-4, the answer to the final question aligned with the manual researcher's findings. GPT-4 required just 30 minutes, a stark contrast to the manual researcher's 9-hour analytical duration.This quality improvement project emphasises the transformative potential of GenAI in the domain of medical data analysis. GPT-4 not only paralleled the accuracy of manual analysis but also achieved this in significantly less time. For optimal accurate results, data analysis by AI can be enhanced through human oversight. Adopting AI-driven approaches, particularly in orthopaedic data interpretation, can enhance efficiency and ultimately improve patient care. We recommend future investigations on large and more varied datasets to reaffirm these outcomes.\"\n",
      " 'In this study, we aimed to explore the frequency of use and perceived usefulness of LLM GenAI chatbots (e.g., GenAI) for schoolwork, particularly in relation to adolescents’ executive functioning (EF), which includes critical cognitive processes like planning, inhibition, and cognitive flexibility essential for academic success. Two studies were conducted, encompassing both younger (Study 1: N\\u2009=\\u2009385, 46% girls, mean age 14 years) and older (Study 2: N\\u2009=\\u2009359, 67% girls, mean age 17\\u2009years) adolescents, to comprehensively examine these associations across different age groups. In Study 1, approximately 14.8% of participants reported using GenAI, while in Study 2, the adoption rate among older students was 52.6%, with GenAI emerging as the preferred tool among adolescents in both studies. Consistently across both studies, we found that adolescents facing more EF challenges perceived GenAI as more useful for schoolwork, particularly in completing assignments. Notably, academic achievement showed no significant associations with AI usage or usefulness, as revealed in Study 1. This study represents the first exploration into how individual characteristics, such as EF, relate to the frequency and perceived usefulness of LLM GenAI chatbots for schoolwork among adolescents. Given the early stage of GenAI chatbots during the survey, future research should validate these findings and delve deeper into the utilization and integration of GenAI into educational settings. It is crucial to adopt a proactive approach to address the potential challenges and opportunities associated with these emerging technologies in education.'\n",
      " 'Personalized learning has always been a dream for schools, educators, and students but until recently, educators didn’t have the time or resources to implement it on a large scale. With the advancements in AI, GenAI can automate many of a teacher’s core tasks, such as creating lesson resources. providing lesson structures and key talking points, designing infographics, creating slideshows, and converting text into videos and images. This study details the development and evaluation of an AI-powered tutoring system designed to enhance student learning experiences. Motivated by the transformative potential of AI in education, the research aims to utilize large language models, including OpenAI, to create a personalized and adaptive learning environment. The research is a two-phase approach, involving a comprehensive literature review, problem definition, and AI integration in the Research Phase, followed by design, prototyping, and testing in the Design and Development Phase. The course creation workflow emphasizes the collaborative efforts of human tutors and AI algorithms using the GPT-3.5-Turbo model. The study identified the potential improvement in education where the course has been created by AI including the image generated by DALLE-3 and contributing to the evolving landscape of AI-assisted education using the text-to-voice, an automatic speech recognition system by Whisper, offering an innovative and transformative learning experience for students and tutors. The course content has question-answering chatbots where the students can ask any questions related to the topic while learning.'\n",
      " 'This research discusses the impact of the integration of AI (AI) in Human Resource Management (HRM) practices through a systematic literature review approach. Involving the analysis of 37 articles from various academic databases, the research identified the key benefits provided by AI in HRM, such as improved efficiency, process effectiveness and corporate decision making. However, significant challenges were also identified, including issues of data security, privacy and the need for HR skills development. In addition, the psychological impact on employees and work team dynamics is an important concern. In conclusion, the combination of AI in HRM has the capability to shape a new paradigm in human resource management, however it requires careful coping with rising demanding situations. This study offers a stable basis for a deep know-how of the complex interactions between AI and HRM, starting the door to in addition research and improvement on this region.'\n",
      " \"The advent of AI (AI), often known as the fourth industrial revolution (IR 4.0),will affect not just our day-to-day activities and social interactions, but also our understanding of who weare. AI, however, has a profound effect on the way we go about our daily lives andconnect with one another. Keep an eye on the progress of AI to ensure that everyone can reap the benefitsof this new kind of intelligence. This idea is linked to the concept that AI should display intelligentbehaviour. Prior to this, only humans were allowed there. AI (AI) can act autonomously ina variety of contexts and solve complex issues without human intervention. The way people think about thedevelopment of AI has changed drastically as a result. There are many facets of modernlife in which AI is rapidly progressing. There are many potential applications for artificialintelligence, including healthcare and the creation of game-changing technology like autonomous cars.There have been good and bad results from AI's entrance into society. The major purpose of this studyis to examine the effects of AI on society and the difficulties AI faces.\"\n",
      " 'GenAI (genAI) language models have become firmly embedded in public consciousness. Their abilities to extract and summarise information from a wide range of sources in their training data have attracted the attention of many scholars. This paper examines how four genAI large language models (GenAI, GPT4, DeepAI, and Google Bard) responded to prompts, asking (i) whether AI would affect how cultural heritage will be managed in the future (with examples requested) and (ii) what dangers might emerge when relying heavily on genAI to guide cultural heritage professionals in their actions. The genAI systems provided a range of examples, commonly drawing on and extending the status quo. Without a doubt, AI tools will revolutionise the execution of repetitive and mundane tasks, such as the classification of some classes of artifacts, or allow for the predictive modelling of the decay of objects. Important examples were used to assess the purported power of genAI tools to extract, aggregate, and synthesize large volumes of data from multiple sources, as well as their ability to recognise patterns and connections that people may miss. An inherent risk in the ‘results’ presented by genAI systems is that the presented connections are ‘artifacts’ of the system rather than being genuine. Since present genAI tools are unable to purposively generate creative or innovative thoughts, it is left to the reader to determine whether any text that is provided by genAI that is out of the ordinary is meaningful or nonsensical. Additional risks identified by the genAI systems were that some cultural heritage professionals might use AI systems without the required level of AI literacy and that overreliance on genAI systems might lead to a deskilling of general heritage practitioners.'\n",
      " \"This study examines the integration of AI and GenAI in B2C companies' growth strategies, addressing the transformative impact on business processes and customer interactions. Utilizing a comprehensive analysis of McKinsey reports and current research, the paper develops a strategic framework for AI integration in B2C sectors. The research reveals a significant increase in AI adoption, with 72% of organizations implementing AI technologies. The study outlines key areas of transformation, including hyper-personalization of customer experiences, operational efficiency optimization, and acceleration of innovation cycles. A novel strategic framework is proposed, encompassing readiness assessment, roadmap development, and risk management strategies. The findings highlight the critical importance of ethical considerations and organizational culture transformation in successful AI integration. This research contributes to the understanding of AI-driven strategies in B2C, offering insights into long-term economic effects, consumer behavior changes, and regulatory implications of AI adoption in the digital economy era.\"\n",
      " 'Tony Silbert and Bill Matuszak’s collaborative dialogue explores the potential fusion of AI and ai. Their conversation underscores the significance of proactively mitigating biases in AI through Appreciative Inquiry’s generative-focused approach. It highlights the need for collaboration between AI experts and ai practitioners to foster ethical AI development practices that prioritize transparency, fairness, and accountability.'\n",
      " \"AI (AI) technology is to make human life easy and trouble-free and contribute to the advancement of human development. AI is a driving technological force of the twenty-first century and it has been a centre of discussion in technological innovations for its unlimited potential to alter the scenario of social interaction through resolving social challenges and virtually transform every industry. Education is the top priority of present society because it is a fundamental human right that builds peace and drives sustainable development across the world. The integration and application of AI in the classrooms will make teaching and learning effective by supporting teachers and learners in the process through the usage of robotic technology and sensors. AI-based technology facilitates inclusive and equitable quality education along with ensuring universal access to life-long learning for all across the world. The technology of AI has been advanced and sophisticated that can recognize the gesture of the students and understand their mood and ease during the lecture even it can read facial expressions and posture of the students to understand difficulties and problems they are facing in the lecture and recommends altering the lesson. AI technology-based assessment system can be used to assess students' knowledge, understanding, skills such as collaboration and persistence and characteristics such as confidence and motivation etc. AI technology has developed speech-to-text transcription, predictive text and facial recognition promising an inclusive future for all learners.\"\n",
      " 'Environmental problems have a tremendous impact on the entire world population, particularly on human health, which plays a leading role in individual well-being. Environmental pollution, according to some estimates, kills approximately 9 million people every year. The introduction of AI (AI) systems in many areas has enormous potential in reducing human impact on the environment; however, such systems have negative effects. The potential of AI systems to improve healthcare is inextricably linked to the ethical challenges posed by the complexity of these systems and their impact on the lives and health of communities, patients, and staff. In addition to aspects that relate directly to the algorithms, data, and clinical application of AI systems, long-term risks exist that are not obvious at first glance. One of these risks is the negative impact of AI systems on the environment, which may harm human health indirectly. AI systems are more than software, having physical components that are necessary for their functioning, such as processors, memory, and sensors. The manufacture and the energy consumption of the components has a profound effect on the environment. One study showed that when a single AI algorithm is trained, carbon emissions may reach values corresponding to the total carbon emissions from five cars lifetime.\\r\\nThis study analyzes existing literature linking the development of AI systems, especially in healthcare, to their effects on the environment. The study is intended to complement the emerging AI Ethics Code for healthcare, specifically the principles of sustainability that will be included in this code.\\r\\nThe study concludes that the environmental impact of AI systems should be considered when formulating ethical standards for AI in healthcare. These standards must be considered during the development, testing, and application phases of AI systems. All the people involved in the creation and use of AI systems (developers, physicians, and regulators) must monitor the environmental impact and minimize the environmental consequences of such systems at all stages of their existence. This principle calls for minimizing negative impacts, improving the energy efficiency, and disposing physical components in strict compliance with current legislation. Moreover, the rapid development of AI systems and the ethical dilemmas require that solutions be proposed jointly and ethical standards be developed in a manner that is consistent and sensitive to emerging technologies.'\n",
      " '<p>As the amount of textual Information increases, we experience a need for Automatic Text Summarizers. In Automatic summarization a text document or a larger corpus of multiple documents are reduced to a short set of words or paragraph that conveys the main meaning of the text Summarization can be classified into two approaches: extraction and abstraction. This paper focuses on extraction approach.The goal of text summarization based on extraction approach is sentences selection. The first step in summarization by extraction is the identification of important features. In our approach short stories and biographies are used as test documents. Each document is prepared by pre-processing process: sentence segmentation, tokenization, stop word removal, case folding, lemmatization, and stemming. Then, using important features, sentence filtering, data compression and finally calculating score for each sentence is done. In this paper we proposed various features of Summary Extraction and also analyzed features that are to be applied depending upon the size of the Document. The experimentation is performed with the DUC 2002 dataset. The comparative results of the proposed approach and that of MS-Word are also presented here. The concept based features are given more weightage. From these results we propose that use of the concept based features helps in improving the quality of the summary in case of large documents.</p>'\n",
      " '\\nBackground\\nSharing knowledge such as resources, research results, and scholarly documents, is of key importance to improving collaboration between researchers worldwide. Research results from the field of AI (AI) are vital to share because of the extensive applicability of AI to several other fields of research. This has led to a significant increase in the number of AI publications over the past decade. The metadata of AI publications, including bibliometrics and altmetrics indicators, can be accessed by searching familiar bibliographical databases such as Web of Science (WoS), which enables the impact of research to be evaluated and identify rising researchers and trending topics in the field of AI.\\n\\n\\nProblem description\\nIn general, bibliographical databases have two limitations in terms of the type and form of metadata we aim to improve. First, most bibliographical databases, such as WoS, are more concerned with bibliometric indicators and do not offer a wide range of altmetric indicators to complement traditional bibliometric indicators. Second, the traditional format in which data is downloaded from bibliographical databases limits users to keyword-based searches without considering the semantics of the data.\\n\\n\\nProposed solution\\nTo overcome these limitations, we developed a repository, named AI-SPedia. The repository contains semantic knowledge of scientific publications concerned with AI and considers both the bibliometric and altmetric indicators. Moreover, it uses semantic web technology to produce and store data to enable semantic-based searches. Furthermore, we devised related competency questions to be answered by posing smart queries against the AI-SPedia datasets.\\n\\n\\nResults\\nThe results revealed that AI-SPedia can evaluate the impact of AI research by exploiting knowledge that is not explicitly mentioned but extracted using the power of semantics. Moreover, a simple analysis was performed based on the answered questions to help make research policy decisions in the AI domain. The end product, AI-SPedia, is considered the first attempt to evaluate the impacts of AI scientific publications using both bibliometric and altmetric indicators and the power of semantic web technology.\\n'\n",
      " 'The rise in AI (AI) and machine learning (ML) in cryptocurrency trading has precipitated complex ethical considerations, demanding a thorough exploration of responsible regulatory approaches. This research expands upon this need by employing a consequentialist theoretical framework, emphasizing the outcomes of AI and ML’s deployment within the sector and its effects on stakeholders. Drawing on critical case studies, such as SBF and FTX, and conducting an extensive review of relevant literature, this study explores the ethical implications of AI and ML in the context of cryptocurrency trading. It investigates the necessity for novel regulatory methods that address the unique characteristics of digital assets alongside existing legalities, such as those about fraud and insider trading. The author proposes a typology framework for AI and ML trading by comparing consequentialism to other ethical theories applicable to AI and ML use in cryptocurrency trading. By applying a consequentialist lens, this study underscores the significance of balancing AI and ML’s transformative potential with ethical considerations to ensure market integrity, investor protection, and overall well-being in cryptocurrency trading.'\n",
      " '<p><span lang=\"EN-US\">This study aims to review methods of AI (AI) in land use modelling. Data were extracted from journals in the Scopus and Google Scholar databases using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) method. The review demonstrates that modelling land use predictions is a complex matter that involves land use maps and driving forces. AI technology can support land use forecasting by interpreting land use data, analyzing drivers, and modeling. However, AI has limitations in terms of broad contextual understanding and algorithmic errors. To anticipate this, it is necessary to select the appropriate image resolution and interpretation method in accordance with digital data segmentation. It is also recommended to use spatial regression methods to determine the driving forces that affect land use. Hybrid models such as multilayer perceptron neural network Markov chain (MLPNN-MC), random forest algorithm (RFA), and cellular automata (CA)-Markov chain (MC) are recommended for modelling. The selection of a model should be based on the data\\'s characteristics and tested for accuracy. The use of AI for land use prediction modelling is expected to provide accurate predictions that can be used as a basis for land use policy.</span></p>'\n",
      " 'AbstractThe advent of GenAI and the widespread adoption of it in society engendered intensive debates about its ethical implications and risks. These risks often differ from those associated with traditional discriminative machine learning. To synthesize the recent discourse and map its normative concepts, we conducted a scoping review on the ethics of GenAI, including especially large language models and text-to-image models. Our analysis provides a taxonomy of 378 normative issues in 19 topic areas and ranks them according to their prevalence in the literature. The study offers a comprehensive overview for scholars, practitioners, or policymakers, condensing the ethical debates surrounding fairness, safety, harmful content, hallucinations, privacy, interaction risks, security, alignment, societal impacts, and others. We discuss the results, evaluate imbalances in the literature, and explore unsubstantiated risk scenarios.'\n",
      " 'The integration of AI (AI) into creative processes has brought about the emergence of AI-generated art, leading to new challenges in terms of creativity, ownership, and fair use. This paper proposes an ethical governance framework specifically tailored for AI-generated art, designed to ensure that such works are governed with respect to these core principles. Through detailed case studies and experimental applications in the art industry, this paper demonstrates the framework’s effectiveness in addressing the ethical complexities of AI-generated art. The results provide practical insights for artists, AI developers, and legal professionals, establishing a foundation for future applications in other creative fields.'\n",
      " \"In an era where AI (AI) technology is increasingly penetrating various aspects of life, including education, it is important to understand its impact on students' social relationships. These changes raise questions about how interactions between students and teachers are affected by AI Technology. This research aims to investigate the impact or AI on students' social relationships in an educational environment. The focus is on understanding changes in interactions between students, student-teacher interaction, as well as broader implications for social dynamics inside the classroom and outside the classroom. The research method used is a literature review which uses data collections sources that are relevant to this research, which can be in books, megazines and other print media, or can be obtained from photos and videos. The research results show that AI technology has a complex impact on students' social relationships. Although it can improve efficiency and learning outcomes, AI technology can also reduce social inequality, and create excessive dependence on technology. Educators and policymakers need to carefully consider the use of AI technology in education to ensure that positive impacts are maximized, while negative impacts are minimized.\"\n",
      " 'GenAI (AI) is swiftly cementing its role as an indispensable tool for students transitioning from K-12 to higher education and professional spheres. Yet, harnessing its full potential requires more than mere familiarity. Students must be equipped with the skills to engage with AI both productively and ethically. Left unchecked, AI usage can pose risks, especially if students lack proper guidance or understanding of their actions. Moreover, effective interaction with AI necessitates skills in prompt engineering to yield desired outcomes. Sidekick Academy is a digital online platform where students can safely experiment with and learn about AI. This article delves into the genesis of Sidekick Academy, offering a glimpse into its lessons on how to use AI and complex debate on ethical use. It also sheds light on the academy\\'s \"sandbox\" - a secure space for students to explore AI without jeopardizing their safety or privacy.'\n",
      " 'AbstractAI is becoming increasingly prevalent in creative fields that were thought to be exclusively human. Thus, it is non-surprising that a negative bias toward AI-generated artwork has been proclaimed. However, results are mixed. Studies that have presented AI-generated and human-created images simultaneously have detected a bias, but most studies in which participants saw either AI-generated or human-created images have not. Therefore, we propose that the bias arises foremost in a competitive situation between AI and humans. In a sample of N\\u2009=\\u2009952 participants, we show that different evaluations emerge only when AI-generated and human-created pieces of art are presented simultaneously. Importantly, we demonstrate that AI art is not devalued, but rather, human art is upvalued, indicating the existence of a positive bias toward humans, rather than a negative bias. Further, we show that attitudes toward AI and empathy partially explain the different valuations of AI and human art in competitive situations.'\n",
      " '\\nIn the field of higher education, GenAI (GenAI) has become a revolutionary influence, shaping how students access and use library resources. This study explores the intricate balance of both positive and negative effects that GenAI might have on the academic library experience for higher education (HE) students. The key aspects of enhanced discovery and retrieval, personalization and engagement, streamlined research processes, and digital literacy and information evaluation potentially offered through using GenAI will be considered. These prospective advantages to HE students offered by using GenAI will be examined through will be examined through the theoretical framework of the Technological Acceptance Model (TAM) introduced by Davis et al. in 1986, which suggests that perceived usefulness and perceived ease of use are key factors in determining user acceptance and utilization of technology. The adoption of GenAI by higher education students will be analyzed from this viewpoint before assessing its impact on their use of library resources.\\n'\n",
      " 'With the maturing of AI (AI) and multiagent systems research, we have a tremendous opportunity to direct these advances toward addressing complex societal problems. In pursuit of this goal of AI for social impact, we as AI researchers must go beyond improvements in computational methodology; it is important to step out in the field to demonstrate social impact. To this end, we focus on the problems of public safety and security, wildlife conservation, and public health in low‐resource communities, and present research advances in multiagent systems to address one key cross‐cutting challenge: how to effectively deploy our limited intervention resources in these problem domains. We present case studies from our deployments around the world as well as lessons learned that we hope are of use to researchers who are interested in AI for social impact. In pushing this research agenda, we believe AI can indeed play an important role in fighting social injustice and improving society.'\n",
      " 'Recent significant advances in the healthcare industry due to AI (AI) and machine learning (ML) have been shown to revolutionize healthcare delivery by improving efficiency, accuracy, and patient outcomes. However, these technologies can face significant challenges and ethical considerations. This systematic review aimed to gather and synthesize the current knowledge on the impact of AI and ML adoption in healthcare delivery, with its associated challenges and opportunities. This study adhered to the PRISMA guidelines. Articles from 2014 to 2024 were selected from various databases using specific keywords. Eligible studies were included after rigorous screening and quality assessment using checklist tools. Themes were identified through data analysis and thematic analysis. From 4981 articles screened, a data synthesis of nine eligible studies revealed themes, including productivity enhancement, improved patient care through decision support and precision medicine, legal and policy challenges, technological considerations, organizational and managerial aspects, ethical concerns, data challenges, and socioeconomic implications. There exist significant opportunities, as well as substantial challenges and ethical concerns, associated with integrating AI and ML into healthcare delivery. Implementation strategies must be carefully designed, considering technical, ethical, and social factors.'\n",
      " 'Abstract— Groundlight AI/Document extraction (GenAI on edge device) :- The “Document Data Extraction Tool: Integrating GroundLight AI and Tesseract OCR” project addresses the critical need for efficient data extraction from unstructured documents, such as PDFs and images, prevalent in today’s digital age. By combining the capabilities of GroundLight AI for structured data extraction and Tesseract OCR for text extraction from images, the project aims to automate and enhance the accuracy of document processing. This comprehensive tool features a user-friendly interface, supports multiple document formats, and ensures systematic data organization, significantly reducing manual effort and errors. Rigorous testing validates the tool’s reliability and performance, making it a valuable asset for organizations seeking to unlock insights from their document repositories efficiently. The future scope includes integrating natural language processing for advanced analysis, machine learning for document classification, and expanding format support, thereby further enhancing document management and data utilization across various sectors.  Keywords – Edge-device Application, Python, Document Extraction.'\n",
      " 'This study attempted to deploy a high performing natural language processing model which specifically trained on flagging clickbait Indonesian news headline. The deployed model is accessible from any internet-connected device because it implements representational state transfer application programming interface (RESTful API). The application is useful to avoid clickbait news which often solely purposed to rack money but not delivering trustworthy news. With many online news outlets adopting the click-based advertising, clickbait headline become ubiquitous. Thus, newsworthy articles often cluttered with clickbait news. Leveraging state-of-the-art bidirectional encoder representation from transformers (BERT), a lightweight web application is developed. This study offloaded the computing resources needed to train the model on a separate instance of virtual server and then deployed the trained model on the cloud, while the client-side application only needs to send a request to the API and the cloud server will handle the rest, often known as three-layer architecture. This study designed and developed a web-based application to detect clickbait in Indonesian using IndoBERT as its language model. The application usage and potentials were discussed. The source code and running application are available for public with a performance of mean receiver operating characteristic-area under the curve (ROC-AUC) of 89%.'\n",
      " 'This article reports on the Explainable AI Workshop, held within the International Joint Conferences on AI 2019 Workshop Program in Macau, August 11, 2019. With over 160 registered attendees, the workshop was the largest workshop at the conference. It featured an invited talk and 23 oral presentations, and closed with an audience discussion about where explainable AI research stands.'\n",
      " 'AI (AI), the simulation of human intelligence processes by machines, is having a growing impact on healthcare [...]'\n",
      " 'AbstractApplications of AI (AI) bear great transformative potential in the economic, technological and social sectors, impacting especially future work environments. Ethical regulation of AI requires a relational understanding of the technology by relevant stakeholder groups such as researchers, developers, politicians,\\xa0civil servants, affected workers or other users applying AI in their work processes. The purpose of this paper is to support relational AI discourse for an improved ethical framing and regulation of the technology. The argumentation emphasizes a widespread reembodied understanding of AI technology as critical requirement for capable ethical and regulatory frameworks. A sociotechnical perspective encourages the material interpretation of AI as reembodied adaptation of biological intelligence. Reviewing Cartesian dualism as motivating the disembodiment of human intelligence for its transfer to machines, the argumentation develops an integrated embodiment concept of AI in its mechanistic, naturalistic, combined AI and neuroethical, and relational contexts. This concept is discussed in relation to basic phenomenological and postphenomenological assumptions, and is applied to the example of AI-based neurotechnology potentially disrupting future work processes. Strengthening a human-centered approach, the presented concept for a reembodied understanding of AI technology enables better integrated ethical and regulatory debates, and improves social discourse and human agency in developing and regulating AI technology.'\n",
      " 'The rise of text generation models, especially those powered by advanced deep learning architectures like Open AI’s GPT-3, has unquestionably transformed various natural language processing applications. However, these models have recently faced examination due to their inherent biases, often evident in the generated text. This paper critically examines the issue of bias in text generation models, exploring the challenges posed, the ethical implications it entails, and the potential strategies to mitigate bias. Firstly, we go through the causes of the origin of the bias, ways to minimize it, and mathematical representation of Bias.'\n",
      " 'In line with the positive effects of personalized learning, personalized assessments are expected to maximize learner motivation and engagement, allowing learners to show what they truly know and can do. Considering the advances in GenAI (GenAI), in this perspective article, we elaborate on the opportunities of integrating GenAI into personalized educational assessments to maximize learner engagement, performance, and access. We also draw attention to the challenges of integrating GenAI into personalized educational assessments regarding its potential risks to the assessment’s core values of validity, reliability, and fairness. Finally, we discuss possible solutions and future directions.'\n",
      " \"This study investigates the integration of AI (AI) into science curricula at Nigerian universities, motivated by the imperative to prepare students for the evolving demands of the digital age. Employing a mixed-methods approach, the research explores the impact of AI integration on learning outcomes, student engagement, and overall educational quality in science education. Quantitative analysis focuses on academic records, assessing the performance metrics of 180 science education students enrolled in AI-integrated courses across three Nigerian universities. Diverse representation across institutions and academic levels ensures comprehensive insights. Qualitative data, gathered through semi-structured interviews with three experienced lecturers, delves into their perspectives on AI integration in science education. Interviews, conducted via online platforms, highlight the rationale for integrating AI into the curriculum and the lecturers' experiences with AI in their classrooms. Statistical analysis of quantitative data, including regression analysis, identifies patterns and correlations in student performance. Qualitative data undergoes thematic analysis, revealing key insights and recurring themes within educators' and students' narratives. The results demonstrate a tangible link between AI integration and science education, offering a nuanced understanding of advantages and disadvantages. This research advocates for an adaptive curriculum that equips students with AI-related skills, contributing valuable insights for educational stakeholders on effective AI integration into science curricula. Ultimately, the study aims to foster the development of future experts capable of leveraging AI for scientific innovation in Nigeria's evolving technological landscape.\"\n",
      " \"Ever since the commercialization of the Internet in the '90s, technology has been evolving faster than ever with the advent of cloud computing, social media, ubiquitous mobile devices, the Internet of Things (IoT), blockchain, and more. A staggering number of three billion internet users, five billion mobile users, and six billion devices are now connected through this massive global network of networks, facilitating customer information exchange and interaction never before seen in history. Driven by recent technological advances in computing power, big data, high-speed internet connection, and easier access to models built with advanced algorithms, AI (AI) is the next wave of innovation, which has already come into widespread awareness in the consumer world with the emergence of virtual assistants and chatbots (e.g., Amazon's Alexa, Apple's Siri, Google's Assistant), image recognition (e.g., Facebook Photos, Google ImageNet), personalized recommendations (e.g., Netflix, Amazon) and autonomous driving (e.g., Tesla, Google Waymo). This qualitative research study intends to learn about the impact of AI on customer relationship management (CRM), specifically in the area of customer service of problem resolution. Most prior research focuses on the AI technologies leveraged in CRM systems, such as machine learning, natural language processing, voice recognition, chatbots, data analytics, and cloud infrastructure. Few extant studies have used a qualitative research methodology to gather data from industry experts to truly understand the impact of AI technologies on customer relationship management, especially in the area of customer service and problem resolution. This study aims to fill this research gap. This research contributes to the literature on AI in the context of CRM and is of value to both academics and practitioners as it provides a detailed analysis and documentation of the impact of AI on the customer service domain.\"\n",
      " 'This study sought to investigate the impact of AI on digital financial inclusion. Digital financial inclusion is becoming central in the debate on how to ensure that people who are at the lower levels of the pyramid become financially active. Fintech companies are using AI and its various applications to ensure that the goal of digital financial inclusion is realized that is to ensure that low-income earners, the poor, women, youths, small businesses participate in the mainstream financial market. This study used conceptual and documentary analysis of peer-reviewed journals, reports and other authoritative documents on AI and digital financial inclusion to assess the impact of AI on digital financial inclusion. The present study discovered that AI has a strong influence on digital financial inclusion in areas related to risk detection, measurement and management, addressing the problem of information asymmetry, availing customer support and helpdesk through chatbots and fraud detection and cybersecurity. Therefore, it is recommended that financial institutions and non-financial institutions and governments across the world adopt and scale up the use of AI tools and applications as they present benefits in the quest to ensure that the vulnerable groups of people who are not financially active do participate in the formal financial market with minimum challenges and maximum benefits.'\n",
      " 'The recent introduction of AI tools in the justice sector poses several ethical implications as risks for judges’ independence and for procedural transparency, and discrimination biases. By developing ethical frameworks governing AI application, private and public agents have been increasingly dealing with risks pertaining to the use of AI. By inventorying and analyzing a set of ethical documents through content analysis, this study highlights the ethical implications involved in the application of AI. Moreover, by investigating the CEPEJ Charter (European Commission for the Effectiveness of Justice of the Council of Europe), the unique ethical document focusing on AI in justice, we were able to clarify potential differences between justice and other contexts of AI application with respect to risks prospected and the protection of ethical principles. The analysis confirms that the discipline of AI is a complex subject that involves very different aspects and therefore needs a broad focus on all contexts of application.'\n",
      " 'This comprehensive article investigates the dynamic integration of AI (AI) in journalism, tracing its evolution from the initial stages of computer-assisted reporting to the current advanced applications and ethical dilemmas. The paper offers an in-depth analysis of AI’s Impact on journalism, highlighting both the enhancements in efficiency, personalization, and data reporting, as well as the challenges posed by ethical concerns, potential job displacement, and the risks of misinformation. The paper examines real-world applications and controversies surrounding AI in newsrooms, including the use of automated content generation and AI-driven editorial decisions. A critical discussion on ethical considerations is presented, focusing on transparency, accountability, and bias in AI systems and the need for ethical standards and industry-wide collaboration. Looking forward, the article speculates on the future of AI in journalism, emphasizing the continuous essential role of human journalists and the potential technological advancements. This work underscores the necessity of a balanced approach in harnessing AI’s capabilities in journalism, ensuring that technological progress aligns with maintaining journalistic integrity and ethical standards.'\n",
      " 'With the advancement of AI (AI) nowadays, the world is experiencing conveniences in automating some complex and tedious tasks, such as analysing large data and predicting the future by mimicking human expertise. AI has also shown promise for mitigating future crisis, such as pandemic. Since the beginning of the COVID-19, several AI models have been published by the researchers to help the healthcare to fight in this situation. However, before deploying the model, one needs to ensure that the model is robust and safe to learn from the real environment, especially in medical domain, where the uncertainty and incomplete information are not unusual. In the effort of providing robust AI, we proposed to use patient age as one of the feasible feature for ensuring vigorous AI models from electronic health record. We conducted several experiment with 28 blood test items and radiologist report from 1,000 COVID-19 patients. Our result shows that with the predicted age as an additional feature in mortality classification task, the model is significantly improved when compared to adding the actual age. We also reported our findings regarding the predicted age in the dataset.'\n",
      " \"In light of significant issues in the technology industry, such as algorithms that worsen racial biases, the spread of online misinformation, and the expansion of mass surveillance, it is increasingly important to teach the ethics and sociotechnical implications of developing and using AI (AI). Using 53 survey responses from engineering undergraduates, this paper measures students' abilities to identify, mitigate, and reflect on a hypothetical AI ethics scenario. We engage with prior research on pedagogical approaches to and considerations for teaching AI ethics and highlight some of the obstacles that engineering undergraduate students experience in learning and applying AI ethics concepts.\"\n",
      " 'AI (AI) is transforming various industries by enhancing efficiency, accuracy, and decision-making. The non-governmental organization (NGO) sector is also exploring the use of AI to revolutionize their work. This paper explores the role of AI in revolutionizing NGO work, including its potential benefits and challenges. The paper presents case studies of AI implementations in NGO program design, resource management, monitoring and evaluation, and predictive analysis. The paper also discusses the ethical considerations and challenges of using AI in NGOs and outlines the future directions and challenges for AI in the NGO sector.'\n",
      " 'AI use in higher education raises ethical concerns that must be addressed. Biased algorithms pose a significant threat, especially if used in admission or grading processes, as they could have devastating effects on students. Another issue is the displacement of human educators by AI systems, and there are concerns about transparency and accountability as AI becomes more integrated into decision-making processes. This paper examined three AI objectives related higher education: biased algorithms, AI and decision-making, and human displacement. Discourse analysis of seven AI ethics policies was conducted, including those from UNESCO, China, the European Commission, Google, MIT, Sanford HAI, and Carnegie Mellon. The findings indicate that stakeholders must work together to address these challenges and ensure responsible AI deployment in higher education while maximizing its benefits. Fair use and protecting individuals, especially those with vulnerable characteristics, are crucial. Gender bias must be avoided in algorithm development, learning data sets, and AI decision-making. Data collection, labeling, and algorithm documentation must be of the highest quality to ensure traceability and openness. Universities must study the ethical, social, and policy implications of AI to ensure responsible development and deployment. The AI ethics policies stress responsible AI development and deployment, with a focus on transparency and accountability. Making AI systems more transparent and answerable may reduce the adverse effects of displacement. In conclusion, AI must be considered ethically in higher education, and stakeholders must ensure that AI is used responsibly, fairly, and in a way that maximizes its benefits while minimizing its risks.'\n",
      " ' Since AI (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can’t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can’t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.\\xa03, 417–457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn’t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed “Artificial Agential Intelligence” (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist\\xa062(3), 331–350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., & Botvinick, M. [2017] Neuroscience-inspired AI, Neuron\\xa095(2), 245–258) can help carry out this project. '\n",
      " 'An experimental diagramic article on the relationship between AI and the aesthetic of music.'\n",
      " 'Art inspires emotion. The process of creation invigorates the senses and keeps the researcher on fire. To create artistic masterpieces using words through natural language processing further stimulates the mind and helps to overcome writer’s block. An AI tool interprets the words and transforms them into artistic expressions that feel like magic. Yet, AI art is not without consequences. Critics challenge the digital rights of AI-generated images, noting that they are derivative works. This paper examines the joy of creation as well as the copyright challenges creators face when writing detailed prompts to generate amazing artwork. The role of affective computing illustrates the relationship between the designer and the AI tool while ethical concerns remind designers to use caution in their prompts.  The article examines the architecture of a prompt, the characteristics to enhance it, and examples of GenAI art. Additional content includes references to handouts, art catalogs, and legal opinions regarding the copyright debate. The article concludes with a recommendation with respect to the intellectual property rights of artists and their creative work.'\n",
      " 'As AI(AI) is emerging in this century,it can be seen as it is going to take most of the humans’ tasks soon.AI is widely used in all the fields whether it is medical field,research field,automatic vehicle system,Business models of market,weather forecasting and much more.If the future prospects of AI to be highlighted, then the main focus are on how AI will impact on lifestyle of people and how will our society and industries going to change.In this research paper,the AI growth and its applications will be highlighted in three phases.In the first phase the past events of AI and its growth is discussed,the second phase covers the present event and applications of AI and in the last phase,the future(after 10 years) aspects and its applications will be highlighted.As the world is growing in the fast pace and the information technology field is shaping every context of market and research.'\n",
      " '<span lang=\"EN-US\">Apple leaf disease (ALD) potentially affects the apple tree\\'s health by reducing fruit yield and its capability to grow healthy. The prime purpose of the proposed study is to review and assess the strengths and weaknesses associated with the frequently exercised methods of ALD diagnosis using image processing and AI (AI). Although these are widely adopted in recent studies, the core notion is to find the pros and cons associated with the practical viability. A desk research methodology is undertaken to carry out proposed review work where a database of recent scientific manuscripts is collected and studied very closely. The existing approaches are reviewed concerning identified problems, adopted solutions, advantages, and limitations. Finally, the paper contributes towards offering insight into potential research gap which will guide the upcoming researchers to make wise decisions for planning their models. The results acquired from this review work show that generalized challenges of ALD are not addressed, less emphasis on illumination variability, reduced target to minimize complexity, lesser evidence towards real-time processing, no evidence towards interpretability, limitation of available dataset, and tradeoff-between image processing and AI.</span>'\n",
      " 'In November 2022, OpenAI publicly launched its large language model (LLM), GenAI, and reached the milestone of having over 100 million users in only 2 months. LLMs have been shown to be useful in a myriad of health care–related tasks and processes. In this paper, I argue that attention to, public access to, and debate about LLMs have initiated a wave of products and services using GenAI (AI), which had previously found it hard to attract physicians. This paper describes what AI tools have become available since the beginning of the GenAI revolution and contemplates how it they might change physicians’ perceptions about this breakthrough technology.'\n",
      " 'Visual art facilitates expression, communication, and connection, yet it remains inaccessible to those who are visually-impaired and those who lack the resources to understand the techniques and history of art. In this work, I propose the development of a GenAI model that generates a description and interpretation of a given artwork. Such research can make art more accessible, support art education, and improve the ability of AI to understand and translate between creative media. Development will begin with a formative study to assess the needs and preferences of blind and low vision people and art experts. Following the formative study, the basic approach is to train the model on a database of artworks and their accompanying descriptions, predict sentiments from extracted visual data, and generate a paragraph closely resembling training textual data and incorporating sentiment analysis. The model will then be evaluated quantitatively through metrics like METEOR and qualitatively through Turing tests in an iterative process.'\n",
      " 'Explainable AI (XAI) has emerged as a critical field in AI research, addressing the lack of transparency and interpretability in complex AI models. This conceptual review explores the significance of XAI in promoting trust and transparency in AI systems. The paper analyzes existing literature on XAI, identifies patterns and gaps, and presents a coherent conceptual framework. Various XAI techniques, such as saliency maps, attention mechanisms, rule-based explanations, and model-agnostic approaches, are discussed to enhance interpretability. The paper highlights the challenges posed by black-box AI models, explores the role of XAI in enhancing trust and transparency, and examines the ethical considerations and responsible deployment of XAI. By promoting transparency and interpretability, this review aims to build trust, encourage accountable AI systems, and contribute to the ongoing discourse on XAI.'\n",
      " '\\nThe use of GenAI (genAI) in university settings is a current topic of debate, with a range of viewpoints regarding the extent to which these tools should be used by students (Ahmad et al., 2023) and the potential applications of genAI tools in higher education (Yu & Guo, 2023). Concerns have also been raised regarding the potential student misuse of genAI tools, and the ability of these tools to score a passing grade in some university subjects (Nikolic et al., 2023).\\n\\n\\nRMIT University’s position is that we must build the capability in our students to engage with AI as part of the current and future requirements of work. The RMIT units responsible for academic quality and for education innovation have created a set of statements that educators can choose from when designing assessment tasks. These statements include there being no restrictions on the use of genAI tools in the assessment task, that genAI tools can be used with limitations, or that genAI tools cannot be used. \\xa0If students are permitted to use genAI tools in assessment tasks, they must appropriately acknowledge and reference the use of these tools and their outputs.\\n\\n\\nIn the library, we were tasked with creating citing and referencing guidelines for AI-generated content for each of the styles used at our institution, including APA 7th, IEEE, Chicago 17th and AGLC4. A challenge of this project was that there was either no specific genAI referencing advice provided by the style manual editors, or the advice was limited to a specific tool, e.g. GenAI in the case of APA 7th (McAdoo, 2023) and Chicago 17th (The Chicago Manual of Style Online, n.d.). We adapted the existing style advice for referencing software for the APA 7th, Harvard, Chicago 17th, and IEEE styles, the advice for referencing internet sources for Vancouver, and the advice for referencing personal correspondence for AGLC 4. We created referencing guidelines for both AI-generated text and images, as well as when genAI was used for background research. We also incorporated current Australian copyright advice into these guidelines, in which authorship can only be granted to human creators, and so the creator of the tool was used as the author rather than the tool itself. These guidelines are housed in a subject guide (RMIT, 2023) which has received more than 17,000 views between February and July 2023.\\n\\n\\nWe also updated our Academic Integrity Awareness (AIA) microcredential to include educative information about genAI tools. We included guidance relating to the inaccurate information and ethical concerns in some of the current tools, as well as placing these tools within the overall context of academic integrity. This microcredential is used as a component of assessment tasks in many disciplines across our institution.\\n\\n\\nThese resources assist students in maintaining academic integrity when using genAI tools in their learning, and when using genAI in their future careers, as they reinforce the central requirement that the work of others (including work that is AI-generated) is appropriately acknowledged. These resources will continue to be updated as genAI tools evolve and become more widely used within learning.\\n'\n",
      " '<span>Media news are making a large part of public opinion and, therefore, must not be fake. News on web sites, blogs, and social media must be analyzed before being published. In this paper, we present linguistic characteristics of media news items to differentiate between fake news and real news using machine learning algorithms. Neural fake news generation, headlines created by machines, semantic incongruities in text and image captions generated by machine are other types of fake news problems. These problems use neural networks which mainly control distributional features rather than evidence. We propose applying correlation between features set and class, and correlation among the features to compute correlation attribute evaluation metric and covariance metric to compute variance of attributes over the news items. Features unique, negative, positive, and cardinal numbers with high values on the metrics are observed to provide a high area under the curve (AUC) and F1-score.</span>'\n",
      " 'Agile methods are widely known in different companies, including information technology (IT) companies. They appeared intending to solve the problems of traditional methods while proposing an iterative and incremental cycle. These methods consist of four values and the twelve principles agreed upon in 2001 in a Manifesto. However, each method holds singularities from which it is difficult to choose one to adopt in different project cases. The selection of the method to adopt positively or negatively affects the final product following the criteria of the project and the personnel. Project experts must research and compare methods manually to make a choice, a thing that drains time, which is a key factor in project realization. Currently, there is no intelligent system or model that allows choosing the agile method to adopt for such a project. For this purpose, AI (AI) techniques will be used to develop a Chatbot that allows reaching the aim. This Chatbot will be developed based on a decision tree model that will be proposed from an experimental study.'\n",
      " 'GenAI (generative pre-training transformer) merupakan sebuah teknologi kecerdasan buatan dari OpenAI yang berfungsi sebagai chatbot\\xa0dengan kemampuan percakapan mirip manusia. GenAI berpotensi meningkatkan layanan kesehatan, antara lain pelayanan diabetes melitus. Tantangan saat ini adalah faktor-faktor seperti kurangnya sumber daya manusia dan rendahnya kesadaran masyarakat. Integrasi GenAI diusulkan untuk meningkatkan efektivitas layanan kesehatan, menawarkan dukungan diagnostik, dan sumber daya pendidikan untuk kesadaran atas masalah diabetes.'\n",
      " \"With the advent of AI (AI), 'AI art' was born, and the concept of 'AI aesthetics' was derived. Despite the emergence of this new concept in art theory, the question of whether artworks created by AI have artistic and aesthetic value still needs to be debated in academia. While new concepts related to AI art are emerging, the discussion of whether a sustainable and critical theory system can be constructed in the field of computers and art, which is most closely related to it, ought to be focused on AI itself to explore whether it possesses similar characteristics of creativity and emotion as traditional art creation processes. This paper will first analyze the origins and possibilities of AI art and then explore the enormous impact of the rise of AI art on current and future human society in 4 dimensions: creativity, motivation, self-awareness, and emotion.\"\n",
      " 'Recent developments in GenAI (GenAI) have created a paradigm shift in multiple areas of society, and the use of these technologies is likely to become a defining feature of education in coming decades. GenAI offers transformative pedagogical opportunities, while simultaneously posing ethical and academic challenges. Against this backdrop, we outline a practical, simple, and sufficiently comprehensive tool to allow for the integration of GenAI tools into educational assessment: the AI Assessment Scale (AIAS). The AIAS empowers educators to select the appropriate level of GenAI usage in assessments based on the learning outcomes they seek to address. The AIAS offers greater clarity and transparency for students and educators, provides a fair and equitable policy tool for institutions to work with, and offers a nuanced approach which embraces the opportunities of GenAI while recognising that there are instances where such tools may not be pedagogically appropriate or necessary. By adopting a practical, flexible approach that can be implemented quickly, the AIAS can form a much-needed starting point to address the current uncertainty and anxiety regarding GenAI in education. As a secondary objective, we engage with the current literature and advocate for a refocused discourse on GenAI tools in education, one which foregrounds how technologies can help support and enhance teaching and learning, which contrasts with the current focus on GenAI as a facilitator of academic misconduct.'\n",
      " 'AI (AI) systems encode not just statistical models and complex algorithms designed to process and analyze data, but also significant normative baggage. This ethical dimension, derived from the underlying code and training data, shapes the recommendations given, behaviors exhibited, and perceptions had by AI. These factors influence how AI is regulated, used, misused, and impacts end-users. The multifaceted nature of AI’s influence has sparked extensive discussions across disciplines like Science and Technology Studies (STS), Ethical, Legal and Social Implications (ELSI) studies, public policy analysis, and responsible innovation—underscoring the need to examine AI’s ethical ramifications. While the initial wave of AI ethics focused on articulating principles and guidelines, recent scholarship increasingly emphasizes the practical implementation of ethical principles, regulatory oversight, and mitigating unforeseen negative consequences. Drawing from the concept of “ethics dumping” in research ethics, this paper argues that practices surrounding AI development and deployment can, unduly and in a very concerning way, offload ethical responsibilities from developers and regulators to ill-equipped users and host environments. Four key trends illustrating such ethics dumping are identified: (1) AI developers embedding ethics through coded value assumptions, (2) AI ethics guidelines promoting broad or unactionable principles disconnected from local contexts, (3) institutions implementing AI systems without evaluating ethical implications, and (4) decision-makers enacting ethical governance frameworks disconnected from practice. Mitigating AI ethics dumping requires empowering users, fostering stakeholder engagement in norm-setting, harmonizing ethical guidelines while allowing flexibility for local variation, and establishing clear accountability mechanisms across the AI ecosystem.'\n",
      " '<span id=\"docs-internal-guid-cdb76bbb-7fff-978d-961c-e21c41807064\"><span>During the last few years, deep learning achieved remarkable results in the field of machine learning when used for computer vision tasks. Among many of its architectures, deep neural network-based architecture known as convolutional neural networks are recently used widely for image detection and classification. Although it is a great tool for computer vision tasks, it demands a large amount of training data to yield high performance. In this paper, the data augmentation method is proposed to overcome the challenges faced due to a lack of insufficient training data. To analyze the effect of data augmentation, the proposed method uses two convolutional neural network architectures. To minimize the training time without compromising accuracy, models are built by fine-tuning pre-trained networks VGG16 and ResNet50. To evaluate the performance of the models, loss functions and accuracies are used. Proposed models are constructed using Keras deep learning framework and models are trained on a custom dataset created from Kaggle CAT vs DOG database. Experimental results showed that both the models achieved better test accuracy when data augmentation is employed, and model constructed using ResNet50 outperformed VGG16 based model with a test accuracy of 90% with data augmentation &amp; 82% without data augmentation.</span></span>'\n",
      " '<p>Eyesight, an invaluable gift profoundly impacts our daily lives. In a rapidly evolving healthcare landscape, the preservation and enhancement of ocular health stand as critical objectives. This research endeavors to analyze the two retinal fundus multi-disease image datasets (RFMiD) one containing 3200 images and the other containing 860 fundus images. The primary objective of this study is to scrutinize these datasets, discern variations in the frequency of labeled diseases within and across them, and explore common combinations of labels. These findings hold important implications for the field of retinal image analysis, as they provide valuable insights into the distribution and co-occurrence of defects.</p>'\n",
      " 'AbstractThe memorialization of mass atrocities such as war crimes and genocides facilitates the remembrance of past suffering, honors those who resisted the perpetrators, and helps prevent the distortion of historical facts. Digital technologies have transformed memorialization practices by enabling less top-down and more creative approaches to remember mass atrocities. At the same time, they may also facilitate the spread of denialism and distortion, attempt to justify past crimes and attack the dignity of victims. The emergence of generative forms of AI (AI), which produce textual and visual content, has the potential to revolutionize the field of memorialization even further. AI can identify patterns in training data to create new narratives for representing and interpreting mass atrocities—and do so in a fraction of the time it takes for humans. The use of GenAI in this context raises numerous questions: For example, can the paucity of training data on mass atrocities distort how AI interprets some atrocity-related inquiries? How important is the ability to differentiate between human- and AI-made content concerning mass atrocities? Can AI-made content be used to promote false information concerning atrocities? This article addresses these and other questions by examining the opportunities and risks associated with using GenAIs for memorializing mass atrocities. It also discusses recommendations for AIs integration in memorialization practices to steer the use of these technologies toward a more ethical and sustainable direction.'\n",
      " 'This article examines the ways secondary computer science and English Language Arts teachers in urban, suburban, and semi-rural schools adapted a project-based AI ethics curriculum to make it better fit their local contexts. AI ethics is an urgent topic with tangible consequences for youths’ current and future lives, but one that is rarely taught in schools. Few teachers have formal training in this area as it is an emerging field even at the university level. Exploring AI ethics involves examining biases related to race, gender, and social class, a challenging task for all teachers, and an unfamiliar one for most computer science teachers. It also requires teaching technical content which falls outside the comfort zone of most humanities teachers. Although none of our partner teachers had previously taught an AI ethics project, this study demonstrates that their expertise and experience in other domains played an essential role in providing high quality instruction. Teachers designed and redesigned tasks and incorporated texts and apps to ensure the AI ethics project would adhere to district and department level requirements; they led equity-focused inquiry in a way that both protected vulnerable students and accounted for local cultures and politics; and they adjusted technical content and developed hands-on computer science experiences to better challenge and engage their students. We use Mishra and Kohler’s TPACK framework to highlight the ways teachers leveraged their own expertise in some areas, while relying on materials and support from our research team in others, to create stronger learning experiences.'\n",
      " 'AI (AI) is a rapidly growing technological phenomenon that all industries wish to exploit to benefit from efficiency gains and cost reductions. At the macrolevel, AI appears to be capable of replacing humans by undertaking intelligent tasks that were once limited to the human mind. However, another school of thought suggests that instead of being a replacement for the human mind, AI can be used for intelligence augmentation (IA). Accordingly, our research seeks to address these different views, their implications, and potential risks in an age of increased artificial awareness. We show that the ultimate goal of humankind is to achieve IA through the exploitation of AI. Moreover, we articulate the urgent need for ethical frameworks that define how AI should be used to trigger the next level of IA.'\n",
      " \"In the last few years, there has been a lot of research into the use of machine learning for speech recognition applications. However, applications to develop and evaluate air traffic controllers' communication skills in emergency situations have not been addressed so far. In this study, we proposed a new automatic speech recognition system using two architectures: The first architecture uses convolutional neural networks and gave satisfactory results: 96% accuracy and 3% error rate on the training dataset. The second architecture uses recurrent neural networks and gave very good results in terms of sequence prediction: 99% accuracy and 𝑒 −7% error rate on the training dataset. Our intelligent communication system (ICS) is used to evaluate aeronautical phraseology and to calculate the response time of air traffic controllers during their emergency management. The study was conducted at International Civil Aviation Academy, with third-year air traffic control engineering students. The results of the trainees' performance prove the effectiveness of the system. The instructors also appreciated the instantaneous and objective feedback.\"\n",
      " 'This manuscript compares deterministic AI to a model-following control applied to DC motor control, including an evaluation of the threshold computation rate to let unmanned underwater vehicles correctly follow the challenging discontinuous square wave command signal. The approaches presented in the main text are validated by simulations in MATLAB®, where the motor process is discretized at multiple step sizes, which is inversely proportional to the computation rate. Performance is compared to canonical benchmarks that are evaluated by the error mean and standard deviation. With a large step size, discrete deterministic AI shows a larger error mean than the model-following self-turning regulator approach (the selected benchmark). However, the performance improves with a decreasing step size. The error mean is close to the continuous deterministic AI when the step size is reduced to 0.2 s, which means that the computation rate and the sampling period restrict discrete deterministic AI. In that case, continuous deterministic AI is the most feasible and reliable selection for future applications on unmanned underwater vehicles, since it is superior to all the approaches investigated at multiple computation rates.'\n",
      " \"AbstractAs the use of data and AI systems becomes crucial to core services and business, it increasingly demands a multi-stakeholder and complex governance approach. The Information Commissioner's Office’s ‘Guidance on the AI auditing framework: Draft guidance for consultation’ is a move forward in AI governance. The aim of this initiative is toward producing guidance that encompasses both technical (e.g. system impact assessments) and non-engineering (e.g. human oversight) components to governance and represents a significant milestone in the movement towards standardising AI governance. This paper will summarise and critically evaluate the ICO effort and try to anticipate future debates and present some general recommendations.\"\n",
      " 'Narratives about intelligent artefacts have influenced both the public’s imaginary and the actual development of the AI field since its foundation. Yet, in times where the field seems to be flourishing on the one hand, but rushing into an AI winter on the other, factual narratives about AI applications and advancements are more essential than ever. What is the gap between the actual capabilities of today’s AI and the vocabulary used to report about them? In particular, what is the AI lingua used in official, legal documents in business? To find out, we analysed leading share index companies’ annual reports from a representative fraction of the German economy (DAX 30), as a starting step in this direction. In this paper, we present a fact-based methodology for systematically assessing the true state of enterprise AI of those companies. Our initial empirical investigation covers only the annual reports of leading listed German enterprises in the DAX 30 as of May 2021 (i.e. before the DAX’s expansion to 40 members). For this concrete example, we collected their annual reports from 2010 to 2020 (N=312). We then built upon previous work by extending natural language processing (NLP) algorithms we developed for these purposes. The idea is to systematically process and automatically detect the use of AI-related terminology in those annual reports. Such a terminology is part of a classification schema we introduce for differentiating concrete types of AI-related terms. We also compare different NLP libraries regarding their suitability and speculate on the reasons behind the poor performance of some of them. Furthermore, we look at relevant AI keywords and phrases, thereby conducting a human-based semantic analysis of the context – tasks that machines still cannot do effectively. We also give guidance on how to proceed in similar studies, i.e. on how to extend our methodology and the key findings to other national economies. This way, we are contributing not only to an informed perception about the state of enterprise AI, but also to filling the gap between the narratives it uses and the actual state of AI development.'\n",
      " 'Advancements and usefulness of AI (AI) have been transforming the ways in which companies reach decision making and ethical adherence in competitive market. This study has focused on secondary data collection and thematic analysis for developing understanding about the mitigation of bias and transparency in the use of AI technologies. This study has been responsible for stating about different methods that has been used for gaining proper outcomes. Apart from that, preparation of thematic analysis has been effective to reach the research objectives effectively. Finally, this study has also established strategic recommendations through which organisation scan imply proper ethical principles for better utilisation of AI technology.'\n",
      " '<p>One of the trendiest areas in the field of materials science is AI (AI) based physical applications. Typically, more time and resources are needed for traditional experiments and statistical methods. Thus, there is a growing need for applications of AI in the simulation and investigation of novel materials. Usually, there are significant restrictions because there are not any benchmark datasets, sophisticated pre-processing mechanisms, prediction modelling mechanisms, or simulation tools in the literature on materials. This work aims to attempt for examining computational and experimental data-based AI processes. In addition, the state of research into developing new materials and utilizing AI in material modelling tools is implemented. As long as, AI can be used in materials to improve efficiency and prediction accuracy. Also, it is very difficult to determine great learning models, involving data preparation, model architecture, data management, and simulation techniques. Finally, it has been discussed the challenges in realizing AI-based applications in the field of materials science.</p>'\n",
      " '<p><span lang=\"EN-US\">The recent era of pandemic by corona virus disease (COVID-19) has witnessed a faster evolution of various technological solution to thwart the life-threating situation. The most important step was to select a faster mode of screening COVID-19 using chest x-ray (CXR) which could be actually ten folds faster than conventional invasive screening methods. However, the method of determining the presence of COVID-19 from CXR is critically challenging owing to the dynamic and complex nature of disease. Such problem is attempted to be solved by harnessing the potential of AI (AI). Hence, this paper contributes towards discussion of most recent and current implementation strategies formulated by AI models towards diagnosing COVID-19. The study outcome of this paper yields an interesting learning outcome to show that AI models’ adoption is increasing in faster pace and yet challenges do exist till date. The outcome of study will assist in better adoption of AI models towards screening COVID-19.</span></p>'\n",
      " 'AI (AI) is rapidly transforming the business landscape and the global economy. This paper explores the multifaceted impact of AI on existing businesses, focusing on both opportunities and challenges. It analyzes how AI is enhancing productivity, optimizing decision-making, and creating new business models. The paper also examines the potential for job displacement and the need for workforce retraining. Furthermore, it discusses the broader economic implications of AI, including its contribution to economic growth, potential for inequality, and the importance of ethical considerations.'\n",
      " 'This study investigates the profound impact of transfer learning on the performance of AI (AI) models when applied across diverse domains. Transfer learning, a machine learning technique that leverages knowledge gained from one task to improve performance on a related task, has demonstrated remarkable success in various applications. The article explores the underlying principles of transfer learning, its mechanisms, and the ways in which it enhances AI performance. The findings highlight the potential of transfer learning to facilitate knowledge transfer between domains, reduce training data requirements, and accelerate model convergence, ultimately contributing to the broader adaptability and efficiency of AI systems'\n",
      " 'There have been huge leaps in AI (AI) technologies in recent years, which have led to remarkable advancements from self-driving cars to opening your phone with Face ID. Without algorithms and other AI-based technologies, many sectors in society would not exist—they would still be immersed in sci-fi fantasies. But what is AI? Is it how sci-fi media predicted it to be, a world filled with Terminators or a future like the Matrix? Or is it something more romantic and subtle, like the recent AI movie Her? The word itself has many different connotations, and this multiplicity reflects the lack of consensus around how people view AI and its intentions. Regardless of how AI is conceptualized, consideration must be given to its governance. This article works toward establishing a starting point for understanding AI global governance models.'\n",
      " ''\n",
      " \"AI (AI) has transformed education, raised significant ethical concerns and influenced student perceptions. This study examined the perceptions, awareness, and ethical concerns of AI among students in Zamboanga City. Using a mixed-methods approach, quantitative data were collected from 500 university students through stratified random sampling and validated surveys, while qualitative insights were gathered from focus groups. Pilot testing ensured survey clarity and reliability. Findings revealed high AI awareness (75%) but significant ethical concerns (55%), particularly regarding data privacy and job displacement. Despite recognizing AI's educational benefits, students stressed the need for clearer ethical guidelines and transparency. The study recommended integrating AI ethics into curricula, fostering interdisciplinary discussions, and establishing partnerships with AI organizations. Ethical considerations were paramount, ensuring informed consent, confidentiality, and data protection. The conceptual framework was based on the Theory of Planned Behavior, examining how attitudes, subjective norms, and perceived behavioral control influenced AI acceptance. Grounded in Ethical Theories, the study underscored the importance of addressing ethical considerations in AI education. Further research was suggested to explore longitudinal impacts and targeted interventions to enhance AI literacy and mitigate ethical concerns.\"\n",
      " 'The emancipatory effect of copyright on the lives of creators has long been hindered by the concentration of rights by powerful entities that can hold creativity hostage through exclusive rights over countless cultural references. Exceptions to copyright have played an important counter-hegemonic role, supporting what we might call a public domain counterprinciple. The recent explosion of GenAI (GenAI) upends this scenario, with creators bringing copyright infringement claims to the courts to determine, inter alia, the existence and relevance of copying in the training process and whether AI outputs qualify as derivative works. Using digital art as an example, this article assesses these dynamics from the perspective of emancipation, considering the interplay of copyright rules, exceptions, principles and counterprinciples, and seeks to devise pathways, within and outside copyright, to address the challenges posed to creators by GenAI.'\n",
      " 'Still rebounding from the impact of the global pandemic, the higher education sector is being challenged even further by the next wave of AI (AI) technologies. These technologies have the power to generate in a matter of seconds, quality text, images, music and coding responses to questions or prompts entered into an online chat box. Currently, one of the most accessible and popular text generators is OpenAI’s GenAI which was released in November 2022. Early evaluation indicates that the quality of the responses exceed standard pass rates for comparable university assessments. Even if academic protocols mandate that text cited from AI sources should be acknowledged and referenced as any other source material, the speed, accessibility and high quality of the AI material justifies a rethink of the purpose of higher education and a redesign of curriculum, pedagogy and assessment. An initial suggestion being promoted in the sector is that learning outcomes and assessments should move away from a focus on content memorisation and recall, to development of higher order thinking skills such as critical analysis, evaluation, resilience, creativity, problem solving, appraising and mastery of verbal communication and computer literacy. This preliminary paper examines some of the literature to date, which discusses potential risks and threats, as well as the opportunities to enhance learning, embedded in this new wave of emerging AI technologies in higher education. Keywords: AI technologies, generative text software, implications for curriculum, pedagogy and assessment design.'\n",
      " 'The development of AI has gained momentum in recent years in many fields, most of which have been trying to improve organizational functions. However, there are gaps in how organizations should use AI to improve organizational productivity. Regarding the application of AI and the conditions of internal organizations, this research is a conceptual research model that identifies the effects that AI (AI) can have in improving organizational productivity. This research was conducted with the aim of investigating the impact of AI in improving organizational productivity in 1402. The statistical population of the research included all the selected employees of the affiliated companies of the Ministry of Energy in Tehran, whose total number was 330, out of which 175 people were considered as the sample size using the Morgan table and simple random sampling method. The method of data collection was based on the standard questionnaires of AI of Micallef et al. (2023) and the productivity of Achio (1994). After the distribution and collection of questionnaires, information review and hypothesis testing was done using the structural equation modeling method and with the help of Smart PLS 2 software in two parts of the measurement model and the structural part. In the first part, the technical characteristics of the questionnaire including reliability, convergent validity and divergent validity specific to PLS were investigated. In the second part, the significant coefficients of the software were used to check the research hypotheses. Finally, the findings of the research confirmed the impact of AI and its functions, including infrastructure, the ability to expand work and preventive positions in the studied society.'\n",
      " '\\nBackground\\nAI (AI)–based cancer detectors (CAD) for mammography are starting to be used for breast cancer screening in radiology departments. It is important to understand how AI CAD systems react to benign lesions, especially those that have been subjected to biopsy.\\n\\n\\nObjective\\nOur goal was to corroborate the hypothesis that women with previous benign biopsy and cytology assessments would subsequently present increased AI CAD abnormality scores even though they remained healthy.\\n\\n\\nMethods\\nThis is a retrospective study applying a commercial AI CAD system (Insight MMG, version 1.1.4.3; Lunit Inc) to a cancer-enriched mammography screening data set of 10,889 women (median age 56, range 40-74 years). The AI CAD generated a continuous prediction score for tumor suspicion between 0.00 and 1.00, where 1.00 represented the highest level of suspicion. A binary read (flagged or not flagged) was defined on the basis of a predetermined cutoff threshold (0.40). The flagged median and proportion of AI scores were calculated for women who were healthy, those who had a benign biopsy finding, and those who were diagnosed with breast cancer. For women with a benign biopsy finding, the interval between mammography and the biopsy was used for stratification of AI scores. The effect of increasing age was examined using subgroup analysis and regression modeling.\\n\\n\\nResults\\nOf a total of 10,889 women, 234 had a benign biopsy finding before or after screening. The proportions of flagged healthy women were 3.5%, 11%, and 84% for healthy women without a benign biopsy finding, those with a benign biopsy finding, and women with breast cancer, respectively (P<.001). For the 8307 women with complete information, radiologist 1, radiologist 2, and the AI CAD system flagged 8.5%, 6.8%, and 8.5% of examinations of women who had a prior benign biopsy finding. The AI score correlated only with increasing age of the women in the cancer group (P=.01).\\n\\n\\nConclusions\\nCompared to healthy women without a biopsy, the examined AI CAD system flagged a much larger proportion of women who had or would have a benign biopsy finding based on a radiologist’s decision. However, the flagging rate was not higher than that for radiologists. Further research should be focused on training the AI CAD system taking prior biopsy information into account.\\n'\n",
      " \"GenAI (GAI), also known as creative AI, is a technology capable of independently producing original and creative content, such as text, images, videos, music, or code. It uses machine learning algorithms to analyze and learn from a vast amount of data to generate similar or even innovative content. This type of AI is used in several fields, such as health for the production of new drugs, design to generate adaptive designs, video games to create immersive environments, and AI to generate training data for new networks. Seizing the opportunities offered by AI innovations in education is crucial. We cannot afford to let time pass without doing anything and without benefiting from this technique. It is time to enhance traditional learning methods and adopt more innovative approaches that take advantage of the potential of AI, like content and exam generation, and also improve students' learning experience by exploiting their closeness to the technology. This paper aims to answer the question of when and how to use AI responsibly, considering it as a technology and limiting its excessive use. Additionally, we present the impact of GAI through a comparative study of student performance in three exam types: a classical MCQ exam written by the teacher, an adaptive MCQ exam generated by GAI from a topic, and a third MCQ exam generated by GAI based on the content of the provided documents. This study is conducted on students undergoing a software testing training program. By evaluating their performance in the AI-generated adaptive MCQ exams and the traditional MCQ exam, we can gain insights into the potential of this technology to enhance educational practices and provide personalized learning experiences. This research will contribute to the ongoing discussion on responsible and effective utilization of GAI in education, paving the way for future advancements in the field.\"\n",
      " 'Recent developments in \"cryptocurrencies\" and \"smart contracts\" are creating new opportunities for applying AI techniques. These economic technologies would benefit from greater real world knowledge and reasoning as they become integrated with everyday commerce. Cryptocurrencies and smart contracts may also provide an infrastructure for ensuring that AI systems follow specified legal and safety regulations as they become more integrated into human society.'\n",
      " 'In this paper we develop a framework for analysing the impact of AI (AI) on occupations. This framework maps 59 generic tasks from worker surveys and an occupational database to 14 cognitive abilities (that we extract from the cognitive science literature) and these to a comprehensive list of 328 AI benchmarks used to evaluate research intensity across a broad range of different AI areas. The use of cognitive abilities as an intermediate layer, instead of mapping work tasks to AI benchmarks directly, allows for an identification of potential AI exposure for tasks for which AI applications have not been explicitly created. An application of our framework to occupational databases gives insights into the abilities through which AI is most likely to affect jobs and allows for a ranking of occupations with respect to AI exposure. Moreover, we show that some jobs that were not known to be affected by previous waves of automation may now be subject to higher AI exposure. Finally, we find that some of the abilities where AI research is currently very intense are linked to tasks with comparatively limited labour input in the labour markets of advanced economies (e.g., visual and auditory processing using deep learning, and sensorimotor interaction through (deep) reinforcement learning).\\r\\nThis article appears in the special track on AI and Society.'\n",
      " 'The integration of GenAI (AI) tools in art and design has disrupted the traditional creative landscape, leading to debates on the legitimacy of AI-generated art and the emergence of new markets such as non-fungible tokens (NFTs). The US Copyright Office’s February 21, 2023, ruling withdrawing copyright protection for AI-generated comic artwork, while protecting the accompanying text and arrangement, highlights the contested nature of AI art and suggests that significant human intervention in the creative process will be required for monetization. Whether considered content interpolation or content creation, AI generative content for the creation of art and design is here with human-AI collaboration. To explore the potential of AI tools in creative practice, this study introduced students in a digital art course to Craiyon and Midjourney GenAI tools, with DALL-E 2 selected as the primary tool due to its varied output. The students were tasked with selecting a preferred prompt from one tool and then reproducing the output from both tools. The results revealed significant variations in replicating the outputs of different AI tools and limited exploration of prompt engineering, leading to restrictions in the iterative process of artmaking. The students agreed that GenAI tools are not a substitute for human creativity and should be used for final projects. The study demonstrates the potential and limitations of integrating AI tools in art and design and suggests the need for further research in developing effective prompt engineering strategies.'\n",
      " \"With the emergence of the use of AI (AI), ethics in Art and the Media has become more of a concern. The debate on the use of AI in Art and Media has reached its peak. It has been witnessed that several agents of AI in the field of Art can assist large-scale highly refined content without detection and seems like human-created content. However, the discussion hasn’t been enough on the issues and the moral dilemma of ethics which covers the blending of work of a human and a machine. AI Art and media are transforming the way artists and a design creates because GenAI is capable to create artistic content, audio, video and text. This paper explains the expressive and ethical layers of AI art and media with reference to AI research and art contemporary. This conceptual paper aims to draw some critical framework of AI art and media. This paper also challenges the current debate on the ethics of AI by focusing on the studies that are developed around three challenges raised by the AI text agents: disinformation and mass manipulation, a lot of poor-quality content production and the development of a rising barrier among stakeholders for the communication. The paper highlights the relevance of understanding AI art's existential conditions and its potential to inform both artistic and scientific AI research while guiding its cultural handling.\"\n",
      " 'Energy efficiency is challenging task in wireless sensor network (WSN), it is the main barrier in extending network lifespan. In WSN, maximum energy is wasted during data gathering, hence energy efficient algorithms using AI can be designed, that preserves energy while data gathering. Thus, our proposed methodology, A novel energy efficient data gathering algorithm using AI for wireless sensor networks (NDGAI), uses novel AI algorithms and addresses issue of energy consumption while gathering data. In our proposed work, mobile element is utilized to gather information from sensor nodes in the clusters, formed using amended-expectation-maximization. Each cluster should have a cluster leader and a virtual-point. These cluster leaders are formed utilizing fuzzy logic technique. Virtual-points are formed in the range of cluster leader, only when cluster leader has data. The mobile element reaches virtual point by taking the optimal path, that determined by the hybrid AI algorithms, such as artificial-bee-colony (ABC) technique and particle swarm optimization (PSO) algorithms. Thus, by properly performing clustering, cluster leader selection, virtual-point selection and optimal path determination, lead to improved network lifetime and energy saving while gathering the data. Results are simulated and compared with scalable gridbased data gathering algorithm for environmental monitoring wireless sensor networks (SGBDN) and proposed algorithm performs better.'\n",
      " 'The marriage of AI (AI) techniques to problems surrounding the generation, maintenance, and use of source code has come to the fore in recent years as an important AI application area1. A large chunk of this recent attention can be attributed to contemporaneous advancements in Natural Language Processing (NLP) techniques and sub-fields. The naturalness hypothesis, which states that \"software is a form of human communication\" and that code exhibits patterns that are similar to (human) natural languages (Devanbu, 2015; Hindle, Barr, Gabel, Su, & Devanbu, 2016), has allowed for the application of many of these NLP advances to code-centric usecases. This development has contributed to a spate of work in the community --- much of it captured in a survey by Allamanis, Barr, Devanbu, and Sutton (2018) that focuses on classifying these approaches by the type of probabilistic model applied to source code.\\nThis increase in the variety of AI techniques applied to source code has found various manifestations in the industry at large. Code and software form the backbone that underpins almost all modern technical advancements: it is thus natural that breakthroughs in this area should reflect in the emergence of real world deployments.'\n",
      " 'Günümüzde insanın iş yapabilme, yazma, konuşma gibi etkin faaliyetlerini gerçekleştirme kapasitesine yaklaşan yapay zekâ, sanat alanında da giderek daha da gelişmekte ve etkili olmaktadır. Bilgisayar programlarının sanat eserleri üretimine\\n                        katkısı sonucunda, eserlerin sanatsal niteliklerinin sorgulanması ya da kabulü, postmodern sürecin bir parçası olmuştur. Diğer yandan insan hayatını kolaylaştırmak üzere tasarlanan yazılımların sanatsal eylemi taklit etmesini insanın\\n                        yaratıcı eyleminden ayrı tutmak gereklidir. Nitekim bu eylemde İnsanın kendini ifade etmeye duyduğu ihtiyaç söz konusudur. İnsani deneyimlere ilişkin olan duygu, düşünce dünyasının aktarımıdır. İç ve dış dünyayı anlamlandırmayı\\n                        sağlayan bir geçiş alanıdır. İyileştirici bu anlamlandırma sürecinde ortaya çıkan form sanatsal düşünmenin sonucudur. Psikoterapide kullanılan yöntemlerden biri olan sanat terapisinin iyileştirici gücü de sanatın gerekliliğini\\n                        göstermektedir. Nitekim sanat terapisi duyguların anlamlandırılması için iç ve dış dünya arasında bir köprü işlevi görür. Sanat, sözle ifade edemediğimiz duyguların dışarıya aktarımını sağlar. Aynı zamanda sağaltıcı özelliktedir.\\n                        Bu bakımdan, insan yaşamını kolaylaştırmak için tasarlanan yapay zekânın sanatta ne gibi bir rolü olduğu düşündürücüdür. Kuspit, postmodern süreçte düşünce ve kavram odaklı bakış açısının önem kazanmasıyla sanatın insani özü bakımından\\n                        noksan kaldığını öne sürmüştür. Günümüzde de ‘sanatçı robotlar’ın eserlerine dışarıdan yüklenen anlamlarla sanat üreten bir robotun önemli hâle gelmesi sanatın insani özü bakımından noksan kaldığı yeni bir durumu daha meydana getirmektedir.\\n                        Danto’nun, Brillo kutularıyla birlikte “sanat nedir\" sorusunu farklı bir açıdan tartışmaya sunması gibi yapay zekânın sanattaki yerinin tartışılması da önemlidir. Sanatın insansızlaştırılması konusunda eleştirel bir bakış sunmayı\\n                        amaçlayan bu makale, yazılım tabanlı üretilen bir eserin yaratımla ilişkisi üzerine düşündürmeyi amaçlamaktadır. Yaratımın insani yönünü vurgulamak için sanatsal ifadenin gerekliliği ve sanat terapisi arasındaki ilişkiselliğe dikkat\\n                        çekmektedir. Konuyu somutlaştırmak içinse sanatçı robot Ai-Da örneğine yer verilmiştir.'\n",
      " 'The purpose of this article is to reflect the possible connections between Social Technology (TS) and AI (AI), in an attempt to understand some limits and possibilities in the contemporary world. Is it possible to envision any articulation between ST and AI in the health area? What would be the gains and social impacts of this possible articulation? It is these concerns that we intend to reflect on. The article is divided into two moments. In the first moment, we contextualized Social Technology (TS) and AI (AI). In the second and last moment we present the Artificial Partner Technology (TSA), its meaning and perspectives.'\n",
      " 'AbstractAI systems can expand the capabilities and enhance the efficiency of law enforcement agencies preventing, investigating, detecting, and prosecuting criminal offences in the European Union. At the same time, the deployment of AI in the security domain often raises numerous legal and ethical concerns. The ALIGNER Fundamental Rights Impact Assessment is an operational tool, rooted in fundamental rights and in the principles of AI ethics, ready to be integrated in the AI governance measures of European law enforcement agencies to inform their decision-making processes and ensure compliance with the recently adopted AI Act. This paper first introduces the main tensions between law enforcement AI and fundamental rights, as enshrined in the Charter of Fundamental Rights of the European Union; then, it gives an overview of the main developments and best practices in AI governance and their relationship with fundamental rights as well as AI ethics; and finally, it describes the structure of the ALIGNER Fundamental Rights Impact Assessment.'\n",
      " 'AbstractArtificial General Intelligence (AGI) is said to pose many risks, be they catastrophic, existential and otherwise. This paper discusses whether the notion of risk can apply to AGI, both descriptively and in the current regulatory framework. The paper argues that current definitions of risk are ill-suited to capture supposed AGI existential risks, and that the risk-based framework of the EU AI Act is inadequate to deal with truly general, agential systems.'\n",
      " 'AbstractBiases in cognition are ubiquitous. Social psychologists suggested biases and stereotypes serve a multifarious set of cognitive goals, while at the same time stressing their potential harmfulness. Recently, biases and stereotypes became the purview of heated debates in the machine learning community too. Researchers and developers are becoming increasingly aware of the fact that some biases, like gender and race biases, are entrenched in the algorithms some AI applications rely upon. Here, taking into account several existing approaches that address the problem of implicit biases and stereotypes, we propose that a strategy to cope with this phenomenon is to unmask those found in AI systems by understanding their cognitive dimension, rather than simply trying to correct algorithms. To this extent, we present a discussion bridging together findings from cognitive science and insights from machine learning that can be integrated in a state-of-the-art semantic network. Remarkably, this resource can be of assistance to scholars (e.g., cognitive and computer scientists) while at the same time contributing to refine AI regulations affecting social life. We show how only through a thorough understanding of the cognitive processes leading to biases, and through an interdisciplinary effort, we can make the best of AI technology.'\n",
      " 'The subject of this paper is ethical and responsibility issues relating to the development and acquisition of robotics in healthcare. The purpose of the paper is to study previous scientific publications and research related to the topic and to clarify which questions, aspects, and concerns are most relevant when considering ethics and responsibility issues related to care robots. In the second phase, ideas from different stakeholders regarding the viewpoints are studied, and those ideas are compared to the ones presented in previous publications. The aim of this study is to find solutions to the issues presented in scientific literature and, also, to find new issues for consideration and further studies. The study is qualitative, and a theme interview was utilized as the main method for acquiring knowledge. The study is a part of the SHAPES Horizon 2020 project. From the perspective of SHAPES, the aim of the study is to provide useful knowledge for the project, which would in part promote the goal of SHAPES, i.e., the development of an international healthcare ecosystem. Based on the results of the study, it can be argued that the issues presented in previous academic publications regarding the ethics and accountability of robots in practical healthcare work are not relevant. Both the legislation and the logic of the AI algorithms used by care robots prevent those situations presented in previous academic discussions in which robots would presumably be forced to make decisions demanding ethical consideration. The results also point toward the fact that current legislation does not limit the development of healthcare robots more than it limits healthcare work in general. Thus, the considerations of ethics regarding care robots should rather be focused on the threshold values used by robots, when making interpretations, as well as the data used for the purpose of machine learning. These were identified as potential subjects for further research.'\n",
      " \"The rise of GenAI, such as GenAI, poses challenges for the education sector. To explore strategies for addressing GenAI issues and identifying educational applications, it is essential for us to understand the concerns and attitudes of educators, who are the key implementers in education. In this context, this study investigated the experiences and concerns of university professors regarding the educational use of GenAI by utilizing the Concerns-Based Adoption Model (CBAM). Data was collected from 100 professors representing various disciplines at University A in Gyeonggi-do. The majority of respondents had some experience with GenAI, but its educational utilization was limited. Concerns included the provision of incorrect or biased information, ethical issues, and users' lack of ability to use GenAI. However, 61% of respondents expressed their intention to apply GenAI in their courses in the upcoming semester. Concern levels aligned with the non-user profile, with lower concerns in the consequence stage. There were no significant differences in concern levels based on the professors' disciplines, but differences were observed based on their experience and intention to use GenAI in their classes. Professors who had already used GenAI in their classes showed higher concerns regarding the consequence, collaboration, and refocusing stages. Based on these findings, implications for the educational use of GenAI in higher education were discussed.\"\n",
      " \"This research aims to apply an AI (AI) system to control the position of photovoltaic (PV) panels to maximize the use of solar energy using the solar tracker. The implementation of AI algorithms to achieve optimal panel orientation, considering factors such as sunlight intensity and sun position is also discussed. The simulation results using matrix laboratory (MATLAB) Simulink can be observed on the scope, displaying the position control graph of the solar panel from sunrise to sunset. By employing proportional integral derivative (PID) control, the error is likely to be minimal, ensuring that the panel will continue to follow the sun until it sets at the maximum point of 4:00 PM. After that, the panel can be adjusted back or reset to the initial position at 6:00 AM for the following day. In a full-day simulation, the solar panel will follow the sun's movement from sunset to sunrise. At the basic level, sunrise occurs in the first hour at position 1.0, which is 6:00 AM in the minimum point at the bottom left corner of the curve, and sunset occurs in the afternoon at position 5.25, which is 4:00 PM at the maximum point in the top right corner of the curve.\"\n",
      " 'ABSTRACTAI (AI) and machine learning have demonstrated the potential to provide solutions to societal challenges, for example, automated crop diagnostics for smallholder farmers, environmental pollution modelling and prediction for cities and machine translation systems for languages that enable information access and communication for segments of the population who are unable to speak or write official languages, among others. Despite the potential of AI, the practical and technical issues related to its development and deployment in the African context are the least documented and understood. The development and deployment of AI for social impact systems in the developing world present new intricacies and requirements emanating from the unique technology and social ecosystems in these settings. This paper provides a rubric for developing and deploying AI systems for social impact with a focus on the African context. The rubric is derived from the analysis of a series of selected real‐world case studies of AI applications in Africa. We assessed the selected AI case studies against the proposed rubric. The rubric and examples of AI applications presented in this paper are expected to contribute to the development and application of AI systems in other African contexts.'\n",
      " 'Many educators and professionals in different industries may need to become more familiar with the basic concepts of AI (AI) and GenAI (Gen-AI). Therefore, this paper aims to introduce some of the basic concepts of AI and Gen-AI. The approach of this explanatory paper is first to introduce some of the underlying concepts, such as AI, machine learning, deep learning, artificial neural networks, and large language models (LLMs), that would allow the reader to better understand GenAI. The paper also discusses some of the applications and implications of GenAI on businesses and education, followed by the current challenges associated with GenAI.'\n",
      " 'This study explores the complex process of integrating GenAI (GenAI) into a flipped classroom. Employing Clandinin and Connelly’s (2000) narrative inquiry framework, the study collected data from class observations and semi-structured interviews with a lecturer and six English-majored undergraduates before, during, and at the end of a 15-week British Literature course. Bhattacharya’s (2017) inductive analysis model was used to inform the thematic narrative sub-approach. The findings revealed both challenges and benefits associated with using GenAI for flipped learning while highlighting its impact on students’ self-regulated learning and teacher self-efficacy.\\nThis presentation retells stories from the participants’ lived experiences in a GenAI-enabled and flipped classroom. Exemplary learning resources are showcased to demonstrate how GenAI tools can effectively and efficiently facilitate flipped learning. The insights gained from this study contribute to a deeper understanding of the potential of GenAI in transforming educational practices and enhancing the flipped learning experience.'\n",
      " 'AbstractWith the development of information technologies and information processing methods, it is important to provide high‐quality education in the field of AI (AI). The study aims to investigate the impact of an educational course on AI on the comprehension of concepts, literacy, and empowerment in the field of AI among students of higher educational institutions. The experiment involved 125 students from Hohai University in China. As a result of taking the training course, students were able to improve their understanding of concepts (increasing their average score from 6.33 to 9.69), literacy (from 2.94 to 3.99), and empowerment (from 3.90 to 4.04) in AI. The resulting data statistically confirmed the effectiveness of the developed course for improving confidence in the field of AI. The training module can be applied to improve confidence in the field of AI for students in various careers, as information competence is important these days and increases the success of graduates in employment. When it comes to further research, the encouraging results of this study suggest opportunities for promoting this training program among a diverse group of participants. To confirm the effectiveness of the developed course, it can be conducted among students in schools and other educational institutions, reducing it to even more basic if necessary.'\n",
      " 'Editorial\\nAI Medicine: Pioneering the Integration of AI in Healthcare\\nYu-Dong Yao\\nDepartment of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ 07030, USA\\nReceived: 15 April 2024; Accepted: 17 April 2024; Published: 17 April 2024'\n",
      " 'AI (AI) describes computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. Examples of AI techniques are machine learning, neural networks, and deep learning. AI can be applied in many different areas, such as econometrics, biometry, e-commerce, and the automotive industry. In recent years, AI has found its way into healthcare as well, helping doctors make better decisions (“clinical decision support”), localizing tumors in magnetic resonance images, reading and analyzing reports written by radiologists and pathologists, and much more. However, AI has one big risk: it can be perceived as a “black box”, limiting trust in its reliability, which is a very big issue in an area in which a decision can mean life or death. As a result, the term Explainable AI (XAI) has been gaining momentum. XAI tries to ensure that AI algorithms (and the resulting decisions) can be understood by humans. In this narrative review, we will have a look at some central concepts in XAI, describe several challenges around XAI in healthcare, and discuss whether it can really help healthcare to advance, for example, by increasing understanding and trust. Finally, alternatives to increase trust in AI are discussed, as well as future research possibilities in the area of XAI.'\n",
      " \"Our analysis explores the benefits of AI (AI) in music generation, showcasing progress in electronic music, automatic music generation, evolution in music, contributions to music-related disciplines, specific studies, contributions to the renewal of western music, and hardware development and educational applications. The identified methods encompass neural networks, automation and simulation, neuroscience techniques, optimization algorithms, data analysis, and Bayesian models, computational algorithms, and music processing and audio analysis. These approaches signify the complexity and versatility of AI in music creation. The interdisciplinary impact is evident, extending into sound engineering, music therapy, and cognitive neuroscience. Robust frameworks for evaluation include Bayesian models, fractal metrics, and the statistical creator-evaluator. The global reach of this research underscores AI's transformative role in contemporary music, opening avenues for future interdisciplinary exploration and algorithmic enhancements.\"\n",
      " 'AI (AI) systems have become ubiquitous, transforming various sectors such as healthcare, finance, and criminal justice. However, the potential for bias in these systems raises ethical and practical concerns.'\n",
      " 'IntroductionAn intense debate has been on-going about how AI (AI) technology investments have an impact on employment. The debate has often focused on the potential of AI for human task automation, omitting the strategic incentive for firms to cooperate with their workers as to exploit AI technologies for the most relevant benefit of new product and service innovation.MethodWe calibrate an empirical probit regression model of how changes in employment relate to AI diffusion, based on formalizing a game-theoretical model of a firm exploiting the twin role of AI innovation and AI automation for both absolute and competitive advantage.ResultsThe theoretical game-theory prediction is that employment following AI technology adoption is not negative, and ultimately depends on how AI leads to new success in innovation, competition which defines the competitive reward of innovation and profit sharing between workers and firms. Our estimation, is based on a global survey of 3,000 large companies across 10 countries, demonstrates that a firm employment growth depends on two strategic postures, that is, the firm relative maturity of AI adoption as well as its relative bias toward AI-based product innovation.DiscussionThe contribution of this research is to highlight the twin role of firm and workers in shaping how technology will affect employment. AI in particular marries the potential of task automation with even more potential for expansion.'\n",
      " 'We are in a stage of transition as AI (AI) is increasingly being used in healthcare across the world. Transitions offer opportunities compounded with difficulties. It is universally accepted that regulations and the law can never keep up with the exponential growth of technology. This paper discusses liability issues when AI is deployed in healthcare. Ever-changing, futuristic, user friendly, uncomplicated regulatory requirements promoting compliance and adherence are needed. Regulators have to understand that software itself could be a software as a medical device (SaMD). Benefits of AI could be delayed if slow, expensive clinical trials are mandated. Regulations should distinguish between diagnostic errors, malfunction of technology, or errors due to initial use of inaccurate/inappropriate data as training data sets. The sharing of responsibility and accountability when implementation of an AI-based recommendation causes clinical problems is not clear. Legislation is necessary to allow apportionment of damages consequent to malfunction of an AI-enabled system. Product liability is ascribed to defective equipment and medical devices. However, Watson, the AI-enabled supercomputer, is treated as a consulting physician and not categorised as a product. In India, algorithms cannot be patented. There are no specific laws enacted to deal with AI in healthcare. DISHA or the Digital Information Security in Healthcare Act when implemented in India would hopefully cover some issues. Ultimately, the law is interpreted contextually and perceptions could be different among patients, clinicians and the legal system. This communication is to create the necessary awareness among all stakeholders.'\n",
      " \"The integration of AI (AI) and technology in English Language Learning (ELL) is revolutionizing education. This research explores the impact of AI and technology on English language learners at Quest University, Nawabshah. Through a quantitative approach and an online questionnaire, the Researcher delves into students' perceptions and experiences. Technology, encompassing computers, smartphones, tablets, and AI-powered chat bots, plays a pivotal role. The majority of students find technology-enhanced learning engaging and enjoyable, making it easier to practice English outside the classroom. AI-powered tools receive acclaim for increasing motivation, proficiency, and preference over traditional methods. However, the enjoyment of AI chat bots remains diverse.\"\n",
      " '..'\n",
      " 'This paper is devoted to determining the trends of the AI economy in Russia. The method of trend analysis was used to find the dynamics of change in the values of the indicators of development of the AI economy in Russia. As a result, we revealed the specific features of its Russian model. The first feature is that in Russia, the key participant of the AI economy is the government, and the role of business, despite its being a secondary player, constantly grows. The second feature is that Russia successfully strengthens technological sovereignty in the sphere of the AI economy. The main conclusion is that in the Russian model, the advantages of the AI economy are connected with the growth of the share of knowledge-intensive employment and an increase in the quality of life, and its risks consist in a possible slowdown of the growth rate of labour productivity and reduction of the quality of products. The managerial significance of the paper is that the compiled econometric model generalised the leading experience of the top 30 AI economies in the world in 2023 and disclosed the cause-and-effect relationships of its development. The practical significance is that the authors’ forecast outlined the perspective of the development of the AI economy in Russia in the Decade of Science and Technologies until 2031.'\n",
      " 'AbstractAccurately predicting homeowners’ aesthetic preferences is crucial in interior design. This study develops a fine-tuning model (LORA) for interior design styles corresponding to different MBTI personality types, leveraging the Stable Diffusion Web UI platform and integrating it into a GenAI framework. Subsequently, personalized aesthetic preference architectural interior renderings are recommended based on homeowners’ personality traits, aiming to achieve an adaptive interior design approach. To achieve more precise adaptive solutions, this research surveys the style and color tendencies of respondents with different MBTI personality types and adds style description prompts to assist in image generation. The study finds that this method can better predict the interior design styles favored by certain MBTI personality types. This research contributes to addressing aesthetic biases between designers and homeowners, bringing innovative ideas and methods to interior design, and is expected to enhance homeowners’ satisfaction.'\n",
      " 'AI has been talked about for over half a century now. Still, it became a fast-growing reality in 2023 through modern technologies, such as Meta AI, Open AI, or GenAI, and has created some ethical concerns. This research provides examples of how AI is being used in academia, how it can be used, and how to assess college students’ familiarity with such technologies, their perception of it, and level of usage. Using an AI-generated short survey to gather quantitative and qualitative data through a discussion exercise, 126 undergraduates with four different professors were asked to share their answers and views. The findings show that many of today’s college students in South Florida see the usage of AI as ethical and legal. However, a few respondents remain uncertain due to a lack of clear guidelines from professors and the institution. Thus, most respondents reported that they are familiar with AI as they use it multiple times weekly. Consequently, educators and administrators must sharpen their students’ AI skills so they can be ethical and competitive in the workplace. Implications for students, educators and administrators in the higher education arena are explored. Besides serving as a person’s second brain, using AI can be an excellent way for students to mitigate and overcome procrastination, enhance their productivity, and comprehensively complete academic projects on time. Furthermore, the proper use of AI tools can reduce errors, quickly assess large amounts of data, automate repetitive functions, lead to better decisions, and help learners move forward amid challenging obstacles. As such, academic institutions must do more to ensure they are “sharpening their students’ AI saw” before they graduate and embark on their professional endeavors. AI, when used properly, ethically, and legally following established industry norms and guidelines, offers many transformative benefits across diverse fields to benefit human beings and society. Students pursuing a healthcare career can use AI to aid in early disease detection, accelerate drug discovery, and improve patient care through precision medicine. Graduates in the engineering or transportation industries can use AI to optimize traffic flow, enhance safety with autonomous vehicles, and reduce emissions through predictive maintenance. Moreover, those who remain in the education field after graduation can use AI to facilitate personalized learning experiences tailored to individual student needs while fostering greater engagement and academic success for all learners. The latest advancements underscore AI’s potential to drive innovation, increase efficiency, and address complex challenges while ultimately shaping a more interconnected and prosperous future for everyone in society.'\n",
      " 'AbstractNurses have traditionally been regarded as clinicians that deliver compassionate, safe, and empathetic health care (Nurses again outpace other professions for honesty & ethics, 2018). Caring is a fundamental characteristic, expectation, and moral obligation of the nursing and caregiving professions (Nursing: Scope and standards of practice, American Nurses Association, Silver Spring, MD, 2015). Along with caring, nurses are expected to undertake ever‐expanding duties and complex tasks. In part because of the growing physical, intellectual and emotional demandingness, of nursing as well as technological advances, AI (AI) and AI care robots are rapidly changing the healthcare landscape. As technology becomes more advanced, efficient, and economical, opportunities and pressure to introduce AI into nursing care will only increase. In the first part of the article, we review recent and existing applications of AI in nursing and speculate on future use. Second, situate our project within the recent literature on the ethics of nursing and AI. Third, we explore three dominant theories of caring and the two paradigmatic expressions of caring (touch and presence) and conclude that AI—at least for the foreseeable future—is incapable of caring in the sense central to nursing and caregiving ethics. We conclude that for AI to be implemented ethically, it cannot transgress the core values of nursing, usurp aspects of caring that can only meaningfully be carried out by human beings, and it must support, open, or improve opportunities for nurses to provide the uniquely human aspects of care.'\n",
      " 'This study examines the impact of AI (AI) on financial control, exploring the implementation of AI technology in financial selection-making strategies, predictive analysis and hazard manipulation. the use of a systematic literature examine approach, this studies covers the substantial modifications delivered via using AI in improving operational overall performance, presenting deep insights for financial preference making, and improving customer revel in in the banking area.. Even though it provides great benefits, this research also highlights ethical challenges, data security, adoption risks, as well as the need for policy and regulatory adjustments to the development of AI technology in the context of financial management. It is hoped that the results of this research can provide guidance for companies and policy makers in facing revolutionary changes in financial management in the digital era.'\n",
      " 'The rapid advancement of AI (AI) has significantly influenced the landscape of digital transformation, particularly within the realm of cloud computing. This paper explores the symbiotic relationship between AI and cloud transformation, highlighting how AI-driven technologies enhance cloud infrastructure, optimize resource management, and drive innovation across industries. The integration of AI in cloud services has led to the development of more efficient, scalable, and secure cloud solutions, enabling businesses to achieve greater agility and competitiveness. This study examines the key benefits and challenges associated with the AI-cloud synergy, providing insights into future trends and the strategic implications for organizations embarking on their digital transformation journeys.'\n",
      " 'In the constantly expanding field of cybersecurity, AI (AI), and more specifically GenAI (GenAI) impacts every aspect of the cybersecurity landscape. In today’s world, most manual transactions, interactions, and records have become digital, generating vast amounts of valuable data. Many devices are connected by various private or public networks to the Internet known as the Internet of Things(IoT). This has led to many incidents where users and organizations have been targeted for Fraud, data theft, and disruption to businesses among other challenges. AI-based tools play a key role in defending against cyber attacks rapidly and effectively, due to their ability to analyze large volumes of data in real time. GenAI models can continuously learn and adapt, thus proactively assisting with cyber defense. For digital users and entities, this can help protect data, reduce incidents of Fraud, and model threats, keep systems safe, and mitigate other risks. The applications of GenAI however do not extend just to the defense of systems, they can also be used to increase cybersecurity threats. Malicious actors might use covert methods to manipulate data, attack systems, avoid malware detection, and spread harmful or incorrect information. This paper will detail how AI is a double-edged sword in cyber security, providing proactive and increasingly rapid and efficient ways to enhance cyber defense, as well as its use in newer and more damaging threats. It also aims to bring awareness of regulatory and other impacts on society.'\n",
      " \"In today's rapidly changing technological landscape, AI (AI) is making headlines and being discussed constantly. To be sure, AI provides a powerful tool to nonprofits in creating content and exploiting for countless cost‐effective purposes. As nonprofit executives, you may be wondering how AI intersects with intellectual property and data privacy law, and how it could affect your organization. While the full extent of the implications will only be fully understood after some history with the use of AI, some of the issues are already predictable.\"\n",
      " ''\n",
      " 'This research paper examines the transformative impact of AI (AI) and machine learning (ML) on financial markets. It explores how these technologies are revolutionizing trading strategies, risk management, and financial operations. The paper reviews existing literature to understand the applications of AI and ML in finance. It then delves into potential research methodologies for analyzing the impact of these technologies on market efficiency, volatility, and investor behavior. Finally, the paper discusses the potential outcomes and challenges associated with the increasing adoption of AI and ML in financial markets.'\n",
      " 'This study investigates the transformative impact of AI (AI) on marketing communications through an evaluation research approach. Focused on enhancing personalization, efficiency, and strategic insight, the study explores AI’s applications in content creation, customer service, social media, influencer marketing, and predictive analytics. The results reveal a paradigm transition in customer engagement and behaviour analysis, highlighting AI’s role in providing profound insights and facilitating real-time interactions. Personalized marketing and targeted advertising have evolved, with AI analysing vast datasets to craft tailored messages, significantly enhancing communication relevance. AI’s impact extends to content creation and curation, accelerating processes through natural language generation and improving content personalization. Moreover, AI-driven chatbots redefine customer service, providing 24/7 personalized support and actively contributing to marketing strategies. Social media and influencer marketing benefit from AI’s optimization of content delivery, personalization, and campaign impact measurement. The synergy between AI and predictive analytics anticipates consumer behavior, enabling precise targeting and optimizing the customer journey. The study concludes with implications for businesses, advocating strategic AI integration for sustained growth, and emphasizes the necessity of staying attuned to emerging AI innovations in future research. This research serves as a roadmap, guiding businesses toward successfully navigating the digital era’s evolving marketing communications view.'\n",
      " 'The emergence of widely-used AI (AI) has created a critical need for AI expertise, not just as a research area but for workers in the wide variety of careers and roles that AI disrupts.\\xa0 While AI is still an area of research for new processing, application, and development – it continues to partially automate, augment, or replace many of the tasks which are performed through active use of human hands.\\xa0 While recently publicized items such as GenAI and MidJourney have made press in their adjustment to writing and image generation technology, the basic workflow of copyeditors and digital artists was completely transformed, inside of the year, to a combination of partially automated or fully automated AI tasks.\\xa0 While some blame AI as part of the “problem”, it is naturally part of the “solution” – AI tools to help workers develop AI competencies.\\xa0 The paper describes an array of strategies which the DoD and its ICT UARC are using to address the fundamental problem of quickly upskilling the DoD workforce of over 2 million adult learners.'\n",
      " 'AI (AI) has transcended beyond buzzwords, keywords or trends. The ubiquity of AI is so profound that it has managed to seep into popular culture. It breeds throughout social media platforms. It dominates the airwaves. It is impossible to watch television without mention of the acronym, the word, and how everyone is using it. However, if we look a little closer, take a deep dive into the AI pool where everyone seems to be swimming, we began to learn that AI has been misinterpreted, misrepresented, and incorrectly defined. \"In the Laws of Thought and Thinking Machines,\" Hughes and Hughes (2019) talk about how uncovering the truth of the definition, meaning, applications, and implications of AI would be a noteworthy goal. Today we are pursuing that goal.'\n",
      " 'AI (AI)-enabled text-to-speech transformation has been widely employed to deliver online information in various fields. However, few studies have investigated the effect of the AI voice in environmental risk communication, especially in the field of climate change, an issue that poses a severe threat to global public health. To address this gap, the current study examines how the AI voice impacts the persuasive outcome of climate-related information and the potential mechanism that underlies this process. Based on the social and affect heuristics of voice, we propose a serial mediation model to test the effect of climate-related information delivered by different voice types (AI voice vs. human voice) in eliciting risk perception and motivating pro-environmental behavioral intention. Through an online auditory experiment (N = 397), we found the following. First, the AI voice was as effective as the human voice in eliciting risk perception and motivating pro-environmental behavioral intention. Second, compared with human voice, the AI voice yielded a listener’s lower level of perceived identity oneness with the speaker, which decreased risk perception and subsequently inhibited pro-environmental behavioral intention. Third, compared with human voice, the AI voice produced a higher level of auditory fear, which increased risk perception and thereby led to stronger pro-environmental behavioral intention. The paradoxical role of the AI voice and its wise use in environmental risk communication for promoting global public health are discussed.'\n",
      " 'This inquiry explores the impact of automation and AI (AI) on leadership and the workforce, as well as strategies for leaders to effectively navigate the transition towards a technology-focused workplace. The aim of this research is to expand current understanding by providing valuable insights into how AI and automation affect leadership and the workforce, alongside practical suggestions for managing this transformation. It is essential to recognize the potential benefits of AI and automation, such as improved efficiency and decision-making abilities, while also acknowledging concerns about potential job displacement and ethical considerations. Through a thorough examination of these issues, this study aims to equip organizations and leaders with the necessary resources to prepare for the future of work and ensure they are well-positioned for success in an increasingly technology-driven environment.'\n",
      " 'With the rapid development of information society and computer science, new media art has not made a qualitative leap in the past decade. The reason is that in big data and machine learning, the rapid development of AI technology has brought computer science up to a higher level, while art is still stuck in aesthetics, acoustics, vision, psychology and other aspects, lack of logic, intelligence and integration. Therefore, the new media art needs the support of the computer technology, especially the new technology.In the design stage of new media art, technologies such as AI, machine learning and big data mining are integrated to improve the molding speed of new media art through mathematical modeling.Through machine learning, quickly understand user experience and user needs, further optimize new media art works, use AI AI technology to simulate new media art, and simulate the whole process of user experience and interaction is the main content of this paper.This makes new media art become a typical application in the field of AICG (AI production content). GenAI will greatly reduce the marginal cost of creation and knowledge work, greatly improve labor productivity and economic value, and realize the generation of new media art original content at one tenth of the cost and thousands times production speed.'\n",
      " 'Abstract\\nGenAI has ushered in a new era of AI (AI) that already has significant consequences for many industries, including health care and education. GenAI tools, such as GenAI, refer to AI that is designed to create or generate new content, such as text, images, or music, from their trained parameters. With free access online and an easy-to-use conversational interface, GenAI quickly accumulated more than 100 million users within the first few months of its launch. Recent headlines in the popular press have ignited concerns relevant to medical education over the possible implications of cheating and plagiarism in assessments as well as excitement over new opportunities for learning, assessment, and research. In this Scholarly Perspective, the authors offer insights and recommendations about GenAI for medical educators based on literature review, including the AI literacy framework. The authors provide a definition of GenAI, introduce an AI literacy framework and competencies, and offer considerations for potential impacts and opportunities to optimize integration of GenAI for admissions, learning, assessment, and medical education research to help medical educators navigate and start planning for this new environment. As GenAI tools continue to expand, educators need to increase their AI literacy through education and vigilance around new advances in the technology and serve as stewards of AI literacy to foster social responsibility and ethical awareness around the use of AI.'\n",
      " 'This research focused on testing with maize, economical crop grown in Phetchabun province, Thailand, by installing a total of 20 sets of internet of things (IoT) devices which consist of soil moisture sensors and temperature and humidity sensors (DHT11). Data science tools such as rapidminer studio was used for data cleansing, data imputation, clustering, and prediction. Next, these data would undergo data cleansing in order to group them to obtain optimization clustering to identify the optimum condition and amount of water required to grow the maize through k-mean technique. From the analysis, the optimization result showed 3 classes and these data were further analyzed through prediction to identify precision. By comparing several algorithms including artificial neural network (ANN), decision tree, naïve bayes, and deep learning, it was found that deep learning algorithm can provide the most accurate result at 99.6% with root mean square error (RMSE)=0.0039. The algorithm obtained was used to write function to control the automated watering system to make sure that the temperature and humidity for growing maize is at appropriate condition. By using the improved watering system, it improved the efficacy of watering system which saves more water by 13.89%'\n",
      " 'Abstract:\\r\\nAI (AI) is the simulation of human intelligence processes by machines or computer systems. As large language generated pretrained transformers, when given a prompt the chatbot system rewards the user with a ‘human-like’ response from their massive dataset of information. Their velocity, scope and capabilities become immense. This article is an illustrative analysis focusing on the rise of AI and its applications within industry, health and in particular, social work placement. The suggestion is to encourage practice teachers and students within supervision to use the chatbots GenAI or Perplexity in order to enhance critical thinking. To further consider the areas such as language, power, intuition, confidentiality, ethics, values and beliefs in this brave new world. Limitations of chatbot use within supervision is explored and a balanced conclusion recognising the worth of social work as a profession but not denying the speed of AI development is recognised. From a social work placement perspective this article considers how working from a new evidence base, the application of critically analysing digitally produced knowledge, can be a relevant teaching tool within placement supervision.\\r\\n\\xa0'\n",
      " \"Food is a fundamental human necessity. We need enough nutrition from the diet to carry out our tasks. The biochemical and physiological process known as nutrition describes how an organism uses food to turn it into energy. One of the primary nutrients, carbohydrates keep bodily cells' levels of energy stable. Malnutrition is a severe issue for public health since it has detrimental long-term effects. Adults over 65 years old's nutritional status is influenced by both psychological changes and physiologic factors. The blood glucose level is directly regulated by carbohydrates, which also lowers the chance of developing chronic diseases. Fresh fruits and vegetables, whole grains, legumes, seeds, and nuts are all part of a healthy diet, which also includes fewer animal products, especially fatty and processed meats. In this study, we will determine how much nutrition we consume from food, the impacts that result when that level is over normal, the repercussions of undernutrition, and the precise information regarding carbohydrates. An AI-enabled Recapitulated Neuro Fuzzy Optimization algorithm is applied for evaluating the nutritious food intake of men and women during Covid-19 situation.\"\n",
      " 'The application of AI (AI) into photography has given rise to a controversial discussion over image perception, originality, and authenticity. Though AI presents artists with new tools and opportunities, worries over the degradation of artistic integrity and emotional depth continue. This paper investigates the complex ramifications of AI (AI)-generated art, looking at how it affects the artistic process, public opinion, and the changing field of visual expression. Drawing on insights from recent controversies in the film industry and diverse perspectives from artists, the present essay delves into the complexities of AI-generated art.'\n",
      " 'This statement revises our earlier “WAME Recommendations on GenAI and Chatbots in Relation to Scholarly Publications” (January 20, 2023). The revision reflects the proliferation of chatbots and their expanding use in scholarly publishing over the last few months, as well as emerging concerns regarding lack of authenticity of content when using chatbots. These Recommendations are intended to inform editors and help them develop policies for the use of chatbots in papers published in their journals. They aim to help authors and reviewers understand how best to attribute the use of chatbots in their work, and to address the need for all journal editors to have access to manuscript screening tools. In this rapidly evolving field, we will continue to modify these recommendations as the software and its applications develop.'\n",
      " '<p>The significance of internet-of-vehicle (IoV) is spontaneously increasing with exponentially rising demands towards transportation system and road safety. At present, there are various number of scientific approaches which is meant for leveraging the communication performance in IoV, but yet the problem still exists over multiple attributes e.g. resource management, privacy, security, and service offloading. Such problems are anticipated to be solved by 6G services that offers better communication capabilities compared to its prior version of 5G. At the same time, the quality of communication system can be enhanced by AI (AI), which is capable of solving complex real-world problems. Therefore, this manuscript offers an insight towards strength and weakness of existing 6G based study model as well as AI-based solution in order to contribute towards highlighting an essential research gap that could directly offer better insight towards future planning towards improving communication in IoV.</p>'\n",
      " 'AI (AI) is becoming increasingly influential in the academic sector, which is why it is important to explore the ethical dilemmas and concerns surrounding AI chatbots’ design, development, and deployment in educational contexts. Conducted as a thematic literature review, this paper explores existing research on AI in education, AI chatbots, and their integration with higher education to gather evidence and insights that discuss ethical implications and challenges. The study has analyzed several articles on AI chatbots and their integration into academic fields. Significant gaps have been identified, such as the need for more practical implications and the recognition of AI chatbots as a collaborative tool for academic purposes. More AI chatbots should be explicitly trained on data relevant to the learners’ study to examine their usefulness properly. The paper discusses the ethical dilemmas and concerns about the design, development, and deployment of AI chatbots in higher education. It seeks to provide insights and recommendations to ensure the ethical use of AI chatbots in higher education by identifying significant gaps in the existing literature and providing scenarios to expect in the development of AI in education.'\n",
      " 'GenAI (GenAI) is transforming content creation, enabling faster and cheaper production of text, images, and more. However, it raises complex issues regarding intellectual property rights and ownership. This article explores the evolving landscape of AI-generated content, focusing on its alignment with existing intellectual property regulations. It delves into legal disputes exemplified by cases like Getty Images, INC. v. Stability AI, INC, and Doe v. Github, INC, which highlight the challenges of AI-generated content regarding intellectual property. The article also discusses the impact on the creative sector and offers recommendations, including the need for ethical guidelines, education, hybrid collaboration, public involvement, and international cooperation. Addressing these challenges is crucial to harmonize intellectual property rights and maximize the benefits of AI in content creation.'\n",
      " \"Changes in the way people live and work, driven by digitalization and automation, have always triggered fears. Developments in the field of digitalization and automation, as well as the use of AI, which has been the subject of much discussion recently, require people in all areas to have a certain degree of adaptability. Increasing complexity, the loss of jobs and the challenges of data protection are just a few examples of the challenges facing not only society but also legislators. The simplification of daily life and the increasing efficiency gains made possible by AI are some of the arguments in favor of using AI. The EU law on AI aims to ensure that AI systems brought to market and deployed in the EU are safe and in line with the EU's fundamental rights and values. The groundbreaking proposal is also intended to promote investment and innovation in the field of AI in Europe.\"]\n",
      "[['ai' 'ethics' 'ethical' 'algorithms' 'technologies' 'human'\n",
      "  'generative' 'technology' 'moral' 'implications' 'innovation' 'article'\n",
      "  'concerns' 'decision' 'considerations' 'approaches' 'academic' 'based'\n",
      "  'explores' 'risks' 'enhance' 'data' 'digital' 'future' 'challenges'\n",
      "  'models' 'between' 'paper' 'approach' 'model' 'genai' 'machine'\n",
      "  'critical' 'about' 'regarding' 'within' 'assessment' 'analysis'\n",
      "  'development' 'society' 'study' 'training' 'studies' 'science'\n",
      "  'research' 'insights' 'impact' 'understanding' 'privacy' 'methods']\n",
      " ['ai' 'algorithms' 'technologies' 'generative' 'ethics' 'ethical'\n",
      "  'enhance' 'analysis' 'data' 'technology' 'studies' 'study'\n",
      "  'considerations' 'implications' 'digital' 'innovation' 'decision'\n",
      "  'approaches' 'human' 'efficiency' 'paper' 'which' 'approach'\n",
      "  'assessment' 'impact' 'between' 'genai' 'risks' 'explores' 'generated'\n",
      "  'benefits' 'article' 'within' 'academic' 'review' 'including'\n",
      "  'insights' 'integration' 'also' 'research' 'understanding' 'however'\n",
      "  'across' 'findings' 'framework' 'machine' 'text' 'regarding'\n",
      "  'potential' 'model']\n",
      " ['algorithms' 'generative' 'ai' 'data' 'enhance' 'technologies' 'model'\n",
      "  'models' 'analysis' 'approaches' 'study' 'paper' 'digital' 'framework'\n",
      "  'technology' 'approach' 'studies' 'assessment' 'insights'\n",
      "  'implications' 'findings' 'ethical' 'ethics' 'human' 'generated'\n",
      "  'machine' 'text' 'risks' 'generation' 'impact' 'academic' 'which'\n",
      "  'decision' 'accuracy' 'training' 'challenges' 'understanding' 'review'\n",
      "  'concerns' 'design' 'considerations' 'explores' 'based' 'including'\n",
      "  'with' 'systems' 'system' 'regarding' 'context' 'learning']\n",
      " ['ai' 'educational' 'generative' 'academic' 'algorithms' 'learning'\n",
      "  'enhance' 'assessment' 'technologies' 'education' 'studies' 'ethics'\n",
      "  'study' 'technology' 'ethical' 'integration' 'genai' 'students'\n",
      "  'training' 'explores' 'including' 'paper' 'level' 'which'\n",
      "  'understanding' 'benefits' 'approaches' 'development' 'data' 'review'\n",
      "  'text' 'implications' 'digital' 'impact' 'these' 'between' 'future'\n",
      "  'as' 'regarding' 'human' 'article' 'generated' 'has' 'by' 'innovation'\n",
      "  'with' 'potential' 'generation' 'literature' 'decision']\n",
      " ['ai' 'generative' 'art' 'algorithms' 'creation' 'innovation'\n",
      "  'technologies' 'digital' 'design' 'generated' 'ethical' 'article'\n",
      "  'technology' 'ethics' 'explores' 'paper' 'enhance' 'human'\n",
      "  'implications' 'approaches' 'approach' 'potential' 'data'\n",
      "  'considerations' 'development' 'studies' 'based' 'models' 'efficiency'\n",
      "  'process' 'decision' 'literature' 'risks' 'challenges' 'study'\n",
      "  'machine' 'future' 'understanding' 'learning' 'generation' 'impact'\n",
      "  'model' 'using' 'methods' 'concerns' 'analysis' 'educational' 'text'\n",
      "  'within' 'with']]\n"
     ]
    }
   ],
   "source": [
    "print(model.documents)\n",
    "print(model.topic_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 5\n"
     ]
    }
   ],
   "source": [
    "num_topics = model.get_num_topics()\n",
    "print(f\"Number of topics: {num_topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([['ai', 'ethics', 'ethical', 'algorithms', 'technologies', 'human',\n",
      "        'generative', 'technology', 'moral', 'implications',\n",
      "        'innovation', 'article', 'concerns', 'decision',\n",
      "        'considerations', 'approaches', 'academic', 'based', 'explores',\n",
      "        'risks', 'enhance', 'data', 'digital', 'future', 'challenges',\n",
      "        'models', 'between', 'paper', 'approach', 'model', 'genai',\n",
      "        'machine', 'critical', 'about', 'regarding', 'within',\n",
      "        'assessment', 'analysis', 'development', 'society', 'study',\n",
      "        'training', 'studies', 'science', 'research', 'insights',\n",
      "        'impact', 'understanding', 'privacy', 'methods'],\n",
      "       ['ai', 'algorithms', 'technologies', 'generative', 'ethics',\n",
      "        'ethical', 'enhance', 'analysis', 'data', 'technology',\n",
      "        'studies', 'study', 'considerations', 'implications', 'digital',\n",
      "        'innovation', 'decision', 'approaches', 'human', 'efficiency',\n",
      "        'paper', 'which', 'approach', 'assessment', 'impact', 'between',\n",
      "        'genai', 'risks', 'explores', 'generated', 'benefits', 'article',\n",
      "        'within', 'academic', 'review', 'including', 'insights',\n",
      "        'integration', 'also', 'research', 'understanding', 'however',\n",
      "        'across', 'findings', 'framework', 'machine', 'text',\n",
      "        'regarding', 'potential', 'model'],\n",
      "       ['algorithms', 'generative', 'ai', 'data', 'enhance',\n",
      "        'technologies', 'model', 'models', 'analysis', 'approaches',\n",
      "        'study', 'paper', 'digital', 'framework', 'technology',\n",
      "        'approach', 'studies', 'assessment', 'insights', 'implications',\n",
      "        'findings', 'ethical', 'ethics', 'human', 'generated', 'machine',\n",
      "        'text', 'risks', 'generation', 'impact', 'academic', 'which',\n",
      "        'decision', 'accuracy', 'training', 'challenges',\n",
      "        'understanding', 'review', 'concerns', 'design',\n",
      "        'considerations', 'explores', 'based', 'including', 'with',\n",
      "        'systems', 'system', 'regarding', 'context', 'learning'],\n",
      "       ['ai', 'educational', 'generative', 'academic', 'algorithms',\n",
      "        'learning', 'enhance', 'assessment', 'technologies', 'education',\n",
      "        'studies', 'ethics', 'study', 'technology', 'ethical',\n",
      "        'integration', 'genai', 'students', 'training', 'explores',\n",
      "        'including', 'paper', 'level', 'which', 'understanding',\n",
      "        'benefits', 'approaches', 'development', 'data', 'review',\n",
      "        'text', 'implications', 'digital', 'impact', 'these', 'between',\n",
      "        'future', 'as', 'regarding', 'human', 'article', 'generated',\n",
      "        'has', 'by', 'innovation', 'with', 'potential', 'generation',\n",
      "        'literature', 'decision'],\n",
      "       ['ai', 'generative', 'art', 'algorithms', 'creation',\n",
      "        'innovation', 'technologies', 'digital', 'design', 'generated',\n",
      "        'ethical', 'article', 'technology', 'ethics', 'explores',\n",
      "        'paper', 'enhance', 'human', 'implications', 'approaches',\n",
      "        'approach', 'potential', 'data', 'considerations', 'development',\n",
      "        'studies', 'based', 'models', 'efficiency', 'process',\n",
      "        'decision', 'literature', 'risks', 'challenges', 'study',\n",
      "        'machine', 'future', 'understanding', 'learning', 'generation',\n",
      "        'impact', 'model', 'using', 'methods', 'concerns', 'analysis',\n",
      "        'educational', 'text', 'within', 'with']], dtype='<U14'), array([[0.3952244 , 0.34159836, 0.32142183, 0.21376303, 0.17667817,\n",
      "        0.16847247, 0.15066311, 0.15046994, 0.12912357, 0.11514658,\n",
      "        0.09905584, 0.08731195, 0.0835447 , 0.08126181, 0.07874406,\n",
      "        0.07872882, 0.07774976, 0.07513949, 0.07435974, 0.06721961,\n",
      "        0.06233189, 0.05850974, 0.05520745, 0.05410413, 0.05348547,\n",
      "        0.05339494, 0.05094005, 0.04937578, 0.04801838, 0.04756291,\n",
      "        0.04528584, 0.0436568 , 0.0396683 , 0.03826059, 0.03655243,\n",
      "        0.03541152, 0.03519496, 0.03394897, 0.03373905, 0.03287669,\n",
      "        0.03153691, 0.03147867, 0.03016103, 0.02907695, 0.02866997,\n",
      "        0.02759198, 0.02688073, 0.02597357, 0.02560608, 0.02314251],\n",
      "       [0.22889328, 0.16284242, 0.11906812, 0.11814278, 0.11013775,\n",
      "        0.10863671, 0.09544966, 0.09300645, 0.09241474, 0.0883719 ,\n",
      "        0.08362874, 0.08055345, 0.07319716, 0.07226296, 0.06634438,\n",
      "        0.06582548, 0.06404936, 0.0639187 , 0.05911051, 0.05883805,\n",
      "        0.05728891, 0.05042046, 0.04714847, 0.0469183 , 0.04470794,\n",
      "        0.04362972, 0.04091811, 0.04090884, 0.04009785, 0.03743377,\n",
      "        0.03712612, 0.03634126, 0.03592305, 0.03543342, 0.03278674,\n",
      "        0.03104668, 0.03006539, 0.02910092, 0.02344718, 0.02203358,\n",
      "        0.02160998, 0.02076027, 0.01994854, 0.01991671, 0.01961373,\n",
      "        0.01704748, 0.01666583, 0.01657866, 0.01644973, 0.01599747],\n",
      "       [0.25304008, 0.2455855 , 0.23671731, 0.21316276, 0.17152388,\n",
      "        0.14210986, 0.13922048, 0.13355657, 0.13311967, 0.11821215,\n",
      "        0.11637466, 0.10808159, 0.10785758, 0.10291037, 0.10054334,\n",
      "        0.09900621, 0.09883407, 0.09523605, 0.09450478, 0.09273219,\n",
      "        0.09084851, 0.0884398 , 0.08763151, 0.08472329, 0.08234364,\n",
      "        0.07928513, 0.07908358, 0.07783434, 0.07763836, 0.07645752,\n",
      "        0.07634503, 0.07558397, 0.07389264, 0.07248049, 0.07124069,\n",
      "        0.0692883 , 0.06877413, 0.06816919, 0.06627117, 0.06614172,\n",
      "        0.06606285, 0.06510305, 0.06437281, 0.06418553, 0.06281025,\n",
      "        0.06224609, 0.06173638, 0.06087447, 0.06034736, 0.06027264],\n",
      "       [0.23246552, 0.16483305, 0.13850081, 0.13343823, 0.12547043,\n",
      "        0.12526365, 0.12455209, 0.12359517, 0.12266226, 0.11851721,\n",
      "        0.11034574, 0.10513917, 0.10056847, 0.08661054, 0.08560181,\n",
      "        0.0837809 , 0.08284788, 0.0816312 , 0.0812498 , 0.06267207,\n",
      "        0.06250672, 0.06097585, 0.05964713, 0.05910464, 0.05569516,\n",
      "        0.05225548, 0.05183779, 0.05109813, 0.0495038 , 0.04867852,\n",
      "        0.04854011, 0.04768644, 0.047529  , 0.04717124, 0.04561014,\n",
      "        0.0434914 , 0.04212249, 0.03987084, 0.0392086 , 0.03868746,\n",
      "        0.03786981, 0.03731094, 0.03499832, 0.03235674, 0.03135597,\n",
      "        0.03046349, 0.02983037, 0.02906813, 0.02879948, 0.02851357],\n",
      "       [0.27615458, 0.22124676, 0.2192927 , 0.1547334 , 0.1371943 ,\n",
      "        0.12783334, 0.11958422, 0.11869065, 0.11355598, 0.1133367 ,\n",
      "        0.11022195, 0.10035146, 0.09835285, 0.09283242, 0.08925535,\n",
      "        0.0851509 , 0.08491302, 0.07376291, 0.0736704 , 0.06818868,\n",
      "        0.05837386, 0.05290635, 0.05149035, 0.05000902, 0.04965843,\n",
      "        0.04904021, 0.04801802, 0.04763979, 0.04691649, 0.04494839,\n",
      "        0.04454632, 0.04395632, 0.04293139, 0.04203416, 0.04187032,\n",
      "        0.04096179, 0.04068174, 0.0396042 , 0.03649433, 0.03646694,\n",
      "        0.03595464, 0.03414506, 0.03367274, 0.03132828, 0.03129353,\n",
      "        0.03063034, 0.03002821, 0.02919226, 0.02678706, 0.02641402]],\n",
      "      dtype=float32), array([0, 1, 2, 3, 4]))\n"
     ]
    }
   ],
   "source": [
    "topics = model.get_topics(5)\n",
    "print(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=1, num_docs=5)\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\"-----------\")\n",
    "    print(doc)\n",
    "    print(\"-----------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the list: 434\n"
     ]
    }
   ],
   "source": [
    "num_lines = len(documents)\n",
    "print(f\"Number of lines in the list: {num_lines}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
